{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jocelyn_Baduria_Assignment 4_part_1_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hVPG0T5tcxPo",
        "5KB1sP0_fldu",
        "79VP-0Loe2f3",
        "HwxLENHrZO4M",
        "Jkj4g14DfwXi",
        "Kg7_KUahrf5A",
        "qzc_1P0IRdRy",
        "EC_hrhYWaykh",
        "bBXZsxgea6NN",
        "rnluE-gFBhlD",
        "NCyxV6e1eBPU",
        "goWJp17yeGgO",
        "i4FiJXW0eKTy",
        "2f-Mx3eVemqo",
        "c2pNmdGKjOGB",
        "bbZvWxNvl1eI",
        "STvGCES2jOGC",
        "Ad3L36GijOGC",
        "lKraEWJ0-uMG",
        "moSFmeTvUFpU",
        "QLPt6cMUqLjn",
        "JYKWSHRJBlBc"
      ],
      "authorship_tag": "ABX9TyOn8lA7QV0+ZBSrbQ5zDKom",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jocelynbaduria/Assignment-4_part_1_2/blob/main/Jocelyn_Baduria_Assignment_4_part_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyrBJ2DE21Yv"
      },
      "source": [
        "# **Part 1. MNIST Classifier**\n",
        "- Use plain feed forward NNs without keras NN library but just numpy.\n",
        "- Can use keras only for image augmentation and for getting training set.\n",
        "- Dont use keras for training model /testing other than data preprocessing - like image data augmentation, scaling, and normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVXdZNFeXZbY"
      },
      "source": [
        "**A. Mini Batch Gradient Descent along with appropriate learning rate. **\n",
        "\n",
        "**B. The code should do dropout **\n",
        "\n",
        "**C. The code should do basic image augmentations to supplement the training data (not testing data) using keras libraries (NEW than the deck) **\n",
        "\n",
        "**D. The code should use  3 or more layers for training (not 2 as in example ) ** \n",
        "\n",
        "**E. The code will continue to use relu activation layer in right places like python code **\n",
        "\n",
        "**F. The code should normalize the input as discussed in the class before training (scaling the input) **\n",
        "\n",
        "**G.The code should use appropriate learning rate (try out few to find out which one works) **\n",
        "\n",
        "**H. The code should provide appropriate metrics, visualization,  testing and training accuracy etc.,. and plot the results and confusion matrix  (this is important) **\n",
        "\n",
        "I. The code should display top common errors like in below link (References Link).\n",
        "Extra points if you hit 99% test accuracy with these changes (very challenging given you are not using CNNs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFgXcotyce3z"
      },
      "source": [
        "### Mount the Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIB8I2FRNp-k",
        "outputId": "6ad8c6f9-1c17-444b-b986-7291f4b3921f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBGFca49fvYI"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vor_E_6Mnk1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Use keras for loading training set only\n",
        "from keras.datasets import mnist\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import itertools\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVPG0T5tcxPo"
      },
      "source": [
        "#**1. Neural Nets MNIST 3 layer Model with Normalization, Dropout prior Training**\n",
        "\n",
        "Training MNIST -  Error and Accuracy Without Mini-Batch and dropout with Learning rate(0.005), Iterations ( 350 )\n",
        "\n",
        "\n",
        "I:349 Train-Error:0.108 Train-Accuracy:1.0\n",
        "\n",
        "Test-Error:0.653, Test-Accuracy:0.7073\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpDezIFGfp0Y"
      },
      "source": [
        "### Load the MNIST digit dataset using (1000,28x28)/255 shape size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YMue6_CQQvL"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "digits, labels = (X_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZdFsOAIdFP9"
      },
      "source": [
        "### Perform One Hot Encoding of Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aQM5LtddDnA"
      },
      "source": [
        "encode_labels = np.zeros((len(labels),10))\n",
        "\n",
        "## For Loop enumerating the encoded labels\n",
        "for i,l in enumerate(labels):\n",
        "    encode_labels[i][l] = 1\n",
        "labels = encode_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYnyXLlGd7WD"
      },
      "source": [
        "### Reshape the digits image in 3Dimension H=28px, W=28px, canal = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT44ayq2c55m"
      },
      "source": [
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "X_test = X_test.reshape(-1,28,28,1)\n",
        "\n",
        "# Reshape the test dataset to a one channel\n",
        "test_digits = X_test.reshape(len(X_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KB1sP0_fldu"
      },
      "source": [
        "### Plot the digit images as gray scales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "6Xb4pdXJXm0b",
        "outputId": "c217a012-f57e-419a-93df-ea3f48a04180"
      },
      "source": [
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0][:,:,0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1][:,:,0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2][:,:,0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3][:,:,0], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79VP-0Loe2f3"
      },
      "source": [
        "### Plot the first digit images as gray scales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "5Wzgt2bjf469",
        "outputId": "9e22a058-c2fd-45a5-ca7c-bcfa87327e22"
      },
      "source": [
        "df = pd.DataFrame(X_train[1][:,:,0])\n",
        "df.style.set_properties(**{'font-size':'2pt'}).background_gradient('Greys')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col27,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col0,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col1,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col2,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col3,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col4,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col5,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col23,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col24,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col25,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col26,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col27{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #ffffff;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col10{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #e2e2e2;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col16{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #727272;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col11,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col11{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #000000;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col18{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #717171;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col19{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #e3e3e3;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col10{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #e4e4e4;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col19,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col10,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col16{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #111111;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col16,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col22,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col12,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col12{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #010101;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col13{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #e0e0e0;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col17{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #1d1d1d;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col17,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col11{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #101010;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col11{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #161616;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col7{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #dedede;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col7,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col18,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col17{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #fcfcfc;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col11{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #fafafa;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col12{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #dcdcdc;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col13,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col6{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #222222;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col17{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #404040;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col18{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #c6c6c6;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col6,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col6{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #020202;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col21{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #9c9c9c;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col11{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #6d6d6d;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col18{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #bbbbbb;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col19{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #515151;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col21,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col17{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #6a6a6a;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col14,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col22{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #505050;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col15,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col15{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #a5a5a5;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col18{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #e5e5e5;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col19{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #cbcbcb;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col21{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #696969;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col13{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #5d5d5d;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col14{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #f9f9f9;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col15{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #cfcfcf;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col16{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #9d9d9d;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col17{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #f5f5f5;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col21{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #0c0c0c;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col22{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #d8d8d8;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col13{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #ececec;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col9{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #6b6b6b;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col12{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #383838;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col13{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #c7c7c7;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col22{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #303030;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col13{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #5e5e5e;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col10{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #0f0f0f;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col11{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #d2d2d2;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col12{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #f6f6f6;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col13{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #f2f2f2;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col10{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #dadada;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col7{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #464646;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col7{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #080808;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col9{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #a8a8a8;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col8{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #1b1b1b;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col9,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col7{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #f3f3f3;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col19{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #8c8c8c;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col21{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #555555;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col22{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #f8f8f8;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col8,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col20,#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col16{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #232323;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col18{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #909090;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col21{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #d3d3d3;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col8{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #828282;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col17{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #6c6c6c;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col19{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #636363;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col8{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #212121;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col18{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #6e6e6e;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col8{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #050505;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col9{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #7f7f7f;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col11{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #f1f1f1;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col12{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #c5c5c5;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col14{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #1f1f1f;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col18{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #dfdfdf;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col10{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #1c1c1c;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col11{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #2c2c2c;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col15{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #484848;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col16{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #929292;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col6{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #c8c8c8;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col7{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #444444;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col13{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #171717;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col14{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #818181;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col8{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #949494;\n",
              "            color:  #000000;\n",
              "        }#T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col12{\n",
              "            font-size:  2pt;\n",
              "            background-color:  #868686;\n",
              "            color:  #000000;\n",
              "        }</style><table id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>        <th class=\"col_heading level0 col7\" >7</th>        <th class=\"col_heading level0 col8\" >8</th>        <th class=\"col_heading level0 col9\" >9</th>        <th class=\"col_heading level0 col10\" >10</th>        <th class=\"col_heading level0 col11\" >11</th>        <th class=\"col_heading level0 col12\" >12</th>        <th class=\"col_heading level0 col13\" >13</th>        <th class=\"col_heading level0 col14\" >14</th>        <th class=\"col_heading level0 col15\" >15</th>        <th class=\"col_heading level0 col16\" >16</th>        <th class=\"col_heading level0 col17\" >17</th>        <th class=\"col_heading level0 col18\" >18</th>        <th class=\"col_heading level0 col19\" >19</th>        <th class=\"col_heading level0 col20\" >20</th>        <th class=\"col_heading level0 col21\" >21</th>        <th class=\"col_heading level0 col22\" >22</th>        <th class=\"col_heading level0 col23\" >23</th>        <th class=\"col_heading level0 col24\" >24</th>        <th class=\"col_heading level0 col25\" >25</th>        <th class=\"col_heading level0 col26\" >26</th>        <th class=\"col_heading level0 col27\" >27</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col0\" class=\"data row0 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col4\" class=\"data row0 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col5\" class=\"data row0 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col6\" class=\"data row0 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col7\" class=\"data row0 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col8\" class=\"data row0 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col9\" class=\"data row0 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col10\" class=\"data row0 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col11\" class=\"data row0 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col12\" class=\"data row0 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col13\" class=\"data row0 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col14\" class=\"data row0 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col15\" class=\"data row0 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col16\" class=\"data row0 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col17\" class=\"data row0 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col18\" class=\"data row0 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col19\" class=\"data row0 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col20\" class=\"data row0 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col21\" class=\"data row0 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col22\" class=\"data row0 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col23\" class=\"data row0 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col24\" class=\"data row0 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col25\" class=\"data row0 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col26\" class=\"data row0 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row0_col27\" class=\"data row0 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col0\" class=\"data row1 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col2\" class=\"data row1 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col4\" class=\"data row1 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col5\" class=\"data row1 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col6\" class=\"data row1 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col7\" class=\"data row1 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col8\" class=\"data row1 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col9\" class=\"data row1 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col10\" class=\"data row1 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col11\" class=\"data row1 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col12\" class=\"data row1 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col13\" class=\"data row1 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col14\" class=\"data row1 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col15\" class=\"data row1 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col16\" class=\"data row1 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col17\" class=\"data row1 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col18\" class=\"data row1 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col19\" class=\"data row1 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col20\" class=\"data row1 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col21\" class=\"data row1 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col22\" class=\"data row1 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col23\" class=\"data row1 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col24\" class=\"data row1 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col25\" class=\"data row1 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col26\" class=\"data row1 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row1_col27\" class=\"data row1 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col0\" class=\"data row2 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col2\" class=\"data row2 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col3\" class=\"data row2 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col4\" class=\"data row2 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col5\" class=\"data row2 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col6\" class=\"data row2 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col7\" class=\"data row2 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col8\" class=\"data row2 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col9\" class=\"data row2 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col10\" class=\"data row2 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col11\" class=\"data row2 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col12\" class=\"data row2 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col13\" class=\"data row2 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col14\" class=\"data row2 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col15\" class=\"data row2 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col16\" class=\"data row2 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col17\" class=\"data row2 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col18\" class=\"data row2 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col19\" class=\"data row2 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col20\" class=\"data row2 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col21\" class=\"data row2 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col22\" class=\"data row2 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col23\" class=\"data row2 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col24\" class=\"data row2 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col25\" class=\"data row2 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col26\" class=\"data row2 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row2_col27\" class=\"data row2 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col0\" class=\"data row3 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col3\" class=\"data row3 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col4\" class=\"data row3 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col5\" class=\"data row3 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col6\" class=\"data row3 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col7\" class=\"data row3 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col8\" class=\"data row3 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col9\" class=\"data row3 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col10\" class=\"data row3 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col11\" class=\"data row3 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col12\" class=\"data row3 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col13\" class=\"data row3 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col14\" class=\"data row3 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col15\" class=\"data row3 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col16\" class=\"data row3 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col17\" class=\"data row3 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col18\" class=\"data row3 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col19\" class=\"data row3 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col20\" class=\"data row3 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col21\" class=\"data row3 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col22\" class=\"data row3 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col23\" class=\"data row3 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col24\" class=\"data row3 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col25\" class=\"data row3 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col26\" class=\"data row3 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row3_col27\" class=\"data row3 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col0\" class=\"data row4 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col2\" class=\"data row4 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col3\" class=\"data row4 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col4\" class=\"data row4 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col5\" class=\"data row4 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col6\" class=\"data row4 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col7\" class=\"data row4 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col8\" class=\"data row4 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col9\" class=\"data row4 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col10\" class=\"data row4 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col11\" class=\"data row4 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col12\" class=\"data row4 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col13\" class=\"data row4 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col14\" class=\"data row4 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col15\" class=\"data row4 col15\" >51</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col16\" class=\"data row4 col16\" >159</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col17\" class=\"data row4 col17\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col18\" class=\"data row4 col18\" >159</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col19\" class=\"data row4 col19\" >50</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col20\" class=\"data row4 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col21\" class=\"data row4 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col22\" class=\"data row4 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col23\" class=\"data row4 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col24\" class=\"data row4 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col25\" class=\"data row4 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col26\" class=\"data row4 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row4_col27\" class=\"data row4 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col0\" class=\"data row5 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col2\" class=\"data row5 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col3\" class=\"data row5 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col4\" class=\"data row5 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col5\" class=\"data row5 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col6\" class=\"data row5 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col7\" class=\"data row5 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col8\" class=\"data row5 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col9\" class=\"data row5 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col10\" class=\"data row5 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col11\" class=\"data row5 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col12\" class=\"data row5 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col13\" class=\"data row5 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col14\" class=\"data row5 col14\" >48</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col15\" class=\"data row5 col15\" >238</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col16\" class=\"data row5 col16\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col17\" class=\"data row5 col17\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col18\" class=\"data row5 col18\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col19\" class=\"data row5 col19\" >237</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col20\" class=\"data row5 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col21\" class=\"data row5 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col22\" class=\"data row5 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col23\" class=\"data row5 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col24\" class=\"data row5 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col25\" class=\"data row5 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col26\" class=\"data row5 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row5_col27\" class=\"data row5 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col0\" class=\"data row6 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col2\" class=\"data row6 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col3\" class=\"data row6 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col4\" class=\"data row6 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col5\" class=\"data row6 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col6\" class=\"data row6 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col7\" class=\"data row6 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col8\" class=\"data row6 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col9\" class=\"data row6 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col10\" class=\"data row6 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col11\" class=\"data row6 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col12\" class=\"data row6 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col13\" class=\"data row6 col13\" >54</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col14\" class=\"data row6 col14\" >227</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col15\" class=\"data row6 col15\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col16\" class=\"data row6 col16\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col17\" class=\"data row6 col17\" >239</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col18\" class=\"data row6 col18\" >233</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col19\" class=\"data row6 col19\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col20\" class=\"data row6 col20\" >57</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col21\" class=\"data row6 col21\" >6</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col22\" class=\"data row6 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col23\" class=\"data row6 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col24\" class=\"data row6 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col25\" class=\"data row6 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col26\" class=\"data row6 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row6_col27\" class=\"data row6 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col0\" class=\"data row7 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col2\" class=\"data row7 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col3\" class=\"data row7 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col4\" class=\"data row7 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col5\" class=\"data row7 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col6\" class=\"data row7 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col7\" class=\"data row7 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col8\" class=\"data row7 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col9\" class=\"data row7 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col10\" class=\"data row7 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col11\" class=\"data row7 col11\" >10</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col12\" class=\"data row7 col12\" >60</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col13\" class=\"data row7 col13\" >224</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col14\" class=\"data row7 col14\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col15\" class=\"data row7 col15\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col16\" class=\"data row7 col16\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col17\" class=\"data row7 col17\" >202</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col18\" class=\"data row7 col18\" >84</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col19\" class=\"data row7 col19\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col20\" class=\"data row7 col20\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col21\" class=\"data row7 col21\" >122</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col22\" class=\"data row7 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col23\" class=\"data row7 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col24\" class=\"data row7 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col25\" class=\"data row7 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col26\" class=\"data row7 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row7_col27\" class=\"data row7 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col0\" class=\"data row8 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col2\" class=\"data row8 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col3\" class=\"data row8 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col4\" class=\"data row8 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col5\" class=\"data row8 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col6\" class=\"data row8 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col7\" class=\"data row8 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col8\" class=\"data row8 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col9\" class=\"data row8 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col10\" class=\"data row8 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col11\" class=\"data row8 col11\" >163</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col12\" class=\"data row8 col12\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col13\" class=\"data row8 col13\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col14\" class=\"data row8 col14\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col15\" class=\"data row8 col15\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col16\" class=\"data row8 col16\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col17\" class=\"data row8 col17\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col18\" class=\"data row8 col18\" >96</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col19\" class=\"data row8 col19\" >189</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col20\" class=\"data row8 col20\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col21\" class=\"data row8 col21\" >167</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col22\" class=\"data row8 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col23\" class=\"data row8 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col24\" class=\"data row8 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col25\" class=\"data row8 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col26\" class=\"data row8 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row8_col27\" class=\"data row8 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col0\" class=\"data row9 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col2\" class=\"data row9 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col3\" class=\"data row9 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col4\" class=\"data row9 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col5\" class=\"data row9 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col6\" class=\"data row9 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col7\" class=\"data row9 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col8\" class=\"data row9 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col9\" class=\"data row9 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col10\" class=\"data row9 col10\" >51</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col11\" class=\"data row9 col11\" >238</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col12\" class=\"data row9 col12\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col13\" class=\"data row9 col13\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col14\" class=\"data row9 col14\" >190</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col15\" class=\"data row9 col15\" >114</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col16\" class=\"data row9 col16\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col17\" class=\"data row9 col17\" >228</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col18\" class=\"data row9 col18\" >47</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col19\" class=\"data row9 col19\" >79</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col20\" class=\"data row9 col20\" >255</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col21\" class=\"data row9 col21\" >168</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col22\" class=\"data row9 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col23\" class=\"data row9 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col24\" class=\"data row9 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col25\" class=\"data row9 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col26\" class=\"data row9 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row9_col27\" class=\"data row9 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col0\" class=\"data row10 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col2\" class=\"data row10 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col3\" class=\"data row10 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col4\" class=\"data row10 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col5\" class=\"data row10 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col6\" class=\"data row10 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col7\" class=\"data row10 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col8\" class=\"data row10 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col9\" class=\"data row10 col9\" >48</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col10\" class=\"data row10 col10\" >238</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col11\" class=\"data row10 col11\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col12\" class=\"data row10 col12\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col13\" class=\"data row10 col13\" >179</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col14\" class=\"data row10 col14\" >12</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col15\" class=\"data row10 col15\" >75</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col16\" class=\"data row10 col16\" >121</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col17\" class=\"data row10 col17\" >21</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col18\" class=\"data row10 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col19\" class=\"data row10 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col20\" class=\"data row10 col20\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col21\" class=\"data row10 col21\" >243</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col22\" class=\"data row10 col22\" >50</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col23\" class=\"data row10 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col24\" class=\"data row10 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col25\" class=\"data row10 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col26\" class=\"data row10 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row10_col27\" class=\"data row10 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col0\" class=\"data row11 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col1\" class=\"data row11 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col2\" class=\"data row11 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col3\" class=\"data row11 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col4\" class=\"data row11 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col5\" class=\"data row11 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col6\" class=\"data row11 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col7\" class=\"data row11 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col8\" class=\"data row11 col8\" >38</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col9\" class=\"data row11 col9\" >165</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col10\" class=\"data row11 col10\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col11\" class=\"data row11 col11\" >233</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col12\" class=\"data row11 col12\" >208</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col13\" class=\"data row11 col13\" >84</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col14\" class=\"data row11 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col15\" class=\"data row11 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col16\" class=\"data row11 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col17\" class=\"data row11 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col18\" class=\"data row11 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col19\" class=\"data row11 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col20\" class=\"data row11 col20\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col21\" class=\"data row11 col21\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col22\" class=\"data row11 col22\" >165</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col23\" class=\"data row11 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col24\" class=\"data row11 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col25\" class=\"data row11 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col26\" class=\"data row11 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row11_col27\" class=\"data row11 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col0\" class=\"data row12 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col1\" class=\"data row12 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col2\" class=\"data row12 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col3\" class=\"data row12 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col4\" class=\"data row12 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col5\" class=\"data row12 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col6\" class=\"data row12 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col7\" class=\"data row12 col7\" >7</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col8\" class=\"data row12 col8\" >178</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col9\" class=\"data row12 col9\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col10\" class=\"data row12 col10\" >240</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col11\" class=\"data row12 col11\" >71</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col12\" class=\"data row12 col12\" >19</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col13\" class=\"data row12 col13\" >28</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col14\" class=\"data row12 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col15\" class=\"data row12 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col16\" class=\"data row12 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col17\" class=\"data row12 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col18\" class=\"data row12 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col19\" class=\"data row12 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col20\" class=\"data row12 col20\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col21\" class=\"data row12 col21\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col22\" class=\"data row12 col22\" >195</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col23\" class=\"data row12 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col24\" class=\"data row12 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col25\" class=\"data row12 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col26\" class=\"data row12 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row12_col27\" class=\"data row12 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col0\" class=\"data row13 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col1\" class=\"data row13 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col2\" class=\"data row13 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col3\" class=\"data row13 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col4\" class=\"data row13 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col5\" class=\"data row13 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col6\" class=\"data row13 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col7\" class=\"data row13 col7\" >57</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col8\" class=\"data row13 col8\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col9\" class=\"data row13 col9\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col10\" class=\"data row13 col10\" >63</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col11\" class=\"data row13 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col12\" class=\"data row13 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col13\" class=\"data row13 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col14\" class=\"data row13 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col15\" class=\"data row13 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col16\" class=\"data row13 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col17\" class=\"data row13 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col18\" class=\"data row13 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col19\" class=\"data row13 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col20\" class=\"data row13 col20\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col21\" class=\"data row13 col21\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col22\" class=\"data row13 col22\" >195</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col23\" class=\"data row13 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col24\" class=\"data row13 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col25\" class=\"data row13 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col26\" class=\"data row13 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row13_col27\" class=\"data row13 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col0\" class=\"data row14 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col1\" class=\"data row14 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col2\" class=\"data row14 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col3\" class=\"data row14 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col4\" class=\"data row14 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col5\" class=\"data row14 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col6\" class=\"data row14 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col7\" class=\"data row14 col7\" >198</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col8\" class=\"data row14 col8\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col9\" class=\"data row14 col9\" >190</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col10\" class=\"data row14 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col11\" class=\"data row14 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col12\" class=\"data row14 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col13\" class=\"data row14 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col14\" class=\"data row14 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col15\" class=\"data row14 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col16\" class=\"data row14 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col17\" class=\"data row14 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col18\" class=\"data row14 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col19\" class=\"data row14 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col20\" class=\"data row14 col20\" >255</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col21\" class=\"data row14 col21\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col22\" class=\"data row14 col22\" >196</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col23\" class=\"data row14 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col24\" class=\"data row14 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col25\" class=\"data row14 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col26\" class=\"data row14 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row14_col27\" class=\"data row14 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col0\" class=\"data row15 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col1\" class=\"data row15 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col2\" class=\"data row15 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col3\" class=\"data row15 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col4\" class=\"data row15 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col5\" class=\"data row15 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col6\" class=\"data row15 col6\" >76</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col7\" class=\"data row15 col7\" >246</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col8\" class=\"data row15 col8\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col9\" class=\"data row15 col9\" >112</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col10\" class=\"data row15 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col11\" class=\"data row15 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col12\" class=\"data row15 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col13\" class=\"data row15 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col14\" class=\"data row15 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col15\" class=\"data row15 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col16\" class=\"data row15 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col17\" class=\"data row15 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col18\" class=\"data row15 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col19\" class=\"data row15 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col20\" class=\"data row15 col20\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col21\" class=\"data row15 col21\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col22\" class=\"data row15 col22\" >148</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col23\" class=\"data row15 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col24\" class=\"data row15 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col25\" class=\"data row15 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col26\" class=\"data row15 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row15_col27\" class=\"data row15 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col0\" class=\"data row16 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col1\" class=\"data row16 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col2\" class=\"data row16 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col3\" class=\"data row16 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col4\" class=\"data row16 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col5\" class=\"data row16 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col6\" class=\"data row16 col6\" >85</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col7\" class=\"data row16 col7\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col8\" class=\"data row16 col8\" >230</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col9\" class=\"data row16 col9\" >25</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col10\" class=\"data row16 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col11\" class=\"data row16 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col12\" class=\"data row16 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col13\" class=\"data row16 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col14\" class=\"data row16 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col15\" class=\"data row16 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col16\" class=\"data row16 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col17\" class=\"data row16 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col18\" class=\"data row16 col18\" >7</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col19\" class=\"data row16 col19\" >135</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col20\" class=\"data row16 col20\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col21\" class=\"data row16 col21\" >186</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col22\" class=\"data row16 col22\" >12</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col23\" class=\"data row16 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col24\" class=\"data row16 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col25\" class=\"data row16 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col26\" class=\"data row16 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row16_col27\" class=\"data row16 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col0\" class=\"data row17 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col1\" class=\"data row17 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col2\" class=\"data row17 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col3\" class=\"data row17 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col4\" class=\"data row17 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col5\" class=\"data row17 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col6\" class=\"data row17 col6\" >85</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col7\" class=\"data row17 col7\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col8\" class=\"data row17 col8\" >223</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col9\" class=\"data row17 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col10\" class=\"data row17 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col11\" class=\"data row17 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col12\" class=\"data row17 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col13\" class=\"data row17 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col14\" class=\"data row17 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col15\" class=\"data row17 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col16\" class=\"data row17 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col17\" class=\"data row17 col17\" >7</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col18\" class=\"data row17 col18\" >131</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col19\" class=\"data row17 col19\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col20\" class=\"data row17 col20\" >225</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col21\" class=\"data row17 col21\" >71</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col22\" class=\"data row17 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col23\" class=\"data row17 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col24\" class=\"data row17 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col25\" class=\"data row17 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col26\" class=\"data row17 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row17_col27\" class=\"data row17 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col0\" class=\"data row18 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col1\" class=\"data row18 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col2\" class=\"data row18 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col3\" class=\"data row18 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col4\" class=\"data row18 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col5\" class=\"data row18 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col6\" class=\"data row18 col6\" >85</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col7\" class=\"data row18 col7\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col8\" class=\"data row18 col8\" >145</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col9\" class=\"data row18 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col10\" class=\"data row18 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col11\" class=\"data row18 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col12\" class=\"data row18 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col13\" class=\"data row18 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col14\" class=\"data row18 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col15\" class=\"data row18 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col16\" class=\"data row18 col16\" >48</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col17\" class=\"data row18 col17\" >165</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col18\" class=\"data row18 col18\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col19\" class=\"data row18 col19\" >173</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col20\" class=\"data row18 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col21\" class=\"data row18 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col22\" class=\"data row18 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col23\" class=\"data row18 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col24\" class=\"data row18 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col25\" class=\"data row18 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col26\" class=\"data row18 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row18_col27\" class=\"data row18 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col0\" class=\"data row19 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col1\" class=\"data row19 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col2\" class=\"data row19 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col3\" class=\"data row19 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col4\" class=\"data row19 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col5\" class=\"data row19 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col6\" class=\"data row19 col6\" >86</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col7\" class=\"data row19 col7\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col8\" class=\"data row19 col8\" >225</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col9\" class=\"data row19 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col10\" class=\"data row19 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col11\" class=\"data row19 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col12\" class=\"data row19 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col13\" class=\"data row19 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col14\" class=\"data row19 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col15\" class=\"data row19 col15\" >114</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col16\" class=\"data row19 col16\" >238</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col17\" class=\"data row19 col17\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col18\" class=\"data row19 col18\" >162</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col19\" class=\"data row19 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col20\" class=\"data row19 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col21\" class=\"data row19 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col22\" class=\"data row19 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col23\" class=\"data row19 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col24\" class=\"data row19 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col25\" class=\"data row19 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col26\" class=\"data row19 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row19_col27\" class=\"data row19 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col0\" class=\"data row20 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col1\" class=\"data row20 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col2\" class=\"data row20 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col3\" class=\"data row20 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col4\" class=\"data row20 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col5\" class=\"data row20 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col6\" class=\"data row20 col6\" >85</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col7\" class=\"data row20 col7\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col8\" class=\"data row20 col8\" >249</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col9\" class=\"data row20 col9\" >146</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col10\" class=\"data row20 col10\" >48</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col11\" class=\"data row20 col11\" >29</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col12\" class=\"data row20 col12\" >85</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col13\" class=\"data row20 col13\" >178</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col14\" class=\"data row20 col14\" >225</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col15\" class=\"data row20 col15\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col16\" class=\"data row20 col16\" >223</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col17\" class=\"data row20 col17\" >167</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col18\" class=\"data row20 col18\" >56</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col19\" class=\"data row20 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col20\" class=\"data row20 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col21\" class=\"data row20 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col22\" class=\"data row20 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col23\" class=\"data row20 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col24\" class=\"data row20 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col25\" class=\"data row20 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col26\" class=\"data row20 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row20_col27\" class=\"data row20 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col0\" class=\"data row21 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col1\" class=\"data row21 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col2\" class=\"data row21 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col3\" class=\"data row21 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col4\" class=\"data row21 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col5\" class=\"data row21 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col6\" class=\"data row21 col6\" >85</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col7\" class=\"data row21 col7\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col8\" class=\"data row21 col8\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col9\" class=\"data row21 col9\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col10\" class=\"data row21 col10\" >229</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col11\" class=\"data row21 col11\" >215</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col12\" class=\"data row21 col12\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col13\" class=\"data row21 col13\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col14\" class=\"data row21 col14\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col15\" class=\"data row21 col15\" >196</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col16\" class=\"data row21 col16\" >130</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col17\" class=\"data row21 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col18\" class=\"data row21 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col19\" class=\"data row21 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col20\" class=\"data row21 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col21\" class=\"data row21 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col22\" class=\"data row21 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col23\" class=\"data row21 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col24\" class=\"data row21 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col25\" class=\"data row21 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col26\" class=\"data row21 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row21_col27\" class=\"data row21 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col0\" class=\"data row22 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col1\" class=\"data row22 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col2\" class=\"data row22 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col3\" class=\"data row22 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col4\" class=\"data row22 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col5\" class=\"data row22 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col6\" class=\"data row22 col6\" >28</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col7\" class=\"data row22 col7\" >199</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col8\" class=\"data row22 col8\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col9\" class=\"data row22 col9\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col10\" class=\"data row22 col10\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col11\" class=\"data row22 col11\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col12\" class=\"data row22 col12\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col13\" class=\"data row22 col13\" >233</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col14\" class=\"data row22 col14\" >145</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col15\" class=\"data row22 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col16\" class=\"data row22 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col17\" class=\"data row22 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col18\" class=\"data row22 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col19\" class=\"data row22 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col20\" class=\"data row22 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col21\" class=\"data row22 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col22\" class=\"data row22 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col23\" class=\"data row22 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col24\" class=\"data row22 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col25\" class=\"data row22 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col26\" class=\"data row22 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row22_col27\" class=\"data row22 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col0\" class=\"data row23 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col1\" class=\"data row23 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col2\" class=\"data row23 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col3\" class=\"data row23 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col4\" class=\"data row23 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col5\" class=\"data row23 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col6\" class=\"data row23 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col7\" class=\"data row23 col7\" >25</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col8\" class=\"data row23 col8\" >128</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col9\" class=\"data row23 col9\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col10\" class=\"data row23 col10\" >253</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col11\" class=\"data row23 col11\" >252</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col12\" class=\"data row23 col12\" >141</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col13\" class=\"data row23 col13\" >37</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col14\" class=\"data row23 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col15\" class=\"data row23 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col16\" class=\"data row23 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col17\" class=\"data row23 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col18\" class=\"data row23 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col19\" class=\"data row23 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col20\" class=\"data row23 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col21\" class=\"data row23 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col22\" class=\"data row23 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col23\" class=\"data row23 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col24\" class=\"data row23 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col25\" class=\"data row23 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col26\" class=\"data row23 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row23_col27\" class=\"data row23 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col0\" class=\"data row24 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col1\" class=\"data row24 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col2\" class=\"data row24 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col3\" class=\"data row24 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col4\" class=\"data row24 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col5\" class=\"data row24 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col6\" class=\"data row24 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col7\" class=\"data row24 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col8\" class=\"data row24 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col9\" class=\"data row24 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col10\" class=\"data row24 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col11\" class=\"data row24 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col12\" class=\"data row24 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col13\" class=\"data row24 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col14\" class=\"data row24 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col15\" class=\"data row24 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col16\" class=\"data row24 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col17\" class=\"data row24 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col18\" class=\"data row24 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col19\" class=\"data row24 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col20\" class=\"data row24 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col21\" class=\"data row24 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col22\" class=\"data row24 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col23\" class=\"data row24 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col24\" class=\"data row24 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col25\" class=\"data row24 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col26\" class=\"data row24 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row24_col27\" class=\"data row24 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col0\" class=\"data row25 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col1\" class=\"data row25 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col2\" class=\"data row25 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col3\" class=\"data row25 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col4\" class=\"data row25 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col5\" class=\"data row25 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col6\" class=\"data row25 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col7\" class=\"data row25 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col8\" class=\"data row25 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col9\" class=\"data row25 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col10\" class=\"data row25 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col11\" class=\"data row25 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col12\" class=\"data row25 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col13\" class=\"data row25 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col14\" class=\"data row25 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col15\" class=\"data row25 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col16\" class=\"data row25 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col17\" class=\"data row25 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col18\" class=\"data row25 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col19\" class=\"data row25 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col20\" class=\"data row25 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col21\" class=\"data row25 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col22\" class=\"data row25 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col23\" class=\"data row25 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col24\" class=\"data row25 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col25\" class=\"data row25 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col26\" class=\"data row25 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row25_col27\" class=\"data row25 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col0\" class=\"data row26 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col1\" class=\"data row26 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col2\" class=\"data row26 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col3\" class=\"data row26 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col4\" class=\"data row26 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col5\" class=\"data row26 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col6\" class=\"data row26 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col7\" class=\"data row26 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col8\" class=\"data row26 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col9\" class=\"data row26 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col10\" class=\"data row26 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col11\" class=\"data row26 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col12\" class=\"data row26 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col13\" class=\"data row26 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col14\" class=\"data row26 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col15\" class=\"data row26 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col16\" class=\"data row26 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col17\" class=\"data row26 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col18\" class=\"data row26 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col19\" class=\"data row26 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col20\" class=\"data row26 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col21\" class=\"data row26 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col22\" class=\"data row26 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col23\" class=\"data row26 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col24\" class=\"data row26 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col25\" class=\"data row26 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col26\" class=\"data row26 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row26_col27\" class=\"data row26 col27\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col0\" class=\"data row27 col0\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col1\" class=\"data row27 col1\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col2\" class=\"data row27 col2\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col3\" class=\"data row27 col3\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col4\" class=\"data row27 col4\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col5\" class=\"data row27 col5\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col6\" class=\"data row27 col6\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col7\" class=\"data row27 col7\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col8\" class=\"data row27 col8\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col9\" class=\"data row27 col9\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col10\" class=\"data row27 col10\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col11\" class=\"data row27 col11\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col12\" class=\"data row27 col12\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col13\" class=\"data row27 col13\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col14\" class=\"data row27 col14\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col15\" class=\"data row27 col15\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col16\" class=\"data row27 col16\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col17\" class=\"data row27 col17\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col18\" class=\"data row27 col18\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col19\" class=\"data row27 col19\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col20\" class=\"data row27 col20\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col21\" class=\"data row27 col21\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col22\" class=\"data row27 col22\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col23\" class=\"data row27 col23\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col24\" class=\"data row27 col24\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col25\" class=\"data row27 col25\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col26\" class=\"data row27 col26\" >0</td>\n",
              "                        <td id=\"T_90c9d95c_972c_11eb_9d7c_0242ac1c0002row27_col27\" class=\"data row27 col27\" >0</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f6ae23e4590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwxLENHrZO4M"
      },
      "source": [
        "### **Perform Grayscale Normalization of the data prior training **\n",
        "\n",
        "F. The code should normalize the input as discussed in the class before training (scaling the input)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbebnS8ZZSFV"
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkj4g14DfwXi"
      },
      "source": [
        "### Create Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Try9hq0WfvER"
      },
      "source": [
        "# seed random numbers to make calculation\n",
        "np.random.seed(1)\n",
        "\n",
        "# returns x if x > 0, return 0 otherwise\n",
        "Relu = lambda x:(x>=0) * x \n",
        "\n",
        "# returns 1 for input > 0, return 0 otherwise\n",
        "Relu_derivative = lambda x: x>=0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFrOzy0Hg5Ql"
      },
      "source": [
        "### Initialize learning rate (0.005), epoch(350), hidden layers(40), pixels per image(784), number of target values/labels(10)\n",
        "\n",
        "\n",
        "Old setting- Initialize learning rate (0.005), iterations(350), hidden layers(40), pixels per image(784), number of target values/labels(10)\n",
        "lr, epoch, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFunlnTohXlQ"
      },
      "source": [
        "lr, epoch, hidden_size, pixels, numLabels = (0.005, 350, 40, 784, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSwsDFQDrFUG"
      },
      "source": [
        "### Randomly Initialize the weights with mean 0, w = np.random.rand(n) * sqrt(2.0/n)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLbg98xGrCjA"
      },
      "source": [
        "weights0_1 = 0.2*np.random.random((pixels,hidden_size)) - 0.1\n",
        "weights1_2 = 0.2*np.random.random((hidden_size,numLabels)) - 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg7_KUahrf5A"
      },
      "source": [
        "### Forward propagation and Backward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jutbhmg3Qa32",
        "outputId": "00d40ffd-d160-4362-d0d3-e710120cf92a"
      },
      "source": [
        "for j in range(epoch):\n",
        "    error, correctCnt = (0.0, 0)\n",
        "\n",
        "    # Feed forward through layers 0, 1, and 2 ( 3 layers)\n",
        "    for i in range(len(digits)):\n",
        "        layer_0 = digits[i:i+1]\n",
        "        layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "        layer_2 = np.dot(layer_1,weights1_2)\n",
        "\n",
        "    # How much did we miss the target value(error)?\n",
        "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
        "        correctCnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "\n",
        "    # Compute the gradient descent using relu activation function\n",
        "        layer_2_deltaChange = (labels[i:i+1] - layer_2)\n",
        "        layer_1_deltaChange = layer_2_deltaChange.dot(weights1_2.T) * Relu_derivative(layer_1)\n",
        "\n",
        "    # Updating the weights \n",
        "        weights1_2 += lr * layer_1.T.dot(layer_2_deltaChange)\n",
        "        weights0_1 += lr * layer_0.T.dot(layer_1_deltaChange)\n",
        "\n",
        "# Print the error for each training epoch\n",
        "    print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \", Training-Accuracy:\" + str(correctCnt/float(len(digits))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch:0 Training-Error:0.722, Training-Accuracy:0.537\n",
            " Epoch:1 Training-Error:0.512, Training-Accuracy:0.753\n",
            " Epoch:2 Training-Error:0.448, Training-Accuracy:0.804\n",
            " Epoch:3 Training-Error:0.411, Training-Accuracy:0.837\n",
            " Epoch:4 Training-Error:0.385, Training-Accuracy:0.846\n",
            " Epoch:5 Training-Error:0.367, Training-Accuracy:0.863\n",
            " Epoch:6 Training-Error:0.352, Training-Accuracy:0.876\n",
            " Epoch:7 Training-Error:0.340, Training-Accuracy:0.884\n",
            " Epoch:8 Training-Error:0.329, Training-Accuracy:0.892\n",
            " Epoch:9 Training-Error:0.320, Training-Accuracy:0.897\n",
            " Epoch:10 Training-Error:0.312, Training-Accuracy:0.901\n",
            " Epoch:11 Training-Error:0.304, Training-Accuracy:0.904\n",
            " Epoch:12 Training-Error:0.297, Training-Accuracy:0.91\n",
            " Epoch:13 Training-Error:0.291, Training-Accuracy:0.914\n",
            " Epoch:14 Training-Error:0.286, Training-Accuracy:0.918\n",
            " Epoch:15 Training-Error:0.281, Training-Accuracy:0.918\n",
            " Epoch:16 Training-Error:0.276, Training-Accuracy:0.921\n",
            " Epoch:17 Training-Error:0.272, Training-Accuracy:0.922\n",
            " Epoch:18 Training-Error:0.268, Training-Accuracy:0.926\n",
            " Epoch:19 Training-Error:0.264, Training-Accuracy:0.927\n",
            " Epoch:20 Training-Error:0.260, Training-Accuracy:0.93\n",
            " Epoch:21 Training-Error:0.257, Training-Accuracy:0.932\n",
            " Epoch:22 Training-Error:0.254, Training-Accuracy:0.933\n",
            " Epoch:23 Training-Error:0.250, Training-Accuracy:0.935\n",
            " Epoch:24 Training-Error:0.247, Training-Accuracy:0.935\n",
            " Epoch:25 Training-Error:0.245, Training-Accuracy:0.939\n",
            " Epoch:26 Training-Error:0.242, Training-Accuracy:0.941\n",
            " Epoch:27 Training-Error:0.239, Training-Accuracy:0.941\n",
            " Epoch:28 Training-Error:0.237, Training-Accuracy:0.941\n",
            " Epoch:29 Training-Error:0.235, Training-Accuracy:0.945\n",
            " Epoch:30 Training-Error:0.232, Training-Accuracy:0.946\n",
            " Epoch:31 Training-Error:0.230, Training-Accuracy:0.947\n",
            " Epoch:32 Training-Error:0.228, Training-Accuracy:0.947\n",
            " Epoch:33 Training-Error:0.227, Training-Accuracy:0.948\n",
            " Epoch:34 Training-Error:0.225, Training-Accuracy:0.949\n",
            " Epoch:35 Training-Error:0.223, Training-Accuracy:0.953\n",
            " Epoch:36 Training-Error:0.221, Training-Accuracy:0.953\n",
            " Epoch:37 Training-Error:0.220, Training-Accuracy:0.955\n",
            " Epoch:38 Training-Error:0.218, Training-Accuracy:0.956\n",
            " Epoch:39 Training-Error:0.217, Training-Accuracy:0.956\n",
            " Epoch:40 Training-Error:0.215, Training-Accuracy:0.956\n",
            " Epoch:41 Training-Error:0.214, Training-Accuracy:0.958\n",
            " Epoch:42 Training-Error:0.213, Training-Accuracy:0.958\n",
            " Epoch:43 Training-Error:0.212, Training-Accuracy:0.96\n",
            " Epoch:44 Training-Error:0.210, Training-Accuracy:0.961\n",
            " Epoch:45 Training-Error:0.209, Training-Accuracy:0.963\n",
            " Epoch:46 Training-Error:0.208, Training-Accuracy:0.963\n",
            " Epoch:47 Training-Error:0.207, Training-Accuracy:0.963\n",
            " Epoch:48 Training-Error:0.206, Training-Accuracy:0.965\n",
            " Epoch:49 Training-Error:0.205, Training-Accuracy:0.966\n",
            " Epoch:50 Training-Error:0.204, Training-Accuracy:0.966\n",
            " Epoch:51 Training-Error:0.203, Training-Accuracy:0.966\n",
            " Epoch:52 Training-Error:0.202, Training-Accuracy:0.966\n",
            " Epoch:53 Training-Error:0.201, Training-Accuracy:0.967\n",
            " Epoch:54 Training-Error:0.200, Training-Accuracy:0.967\n",
            " Epoch:55 Training-Error:0.199, Training-Accuracy:0.967\n",
            " Epoch:56 Training-Error:0.198, Training-Accuracy:0.967\n",
            " Epoch:57 Training-Error:0.197, Training-Accuracy:0.967\n",
            " Epoch:58 Training-Error:0.196, Training-Accuracy:0.967\n",
            " Epoch:59 Training-Error:0.195, Training-Accuracy:0.967\n",
            " Epoch:60 Training-Error:0.194, Training-Accuracy:0.967\n",
            " Epoch:61 Training-Error:0.193, Training-Accuracy:0.968\n",
            " Epoch:62 Training-Error:0.193, Training-Accuracy:0.97\n",
            " Epoch:63 Training-Error:0.192, Training-Accuracy:0.97\n",
            " Epoch:64 Training-Error:0.191, Training-Accuracy:0.971\n",
            " Epoch:65 Training-Error:0.190, Training-Accuracy:0.972\n",
            " Epoch:66 Training-Error:0.189, Training-Accuracy:0.972\n",
            " Epoch:67 Training-Error:0.189, Training-Accuracy:0.974\n",
            " Epoch:68 Training-Error:0.188, Training-Accuracy:0.974\n",
            " Epoch:69 Training-Error:0.187, Training-Accuracy:0.974\n",
            " Epoch:70 Training-Error:0.186, Training-Accuracy:0.975\n",
            " Epoch:71 Training-Error:0.186, Training-Accuracy:0.975\n",
            " Epoch:72 Training-Error:0.185, Training-Accuracy:0.976\n",
            " Epoch:73 Training-Error:0.184, Training-Accuracy:0.976\n",
            " Epoch:74 Training-Error:0.183, Training-Accuracy:0.976\n",
            " Epoch:75 Training-Error:0.183, Training-Accuracy:0.977\n",
            " Epoch:76 Training-Error:0.182, Training-Accuracy:0.978\n",
            " Epoch:77 Training-Error:0.181, Training-Accuracy:0.978\n",
            " Epoch:78 Training-Error:0.180, Training-Accuracy:0.978\n",
            " Epoch:79 Training-Error:0.180, Training-Accuracy:0.979\n",
            " Epoch:80 Training-Error:0.179, Training-Accuracy:0.979\n",
            " Epoch:81 Training-Error:0.178, Training-Accuracy:0.979\n",
            " Epoch:82 Training-Error:0.178, Training-Accuracy:0.979\n",
            " Epoch:83 Training-Error:0.177, Training-Accuracy:0.98\n",
            " Epoch:84 Training-Error:0.176, Training-Accuracy:0.98\n",
            " Epoch:85 Training-Error:0.176, Training-Accuracy:0.98\n",
            " Epoch:86 Training-Error:0.175, Training-Accuracy:0.98\n",
            " Epoch:87 Training-Error:0.174, Training-Accuracy:0.98\n",
            " Epoch:88 Training-Error:0.174, Training-Accuracy:0.98\n",
            " Epoch:89 Training-Error:0.173, Training-Accuracy:0.98\n",
            " Epoch:90 Training-Error:0.172, Training-Accuracy:0.981\n",
            " Epoch:91 Training-Error:0.172, Training-Accuracy:0.981\n",
            " Epoch:92 Training-Error:0.171, Training-Accuracy:0.981\n",
            " Epoch:93 Training-Error:0.170, Training-Accuracy:0.981\n",
            " Epoch:94 Training-Error:0.170, Training-Accuracy:0.983\n",
            " Epoch:95 Training-Error:0.169, Training-Accuracy:0.983\n",
            " Epoch:96 Training-Error:0.169, Training-Accuracy:0.983\n",
            " Epoch:97 Training-Error:0.168, Training-Accuracy:0.983\n",
            " Epoch:98 Training-Error:0.167, Training-Accuracy:0.983\n",
            " Epoch:99 Training-Error:0.167, Training-Accuracy:0.983\n",
            " Epoch:100 Training-Error:0.166, Training-Accuracy:0.984\n",
            " Epoch:101 Training-Error:0.166, Training-Accuracy:0.984\n",
            " Epoch:102 Training-Error:0.165, Training-Accuracy:0.984\n",
            " Epoch:103 Training-Error:0.165, Training-Accuracy:0.984\n",
            " Epoch:104 Training-Error:0.164, Training-Accuracy:0.984\n",
            " Epoch:105 Training-Error:0.164, Training-Accuracy:0.984\n",
            " Epoch:106 Training-Error:0.163, Training-Accuracy:0.984\n",
            " Epoch:107 Training-Error:0.163, Training-Accuracy:0.984\n",
            " Epoch:108 Training-Error:0.162, Training-Accuracy:0.984\n",
            " Epoch:109 Training-Error:0.162, Training-Accuracy:0.984\n",
            " Epoch:110 Training-Error:0.161, Training-Accuracy:0.984\n",
            " Epoch:111 Training-Error:0.161, Training-Accuracy:0.984\n",
            " Epoch:112 Training-Error:0.161, Training-Accuracy:0.985\n",
            " Epoch:113 Training-Error:0.160, Training-Accuracy:0.985\n",
            " Epoch:114 Training-Error:0.160, Training-Accuracy:0.986\n",
            " Epoch:115 Training-Error:0.159, Training-Accuracy:0.986\n",
            " Epoch:116 Training-Error:0.159, Training-Accuracy:0.986\n",
            " Epoch:117 Training-Error:0.158, Training-Accuracy:0.986\n",
            " Epoch:118 Training-Error:0.158, Training-Accuracy:0.986\n",
            " Epoch:119 Training-Error:0.158, Training-Accuracy:0.986\n",
            " Epoch:120 Training-Error:0.157, Training-Accuracy:0.986\n",
            " Epoch:121 Training-Error:0.157, Training-Accuracy:0.986\n",
            " Epoch:122 Training-Error:0.156, Training-Accuracy:0.986\n",
            " Epoch:123 Training-Error:0.156, Training-Accuracy:0.986\n",
            " Epoch:124 Training-Error:0.155, Training-Accuracy:0.986\n",
            " Epoch:125 Training-Error:0.155, Training-Accuracy:0.987\n",
            " Epoch:126 Training-Error:0.155, Training-Accuracy:0.986\n",
            " Epoch:127 Training-Error:0.154, Training-Accuracy:0.987\n",
            " Epoch:128 Training-Error:0.154, Training-Accuracy:0.988\n",
            " Epoch:129 Training-Error:0.153, Training-Accuracy:0.989\n",
            " Epoch:130 Training-Error:0.153, Training-Accuracy:0.99\n",
            " Epoch:131 Training-Error:0.153, Training-Accuracy:0.991\n",
            " Epoch:132 Training-Error:0.152, Training-Accuracy:0.991\n",
            " Epoch:133 Training-Error:0.152, Training-Accuracy:0.991\n",
            " Epoch:134 Training-Error:0.151, Training-Accuracy:0.991\n",
            " Epoch:135 Training-Error:0.151, Training-Accuracy:0.991\n",
            " Epoch:136 Training-Error:0.151, Training-Accuracy:0.991\n",
            " Epoch:137 Training-Error:0.150, Training-Accuracy:0.991\n",
            " Epoch:138 Training-Error:0.150, Training-Accuracy:0.991\n",
            " Epoch:139 Training-Error:0.149, Training-Accuracy:0.991\n",
            " Epoch:140 Training-Error:0.149, Training-Accuracy:0.991\n",
            " Epoch:141 Training-Error:0.148, Training-Accuracy:0.991\n",
            " Epoch:142 Training-Error:0.148, Training-Accuracy:0.991\n",
            " Epoch:143 Training-Error:0.148, Training-Accuracy:0.991\n",
            " Epoch:144 Training-Error:0.147, Training-Accuracy:0.991\n",
            " Epoch:145 Training-Error:0.147, Training-Accuracy:0.991\n",
            " Epoch:146 Training-Error:0.147, Training-Accuracy:0.991\n",
            " Epoch:147 Training-Error:0.146, Training-Accuracy:0.991\n",
            " Epoch:148 Training-Error:0.146, Training-Accuracy:0.991\n",
            " Epoch:149 Training-Error:0.145, Training-Accuracy:0.991\n",
            " Epoch:150 Training-Error:0.145, Training-Accuracy:0.991\n",
            " Epoch:151 Training-Error:0.145, Training-Accuracy:0.991\n",
            " Epoch:152 Training-Error:0.144, Training-Accuracy:0.991\n",
            " Epoch:153 Training-Error:0.144, Training-Accuracy:0.991\n",
            " Epoch:154 Training-Error:0.143, Training-Accuracy:0.991\n",
            " Epoch:155 Training-Error:0.143, Training-Accuracy:0.991\n",
            " Epoch:156 Training-Error:0.143, Training-Accuracy:0.991\n",
            " Epoch:157 Training-Error:0.142, Training-Accuracy:0.991\n",
            " Epoch:158 Training-Error:0.142, Training-Accuracy:0.991\n",
            " Epoch:159 Training-Error:0.142, Training-Accuracy:0.992\n",
            " Epoch:160 Training-Error:0.141, Training-Accuracy:0.992\n",
            " Epoch:161 Training-Error:0.141, Training-Accuracy:0.992\n",
            " Epoch:162 Training-Error:0.141, Training-Accuracy:0.992\n",
            " Epoch:163 Training-Error:0.140, Training-Accuracy:0.992\n",
            " Epoch:164 Training-Error:0.140, Training-Accuracy:0.992\n",
            " Epoch:165 Training-Error:0.140, Training-Accuracy:0.992\n",
            " Epoch:166 Training-Error:0.139, Training-Accuracy:0.992\n",
            " Epoch:167 Training-Error:0.139, Training-Accuracy:0.992\n",
            " Epoch:168 Training-Error:0.139, Training-Accuracy:0.992\n",
            " Epoch:169 Training-Error:0.138, Training-Accuracy:0.992\n",
            " Epoch:170 Training-Error:0.138, Training-Accuracy:0.992\n",
            " Epoch:171 Training-Error:0.138, Training-Accuracy:0.992\n",
            " Epoch:172 Training-Error:0.137, Training-Accuracy:0.992\n",
            " Epoch:173 Training-Error:0.137, Training-Accuracy:0.992\n",
            " Epoch:174 Training-Error:0.137, Training-Accuracy:0.992\n",
            " Epoch:175 Training-Error:0.137, Training-Accuracy:0.992\n",
            " Epoch:176 Training-Error:0.136, Training-Accuracy:0.992\n",
            " Epoch:177 Training-Error:0.136, Training-Accuracy:0.993\n",
            " Epoch:178 Training-Error:0.136, Training-Accuracy:0.993\n",
            " Epoch:179 Training-Error:0.135, Training-Accuracy:0.994\n",
            " Epoch:180 Training-Error:0.135, Training-Accuracy:0.995\n",
            " Epoch:181 Training-Error:0.135, Training-Accuracy:0.995\n",
            " Epoch:182 Training-Error:0.135, Training-Accuracy:0.995\n",
            " Epoch:183 Training-Error:0.134, Training-Accuracy:0.995\n",
            " Epoch:184 Training-Error:0.134, Training-Accuracy:0.995\n",
            " Epoch:185 Training-Error:0.134, Training-Accuracy:0.995\n",
            " Epoch:186 Training-Error:0.133, Training-Accuracy:0.996\n",
            " Epoch:187 Training-Error:0.133, Training-Accuracy:0.996\n",
            " Epoch:188 Training-Error:0.133, Training-Accuracy:0.995\n",
            " Epoch:189 Training-Error:0.133, Training-Accuracy:0.995\n",
            " Epoch:190 Training-Error:0.132, Training-Accuracy:0.995\n",
            " Epoch:191 Training-Error:0.132, Training-Accuracy:0.996\n",
            " Epoch:192 Training-Error:0.132, Training-Accuracy:0.996\n",
            " Epoch:193 Training-Error:0.132, Training-Accuracy:0.996\n",
            " Epoch:194 Training-Error:0.131, Training-Accuracy:0.996\n",
            " Epoch:195 Training-Error:0.131, Training-Accuracy:0.996\n",
            " Epoch:196 Training-Error:0.131, Training-Accuracy:0.996\n",
            " Epoch:197 Training-Error:0.130, Training-Accuracy:0.996\n",
            " Epoch:198 Training-Error:0.130, Training-Accuracy:0.996\n",
            " Epoch:199 Training-Error:0.130, Training-Accuracy:0.998\n",
            " Epoch:200 Training-Error:0.130, Training-Accuracy:0.998\n",
            " Epoch:201 Training-Error:0.129, Training-Accuracy:0.998\n",
            " Epoch:202 Training-Error:0.129, Training-Accuracy:0.998\n",
            " Epoch:203 Training-Error:0.129, Training-Accuracy:0.998\n",
            " Epoch:204 Training-Error:0.129, Training-Accuracy:0.998\n",
            " Epoch:205 Training-Error:0.128, Training-Accuracy:0.998\n",
            " Epoch:206 Training-Error:0.128, Training-Accuracy:0.998\n",
            " Epoch:207 Training-Error:0.128, Training-Accuracy:0.998\n",
            " Epoch:208 Training-Error:0.128, Training-Accuracy:0.998\n",
            " Epoch:209 Training-Error:0.127, Training-Accuracy:0.998\n",
            " Epoch:210 Training-Error:0.127, Training-Accuracy:0.998\n",
            " Epoch:211 Training-Error:0.127, Training-Accuracy:0.998\n",
            " Epoch:212 Training-Error:0.127, Training-Accuracy:0.998\n",
            " Epoch:213 Training-Error:0.127, Training-Accuracy:0.998\n",
            " Epoch:214 Training-Error:0.126, Training-Accuracy:0.998\n",
            " Epoch:215 Training-Error:0.126, Training-Accuracy:0.998\n",
            " Epoch:216 Training-Error:0.126, Training-Accuracy:0.998\n",
            " Epoch:217 Training-Error:0.126, Training-Accuracy:0.998\n",
            " Epoch:218 Training-Error:0.125, Training-Accuracy:0.998\n",
            " Epoch:219 Training-Error:0.125, Training-Accuracy:0.998\n",
            " Epoch:220 Training-Error:0.125, Training-Accuracy:0.998\n",
            " Epoch:221 Training-Error:0.125, Training-Accuracy:0.998\n",
            " Epoch:222 Training-Error:0.125, Training-Accuracy:0.998\n",
            " Epoch:223 Training-Error:0.124, Training-Accuracy:0.998\n",
            " Epoch:224 Training-Error:0.124, Training-Accuracy:0.998\n",
            " Epoch:225 Training-Error:0.124, Training-Accuracy:0.998\n",
            " Epoch:226 Training-Error:0.124, Training-Accuracy:0.998\n",
            " Epoch:227 Training-Error:0.124, Training-Accuracy:0.998\n",
            " Epoch:228 Training-Error:0.124, Training-Accuracy:0.998\n",
            " Epoch:229 Training-Error:0.123, Training-Accuracy:0.998\n",
            " Epoch:230 Training-Error:0.123, Training-Accuracy:0.998\n",
            " Epoch:231 Training-Error:0.123, Training-Accuracy:0.998\n",
            " Epoch:232 Training-Error:0.123, Training-Accuracy:0.998\n",
            " Epoch:233 Training-Error:0.123, Training-Accuracy:0.998\n",
            " Epoch:234 Training-Error:0.122, Training-Accuracy:0.998\n",
            " Epoch:235 Training-Error:0.122, Training-Accuracy:0.998\n",
            " Epoch:236 Training-Error:0.122, Training-Accuracy:0.998\n",
            " Epoch:237 Training-Error:0.122, Training-Accuracy:0.998\n",
            " Epoch:238 Training-Error:0.122, Training-Accuracy:0.998\n",
            " Epoch:239 Training-Error:0.122, Training-Accuracy:0.998\n",
            " Epoch:240 Training-Error:0.121, Training-Accuracy:0.998\n",
            " Epoch:241 Training-Error:0.121, Training-Accuracy:0.998\n",
            " Epoch:242 Training-Error:0.121, Training-Accuracy:0.998\n",
            " Epoch:243 Training-Error:0.121, Training-Accuracy:0.998\n",
            " Epoch:244 Training-Error:0.121, Training-Accuracy:0.998\n",
            " Epoch:245 Training-Error:0.121, Training-Accuracy:0.998\n",
            " Epoch:246 Training-Error:0.120, Training-Accuracy:0.998\n",
            " Epoch:247 Training-Error:0.120, Training-Accuracy:0.998\n",
            " Epoch:248 Training-Error:0.120, Training-Accuracy:0.999\n",
            " Epoch:249 Training-Error:0.120, Training-Accuracy:0.999\n",
            " Epoch:250 Training-Error:0.120, Training-Accuracy:0.999\n",
            " Epoch:251 Training-Error:0.120, Training-Accuracy:0.999\n",
            " Epoch:252 Training-Error:0.120, Training-Accuracy:0.999\n",
            " Epoch:253 Training-Error:0.119, Training-Accuracy:0.999\n",
            " Epoch:254 Training-Error:0.119, Training-Accuracy:0.999\n",
            " Epoch:255 Training-Error:0.119, Training-Accuracy:0.999\n",
            " Epoch:256 Training-Error:0.119, Training-Accuracy:0.999\n",
            " Epoch:257 Training-Error:0.119, Training-Accuracy:0.999\n",
            " Epoch:258 Training-Error:0.119, Training-Accuracy:0.999\n",
            " Epoch:259 Training-Error:0.118, Training-Accuracy:0.999\n",
            " Epoch:260 Training-Error:0.118, Training-Accuracy:0.999\n",
            " Epoch:261 Training-Error:0.118, Training-Accuracy:0.999\n",
            " Epoch:262 Training-Error:0.118, Training-Accuracy:0.999\n",
            " Epoch:263 Training-Error:0.118, Training-Accuracy:0.999\n",
            " Epoch:264 Training-Error:0.118, Training-Accuracy:0.999\n",
            " Epoch:265 Training-Error:0.118, Training-Accuracy:0.999\n",
            " Epoch:266 Training-Error:0.117, Training-Accuracy:0.999\n",
            " Epoch:267 Training-Error:0.117, Training-Accuracy:0.999\n",
            " Epoch:268 Training-Error:0.117, Training-Accuracy:0.999\n",
            " Epoch:269 Training-Error:0.117, Training-Accuracy:0.999\n",
            " Epoch:270 Training-Error:0.117, Training-Accuracy:0.999\n",
            " Epoch:271 Training-Error:0.117, Training-Accuracy:0.999\n",
            " Epoch:272 Training-Error:0.117, Training-Accuracy:0.999\n",
            " Epoch:273 Training-Error:0.116, Training-Accuracy:0.999\n",
            " Epoch:274 Training-Error:0.116, Training-Accuracy:0.999\n",
            " Epoch:275 Training-Error:0.116, Training-Accuracy:0.999\n",
            " Epoch:276 Training-Error:0.116, Training-Accuracy:0.999\n",
            " Epoch:277 Training-Error:0.116, Training-Accuracy:0.999\n",
            " Epoch:278 Training-Error:0.116, Training-Accuracy:0.999\n",
            " Epoch:279 Training-Error:0.116, Training-Accuracy:0.999\n",
            " Epoch:280 Training-Error:0.115, Training-Accuracy:0.999\n",
            " Epoch:281 Training-Error:0.115, Training-Accuracy:0.999\n",
            " Epoch:282 Training-Error:0.115, Training-Accuracy:0.999\n",
            " Epoch:283 Training-Error:0.115, Training-Accuracy:0.999\n",
            " Epoch:284 Training-Error:0.115, Training-Accuracy:0.999\n",
            " Epoch:285 Training-Error:0.115, Training-Accuracy:0.999\n",
            " Epoch:286 Training-Error:0.115, Training-Accuracy:0.999\n",
            " Epoch:287 Training-Error:0.114, Training-Accuracy:0.999\n",
            " Epoch:288 Training-Error:0.114, Training-Accuracy:0.999\n",
            " Epoch:289 Training-Error:0.114, Training-Accuracy:0.999\n",
            " Epoch:290 Training-Error:0.114, Training-Accuracy:0.999\n",
            " Epoch:291 Training-Error:0.114, Training-Accuracy:0.999\n",
            " Epoch:292 Training-Error:0.114, Training-Accuracy:0.999\n",
            " Epoch:293 Training-Error:0.114, Training-Accuracy:0.999\n",
            " Epoch:294 Training-Error:0.114, Training-Accuracy:0.999\n",
            " Epoch:295 Training-Error:0.113, Training-Accuracy:0.999\n",
            " Epoch:296 Training-Error:0.113, Training-Accuracy:0.999\n",
            " Epoch:297 Training-Error:0.113, Training-Accuracy:0.999\n",
            " Epoch:298 Training-Error:0.113, Training-Accuracy:0.999\n",
            " Epoch:299 Training-Error:0.113, Training-Accuracy:0.999\n",
            " Epoch:300 Training-Error:0.113, Training-Accuracy:0.999\n",
            " Epoch:301 Training-Error:0.113, Training-Accuracy:0.999\n",
            " Epoch:302 Training-Error:0.113, Training-Accuracy:0.999\n",
            " Epoch:303 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:304 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:305 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:306 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:307 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:308 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:309 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:310 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:311 Training-Error:0.112, Training-Accuracy:0.999\n",
            " Epoch:312 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:313 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:314 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:315 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:316 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:317 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:318 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:319 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:320 Training-Error:0.111, Training-Accuracy:0.999\n",
            " Epoch:321 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:322 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:323 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:324 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:325 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:326 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:327 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:328 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:329 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:330 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:331 Training-Error:0.110, Training-Accuracy:0.999\n",
            " Epoch:332 Training-Error:0.109, Training-Accuracy:0.999\n",
            " Epoch:333 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:334 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:335 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:336 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:337 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:338 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:339 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:340 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:341 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:342 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:343 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:344 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:345 Training-Error:0.109, Training-Accuracy:1.0\n",
            " Epoch:346 Training-Error:0.108, Training-Accuracy:1.0\n",
            " Epoch:347 Training-Error:0.108, Training-Accuracy:1.0\n",
            " Epoch:348 Training-Error:0.108, Training-Accuracy:1.0\n",
            " Epoch:349 Training-Error:0.108, Training-Accuracy:1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzc_1P0IRdRy"
      },
      "source": [
        "### Test the MNIST digits - Using Forward Propagation, Cost Function (Error Computation) and Accuracy without Mini Batch and Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJsNQKBgRlAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ce4bf6-0aa2-488c-fe04-37b907a5ef87"
      },
      "source": [
        "# Test Digits Sample\n",
        "if(j % 10 == 0 or j == epoch-1):\n",
        "    error, correctCnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(test_digits)):\n",
        "        # Feed forward through layers 0, 1, and 2 ( 3 layers) for test MNIST digit samples\n",
        "        layer_0 = test_digits[i:i+1]\n",
        "        layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "        layer_2 = np.dot(layer_1,weights1_2)\n",
        "\n",
        "        # how much did we miss the target value(error)?\n",
        "        error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "        correctCnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "      \n",
        "    # Print the errot for each iterations for test set\n",
        "    # print(\"\\r Epoch:\" + str(j) + \" Test-Error:\" + str(error/float(len(test_digits)))[0:5] + \", Test-Accuracy:\" + str(correctCnt/float(len(test_digits))))\n",
        "    print(\" Test-Error:\" + str(error/float(len(test_digits)))[0:5] + \", Test-Accuracy:\" + str(correctCnt/float(len(test_digits))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Test-Error:0.653, Test-Accuracy:0.7073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsvwcmeeS5c4"
      },
      "source": [
        "### **Adding Dropout **\n",
        "\n",
        "B. The code should do dropout\n",
        "\n",
        "The test accuracy improved from 0.7073 ~ 0.8065\n",
        "\n",
        "Epoch:299 Training-Error:0.342-> Training-Accuracy:0.883, Test-Error:0.413 -> Test-Accuracy:0.8065"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXziXlxVatNg"
      },
      "source": [
        "### Load the MNIST digit dataset using (1000,28x28)/255 shape size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyLTDpKSatNh"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "digits, labels = (X_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC_hrhYWaykh"
      },
      "source": [
        "### Do One Hot Encoding of Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGgl1KfVayki"
      },
      "source": [
        "encode_labels = np.zeros((len(labels),10))\n",
        "\n",
        "## For Loop enumerating the encoded labels\n",
        "for i,l in enumerate(labels):\n",
        "    encode_labels[i][l] = 1\n",
        "labels = encode_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBXZsxgea6NN"
      },
      "source": [
        "### Reshape the digits image in 3Dimension H=28px, W=28px, canal = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl7OC7Voa6NO"
      },
      "source": [
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "X_test = X_test.reshape(-1,28,28,1)\n",
        "\n",
        "# Reshape the test dataset to a one channel\n",
        "test_digits = X_test.reshape(len(X_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUaWwFJebDUN"
      },
      "source": [
        "### **Perform Grayscale Normalization of the data prior training **\n",
        "\n",
        "F. The code should normalize the input as discussed in the class before training (scaling the input)\n",
        "\n",
        "lr, epoch, hidden_size, = (0.005, 300, 100)\n",
        "pixels, numLabels = (784, 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1vSAGxDbDUO"
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMeskvyReTJX"
      },
      "source": [
        "### Neural Network Training with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuB_J3Lz-jxJ",
        "outputId": "06f4417d-304d-4acb-b4fd-14086a4dbb29"
      },
      "source": [
        "import numpy, sys\n",
        "np.random.seed(1)\n",
        "\n",
        "#Activation Function\n",
        "\n",
        "def Relu(x):\n",
        "    # returns x if x > 0\n",
        "    return ( x >= 0 ) * x\n",
        "\n",
        "def Relu_derivative(output):\n",
        "    # returns 1 for input > 0\n",
        "    return output >= 0 \n",
        "\n",
        "# Initialize parameters\n",
        "lr, epoch, hidden_size, = (0.005, 300, 100)\n",
        "pixels, numLabels = (784, 10)\n",
        "\n",
        "weights0_1 = 0.2*np.random.random((pixels, hidden_size)) - 0.1\n",
        "weights1_2 = 0.2*np.random.random((hidden_size, numLabels)) - 0.1\n",
        "\n",
        "for j in range(epoch):\n",
        "    error, correctCnt = (0.0, 0)\n",
        "\n",
        "    # Feed forward through layers 0, 1, and 2 ( 3 layers)\n",
        "    for i in range(len(digits)):\n",
        "        layer_0 = digits[i:i+1]\n",
        "        layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "\n",
        "        # Adding Dropout\n",
        "        dropOut_mask = np.random.randint(2, size=layer_1.shape)\n",
        "\n",
        "        layer_1 *= dropOut_mask * 2\n",
        "        layer_2 = np.dot(layer_1, weights1_2)  \n",
        "\n",
        "    # How much did we miss the target value(error)?\n",
        "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
        "        correctCnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "\n",
        "    # Compute the gradient descent using relu activation function\n",
        "        layer_2_deltaChange = (labels[i:i+1] - layer_2)\n",
        "        layer_1_deltaChange = layer_2_deltaChange.dot(weights1_2.T) * Relu_derivative(layer_1)\n",
        "\n",
        "    # Adding DropOut\n",
        "        layer_1_deltaChange *+ dropOut_mask\n",
        "\n",
        "    # Updating the weights \n",
        "        weights1_2 += lr * layer_1.T.dot(layer_2_deltaChange)\n",
        "        weights0_1 += lr * layer_0.T.dot(layer_1_deltaChange)\n",
        "\n",
        "    # Test Digits Sample\n",
        "    if(j % 10 == 0 or j == epoch-1):\n",
        "        testError, testCorrectcnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(test_digits)):\n",
        "        # Feed forward through layers 0, 1, and 2 ( 3 layers) for test MNIST digit samples\n",
        "        layer_0 = test_digits[i:i+1]\n",
        "        layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "        layer_2 = np.dot(layer_1,weights1_2)\n",
        "\n",
        "        # how much did we miss the target value(error)?\n",
        "        testError += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "        testCorrectcnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "      \n",
        "\n",
        "    print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \"-> Training-Accuracy:\" + str(correctCnt/float(len(digits))) + \\\n",
        "          \", Test-Error:\" + str(testError/float(len(test_digits)))[0:5] + \" -> Test-Accuracy:\" + str(testCorrectcnt/float(len(test_digits))))\n",
        "    # print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \", Training-Accuracy:\" + str(correctCnt/float(len(digits))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch:0 Training-Error:0.889-> Training-Accuracy:0.474, Test-Error:0.584 -> Test-Accuracy:0.6681\n",
            " Epoch:1 Training-Error:0.624-> Training-Accuracy:0.666, Test-Error:1.101 -> Test-Accuracy:1.3949\n",
            " Epoch:2 Training-Error:0.567-> Training-Accuracy:0.719, Test-Error:1.591 -> Test-Accuracy:2.1459\n",
            " Epoch:3 Training-Error:0.527-> Training-Accuracy:0.741, Test-Error:2.053 -> Test-Accuracy:2.919\n",
            " Epoch:4 Training-Error:0.502-> Training-Accuracy:0.758, Test-Error:2.496 -> Test-Accuracy:3.7001\n",
            " Epoch:5 Training-Error:0.485-> Training-Accuracy:0.77, Test-Error:2.919 -> Test-Accuracy:4.5049\n",
            " Epoch:6 Training-Error:0.481-> Training-Accuracy:0.77, Test-Error:3.333 -> Test-Accuracy:5.3102\n",
            " Epoch:7 Training-Error:0.464-> Training-Accuracy:0.793, Test-Error:3.737 -> Test-Accuracy:6.1289\n",
            " Epoch:8 Training-Error:0.443-> Training-Accuracy:0.801, Test-Error:4.137 -> Test-Accuracy:6.9491\n",
            " Epoch:9 Training-Error:0.441-> Training-Accuracy:0.805, Test-Error:4.540 -> Test-Accuracy:7.7668\n",
            " Epoch:10 Training-Error:0.443-> Training-Accuracy:0.805, Test-Error:0.399 -> Test-Accuracy:0.817\n",
            " Epoch:11 Training-Error:0.432-> Training-Accuracy:0.81, Test-Error:0.784 -> Test-Accuracy:1.6471\n",
            " Epoch:12 Training-Error:0.421-> Training-Accuracy:0.827, Test-Error:1.171 -> Test-Accuracy:2.4675\n",
            " Epoch:13 Training-Error:0.421-> Training-Accuracy:0.804, Test-Error:1.556 -> Test-Accuracy:3.2943\n",
            " Epoch:14 Training-Error:0.422-> Training-Accuracy:0.818, Test-Error:1.931 -> Test-Accuracy:4.131\n",
            " Epoch:15 Training-Error:0.414-> Training-Accuracy:0.826, Test-Error:2.312 -> Test-Accuracy:4.953\n",
            " Epoch:16 Training-Error:0.406-> Training-Accuracy:0.828, Test-Error:2.680 -> Test-Accuracy:5.7958\n",
            " Epoch:17 Training-Error:0.399-> Training-Accuracy:0.831, Test-Error:3.041 -> Test-Accuracy:6.6388\n",
            " Epoch:18 Training-Error:0.407-> Training-Accuracy:0.819, Test-Error:3.410 -> Test-Accuracy:7.4693\n",
            " Epoch:19 Training-Error:0.413-> Training-Accuracy:0.823, Test-Error:3.788 -> Test-Accuracy:8.3062\n",
            " Epoch:20 Training-Error:0.405-> Training-Accuracy:0.829, Test-Error:0.364 -> Test-Accuracy:0.8401\n",
            " Epoch:21 Training-Error:0.403-> Training-Accuracy:0.832, Test-Error:0.739 -> Test-Accuracy:1.6766\n",
            " Epoch:22 Training-Error:0.410-> Training-Accuracy:0.818, Test-Error:1.104 -> Test-Accuracy:2.5117\n",
            " Epoch:23 Training-Error:0.398-> Training-Accuracy:0.832, Test-Error:1.473 -> Test-Accuracy:3.339\n",
            " Epoch:24 Training-Error:0.405-> Training-Accuracy:0.828, Test-Error:1.844 -> Test-Accuracy:4.1684\n",
            " Epoch:25 Training-Error:0.403-> Training-Accuracy:0.837, Test-Error:2.208 -> Test-Accuracy:5.0028\n",
            " Epoch:26 Training-Error:0.398-> Training-Accuracy:0.832, Test-Error:2.571 -> Test-Accuracy:5.8379\n",
            " Epoch:27 Training-Error:0.392-> Training-Accuracy:0.834, Test-Error:2.930 -> Test-Accuracy:6.6729\n",
            " Epoch:28 Training-Error:0.391-> Training-Accuracy:0.85, Test-Error:3.285 -> Test-Accuracy:7.5189\n",
            " Epoch:29 Training-Error:0.380-> Training-Accuracy:0.852, Test-Error:3.641 -> Test-Accuracy:8.3631\n",
            " Epoch:30 Training-Error:0.381-> Training-Accuracy:0.861, Test-Error:0.361 -> Test-Accuracy:0.8323\n",
            " Epoch:31 Training-Error:0.391-> Training-Accuracy:0.838, Test-Error:0.717 -> Test-Accuracy:1.6795\n",
            " Epoch:32 Training-Error:0.386-> Training-Accuracy:0.834, Test-Error:1.077 -> Test-Accuracy:2.5121\n",
            " Epoch:33 Training-Error:0.389-> Training-Accuracy:0.842, Test-Error:1.439 -> Test-Accuracy:3.3468\n",
            " Epoch:34 Training-Error:0.386-> Training-Accuracy:0.853, Test-Error:1.795 -> Test-Accuracy:4.1897\n",
            " Epoch:35 Training-Error:0.379-> Training-Accuracy:0.841, Test-Error:2.151 -> Test-Accuracy:5.0252\n",
            " Epoch:36 Training-Error:0.381-> Training-Accuracy:0.845, Test-Error:2.502 -> Test-Accuracy:5.8688\n",
            " Epoch:37 Training-Error:0.386-> Training-Accuracy:0.842, Test-Error:2.858 -> Test-Accuracy:6.7105\n",
            " Epoch:38 Training-Error:0.392-> Training-Accuracy:0.846, Test-Error:3.217 -> Test-Accuracy:7.55\n",
            " Epoch:39 Training-Error:0.370-> Training-Accuracy:0.862, Test-Error:3.571 -> Test-Accuracy:8.3829\n",
            " Epoch:40 Training-Error:0.373-> Training-Accuracy:0.856, Test-Error:0.367 -> Test-Accuracy:0.8334\n",
            " Epoch:41 Training-Error:0.381-> Training-Accuracy:0.848, Test-Error:0.725 -> Test-Accuracy:1.6743\n",
            " Epoch:42 Training-Error:0.374-> Training-Accuracy:0.855, Test-Error:1.078 -> Test-Accuracy:2.5099\n",
            " Epoch:43 Training-Error:0.386-> Training-Accuracy:0.854, Test-Error:1.433 -> Test-Accuracy:3.3532\n",
            " Epoch:44 Training-Error:0.376-> Training-Accuracy:0.852, Test-Error:1.788 -> Test-Accuracy:4.1896\n",
            " Epoch:45 Training-Error:0.378-> Training-Accuracy:0.848, Test-Error:2.141 -> Test-Accuracy:5.0346\n",
            " Epoch:46 Training-Error:0.376-> Training-Accuracy:0.863, Test-Error:2.497 -> Test-Accuracy:5.8718\n",
            " Epoch:47 Training-Error:0.374-> Training-Accuracy:0.85, Test-Error:2.848 -> Test-Accuracy:6.7197\n",
            " Epoch:48 Training-Error:0.368-> Training-Accuracy:0.85, Test-Error:3.202 -> Test-Accuracy:7.5613\n",
            " Epoch:49 Training-Error:0.390-> Training-Accuracy:0.849, Test-Error:3.566 -> Test-Accuracy:8.3945\n",
            " Epoch:50 Training-Error:0.369-> Training-Accuracy:0.855, Test-Error:0.343 -> Test-Accuracy:0.8441\n",
            " Epoch:51 Training-Error:0.375-> Training-Accuracy:0.858, Test-Error:0.682 -> Test-Accuracy:1.6937\n",
            " Epoch:52 Training-Error:0.368-> Training-Accuracy:0.848, Test-Error:1.041 -> Test-Accuracy:2.5306\n",
            " Epoch:53 Training-Error:0.378-> Training-Accuracy:0.851, Test-Error:1.404 -> Test-Accuracy:3.3646\n",
            " Epoch:54 Training-Error:0.376-> Training-Accuracy:0.845, Test-Error:1.747 -> Test-Accuracy:4.2121\n",
            " Epoch:55 Training-Error:0.359-> Training-Accuracy:0.863, Test-Error:2.102 -> Test-Accuracy:5.0544\n",
            " Epoch:56 Training-Error:0.367-> Training-Accuracy:0.847, Test-Error:2.460 -> Test-Accuracy:5.8961\n",
            " Epoch:57 Training-Error:0.378-> Training-Accuracy:0.85, Test-Error:2.816 -> Test-Accuracy:6.7392\n",
            " Epoch:58 Training-Error:0.373-> Training-Accuracy:0.846, Test-Error:3.179 -> Test-Accuracy:7.574\n",
            " Epoch:59 Training-Error:0.373-> Training-Accuracy:0.867, Test-Error:3.530 -> Test-Accuracy:8.416\n",
            " Epoch:60 Training-Error:0.365-> Training-Accuracy:0.866, Test-Error:0.357 -> Test-Accuracy:0.8395\n",
            " Epoch:61 Training-Error:0.380-> Training-Accuracy:0.853, Test-Error:0.722 -> Test-Accuracy:1.6801\n",
            " Epoch:62 Training-Error:0.374-> Training-Accuracy:0.854, Test-Error:1.076 -> Test-Accuracy:2.5134\n",
            " Epoch:63 Training-Error:0.364-> Training-Accuracy:0.868, Test-Error:1.422 -> Test-Accuracy:3.3569\n",
            " Epoch:64 Training-Error:0.374-> Training-Accuracy:0.853, Test-Error:1.766 -> Test-Accuracy:4.2062\n",
            " Epoch:65 Training-Error:0.368-> Training-Accuracy:0.867, Test-Error:2.111 -> Test-Accuracy:5.0424\n",
            " Epoch:66 Training-Error:0.366-> Training-Accuracy:0.865, Test-Error:2.458 -> Test-Accuracy:5.8824\n",
            " Epoch:67 Training-Error:0.364-> Training-Accuracy:0.859, Test-Error:2.803 -> Test-Accuracy:6.7261\n",
            " Epoch:68 Training-Error:0.366-> Training-Accuracy:0.861, Test-Error:3.157 -> Test-Accuracy:7.5706\n",
            " Epoch:69 Training-Error:0.366-> Training-Accuracy:0.864, Test-Error:3.509 -> Test-Accuracy:8.4195\n",
            " Epoch:70 Training-Error:0.368-> Training-Accuracy:0.853, Test-Error:0.346 -> Test-Accuracy:0.8435\n",
            " Epoch:71 Training-Error:0.377-> Training-Accuracy:0.856, Test-Error:0.683 -> Test-Accuracy:1.691\n",
            " Epoch:72 Training-Error:0.366-> Training-Accuracy:0.859, Test-Error:1.035 -> Test-Accuracy:2.5236\n",
            " Epoch:73 Training-Error:0.352-> Training-Accuracy:0.866, Test-Error:1.374 -> Test-Accuracy:3.3617\n",
            " Epoch:74 Training-Error:0.364-> Training-Accuracy:0.873, Test-Error:1.722 -> Test-Accuracy:4.2127\n",
            " Epoch:75 Training-Error:0.362-> Training-Accuracy:0.856, Test-Error:2.065 -> Test-Accuracy:5.0595\n",
            " Epoch:76 Training-Error:0.357-> Training-Accuracy:0.861, Test-Error:2.411 -> Test-Accuracy:5.8966\n",
            " Epoch:77 Training-Error:0.360-> Training-Accuracy:0.854, Test-Error:2.760 -> Test-Accuracy:6.7404\n",
            " Epoch:78 Training-Error:0.370-> Training-Accuracy:0.856, Test-Error:3.113 -> Test-Accuracy:7.5782\n",
            " Epoch:79 Training-Error:0.363-> Training-Accuracy:0.87, Test-Error:3.458 -> Test-Accuracy:8.419\n",
            " Epoch:80 Training-Error:0.372-> Training-Accuracy:0.849, Test-Error:0.337 -> Test-Accuracy:0.8487\n",
            " Epoch:81 Training-Error:0.363-> Training-Accuracy:0.865, Test-Error:0.680 -> Test-Accuracy:1.6965\n",
            " Epoch:82 Training-Error:0.356-> Training-Accuracy:0.862, Test-Error:1.019 -> Test-Accuracy:2.5442\n",
            " Epoch:83 Training-Error:0.364-> Training-Accuracy:0.862, Test-Error:1.358 -> Test-Accuracy:3.3902\n",
            " Epoch:84 Training-Error:0.355-> Training-Accuracy:0.875, Test-Error:1.709 -> Test-Accuracy:4.2353\n",
            " Epoch:85 Training-Error:0.365-> Training-Accuracy:0.854, Test-Error:2.047 -> Test-Accuracy:5.0861\n",
            " Epoch:86 Training-Error:0.357-> Training-Accuracy:0.863, Test-Error:2.404 -> Test-Accuracy:5.9238\n",
            " Epoch:87 Training-Error:0.357-> Training-Accuracy:0.856, Test-Error:2.747 -> Test-Accuracy:6.7655\n",
            " Epoch:88 Training-Error:0.351-> Training-Accuracy:0.879, Test-Error:3.093 -> Test-Accuracy:7.6027\n",
            " Epoch:89 Training-Error:0.357-> Training-Accuracy:0.856, Test-Error:3.435 -> Test-Accuracy:8.4487\n",
            " Epoch:90 Training-Error:0.352-> Training-Accuracy:0.878, Test-Error:0.338 -> Test-Accuracy:0.8518\n",
            " Epoch:91 Training-Error:0.366-> Training-Accuracy:0.874, Test-Error:0.681 -> Test-Accuracy:1.7006\n",
            " Epoch:92 Training-Error:0.358-> Training-Accuracy:0.882, Test-Error:1.020 -> Test-Accuracy:2.5461\n",
            " Epoch:93 Training-Error:0.364-> Training-Accuracy:0.863, Test-Error:1.360 -> Test-Accuracy:3.3908\n",
            " Epoch:94 Training-Error:0.369-> Training-Accuracy:0.873, Test-Error:1.707 -> Test-Accuracy:4.2425\n",
            " Epoch:95 Training-Error:0.366-> Training-Accuracy:0.864, Test-Error:2.050 -> Test-Accuracy:5.0875\n",
            " Epoch:96 Training-Error:0.359-> Training-Accuracy:0.869, Test-Error:2.399 -> Test-Accuracy:5.932\n",
            " Epoch:97 Training-Error:0.364-> Training-Accuracy:0.864, Test-Error:2.750 -> Test-Accuracy:6.7744\n",
            " Epoch:98 Training-Error:0.372-> Training-Accuracy:0.849, Test-Error:3.100 -> Test-Accuracy:7.6184\n",
            " Epoch:99 Training-Error:0.350-> Training-Accuracy:0.874, Test-Error:3.425 -> Test-Accuracy:8.4734\n",
            " Epoch:100 Training-Error:0.345-> Training-Accuracy:0.871, Test-Error:0.350 -> Test-Accuracy:0.8389\n",
            " Epoch:101 Training-Error:0.361-> Training-Accuracy:0.864, Test-Error:0.697 -> Test-Accuracy:1.6844\n",
            " Epoch:102 Training-Error:0.360-> Training-Accuracy:0.866, Test-Error:1.031 -> Test-Accuracy:2.5294\n",
            " Epoch:103 Training-Error:0.356-> Training-Accuracy:0.885, Test-Error:1.373 -> Test-Accuracy:3.3754\n",
            " Epoch:104 Training-Error:0.356-> Training-Accuracy:0.869, Test-Error:1.722 -> Test-Accuracy:4.2164\n",
            " Epoch:105 Training-Error:0.361-> Training-Accuracy:0.873, Test-Error:2.063 -> Test-Accuracy:5.0625\n",
            " Epoch:106 Training-Error:0.363-> Training-Accuracy:0.87, Test-Error:2.405 -> Test-Accuracy:5.9137\n",
            " Epoch:107 Training-Error:0.364-> Training-Accuracy:0.87, Test-Error:2.755 -> Test-Accuracy:6.7532\n",
            " Epoch:108 Training-Error:0.342-> Training-Accuracy:0.873, Test-Error:3.103 -> Test-Accuracy:7.5932\n",
            " Epoch:109 Training-Error:0.360-> Training-Accuracy:0.871, Test-Error:3.460 -> Test-Accuracy:8.4268\n",
            " Epoch:110 Training-Error:0.363-> Training-Accuracy:0.85, Test-Error:0.347 -> Test-Accuracy:0.8487\n",
            " Epoch:111 Training-Error:0.365-> Training-Accuracy:0.861, Test-Error:0.686 -> Test-Accuracy:1.6954\n",
            " Epoch:112 Training-Error:0.351-> Training-Accuracy:0.869, Test-Error:1.013 -> Test-Accuracy:2.5433\n",
            " Epoch:113 Training-Error:0.348-> Training-Accuracy:0.867, Test-Error:1.352 -> Test-Accuracy:3.3935\n",
            " Epoch:114 Training-Error:0.352-> Training-Accuracy:0.882, Test-Error:1.696 -> Test-Accuracy:4.2376\n",
            " Epoch:115 Training-Error:0.351-> Training-Accuracy:0.872, Test-Error:2.041 -> Test-Accuracy:5.0846\n",
            " Epoch:116 Training-Error:0.353-> Training-Accuracy:0.866, Test-Error:2.390 -> Test-Accuracy:5.9311\n",
            " Epoch:117 Training-Error:0.353-> Training-Accuracy:0.871, Test-Error:2.744 -> Test-Accuracy:6.7746\n",
            " Epoch:118 Training-Error:0.367-> Training-Accuracy:0.871, Test-Error:3.094 -> Test-Accuracy:7.6159\n",
            " Epoch:119 Training-Error:0.345-> Training-Accuracy:0.884, Test-Error:3.441 -> Test-Accuracy:8.4529\n",
            " Epoch:120 Training-Error:0.352-> Training-Accuracy:0.872, Test-Error:0.341 -> Test-Accuracy:0.8451\n",
            " Epoch:121 Training-Error:0.357-> Training-Accuracy:0.867, Test-Error:0.699 -> Test-Accuracy:1.6815\n",
            " Epoch:122 Training-Error:0.356-> Training-Accuracy:0.866, Test-Error:1.049 -> Test-Accuracy:2.5175\n",
            " Epoch:123 Training-Error:0.356-> Training-Accuracy:0.879, Test-Error:1.399 -> Test-Accuracy:3.3695\n",
            " Epoch:124 Training-Error:0.350-> Training-Accuracy:0.875, Test-Error:1.745 -> Test-Accuracy:4.2089\n",
            " Epoch:125 Training-Error:0.360-> Training-Accuracy:0.869, Test-Error:2.087 -> Test-Accuracy:5.0551\n",
            " Epoch:126 Training-Error:0.362-> Training-Accuracy:0.867, Test-Error:2.437 -> Test-Accuracy:5.9005\n",
            " Epoch:127 Training-Error:0.362-> Training-Accuracy:0.868, Test-Error:2.778 -> Test-Accuracy:6.7479\n",
            " Epoch:128 Training-Error:0.354-> Training-Accuracy:0.867, Test-Error:3.121 -> Test-Accuracy:7.6025\n",
            " Epoch:129 Training-Error:0.359-> Training-Accuracy:0.879, Test-Error:3.469 -> Test-Accuracy:8.4471\n",
            " Epoch:130 Training-Error:0.347-> Training-Accuracy:0.878, Test-Error:0.337 -> Test-Accuracy:0.8445\n",
            " Epoch:131 Training-Error:0.368-> Training-Accuracy:0.857, Test-Error:0.678 -> Test-Accuracy:1.6948\n",
            " Epoch:132 Training-Error:0.339-> Training-Accuracy:0.869, Test-Error:1.021 -> Test-Accuracy:2.5394\n",
            " Epoch:133 Training-Error:0.350-> Training-Accuracy:0.873, Test-Error:1.377 -> Test-Accuracy:3.3854\n",
            " Epoch:134 Training-Error:0.362-> Training-Accuracy:0.874, Test-Error:1.711 -> Test-Accuracy:4.2347\n",
            " Epoch:135 Training-Error:0.357-> Training-Accuracy:0.876, Test-Error:2.065 -> Test-Accuracy:5.0847\n",
            " Epoch:136 Training-Error:0.353-> Training-Accuracy:0.866, Test-Error:2.413 -> Test-Accuracy:5.9277\n",
            " Epoch:137 Training-Error:0.354-> Training-Accuracy:0.871, Test-Error:2.759 -> Test-Accuracy:6.7679\n",
            " Epoch:138 Training-Error:0.364-> Training-Accuracy:0.868, Test-Error:3.103 -> Test-Accuracy:7.6166\n",
            " Epoch:139 Training-Error:0.346-> Training-Accuracy:0.895, Test-Error:3.466 -> Test-Accuracy:8.443\n",
            " Epoch:140 Training-Error:0.356-> Training-Accuracy:0.876, Test-Error:0.345 -> Test-Accuracy:0.8378\n",
            " Epoch:141 Training-Error:0.361-> Training-Accuracy:0.863, Test-Error:0.702 -> Test-Accuracy:1.6689\n",
            " Epoch:142 Training-Error:0.350-> Training-Accuracy:0.882, Test-Error:1.066 -> Test-Accuracy:2.4991\n",
            " Epoch:143 Training-Error:0.366-> Training-Accuracy:0.865, Test-Error:1.430 -> Test-Accuracy:3.3221\n",
            " Epoch:144 Training-Error:0.353-> Training-Accuracy:0.87, Test-Error:1.780 -> Test-Accuracy:4.1608\n",
            " Epoch:145 Training-Error:0.348-> Training-Accuracy:0.874, Test-Error:2.128 -> Test-Accuracy:5.0081\n",
            " Epoch:146 Training-Error:0.359-> Training-Accuracy:0.885, Test-Error:2.478 -> Test-Accuracy:5.8566\n",
            " Epoch:147 Training-Error:0.336-> Training-Accuracy:0.889, Test-Error:2.820 -> Test-Accuracy:6.7103\n",
            " Epoch:148 Training-Error:0.348-> Training-Accuracy:0.874, Test-Error:3.154 -> Test-Accuracy:7.5566\n",
            " Epoch:149 Training-Error:0.363-> Training-Accuracy:0.868, Test-Error:3.493 -> Test-Accuracy:8.4034\n",
            " Epoch:150 Training-Error:0.350-> Training-Accuracy:0.875, Test-Error:0.346 -> Test-Accuracy:0.8445\n",
            " Epoch:151 Training-Error:0.364-> Training-Accuracy:0.88, Test-Error:0.698 -> Test-Accuracy:1.689\n",
            " Epoch:152 Training-Error:0.354-> Training-Accuracy:0.859, Test-Error:1.039 -> Test-Accuracy:2.5277\n",
            " Epoch:153 Training-Error:0.353-> Training-Accuracy:0.875, Test-Error:1.382 -> Test-Accuracy:3.37\n",
            " Epoch:154 Training-Error:0.355-> Training-Accuracy:0.885, Test-Error:1.734 -> Test-Accuracy:4.2091\n",
            " Epoch:155 Training-Error:0.352-> Training-Accuracy:0.882, Test-Error:2.082 -> Test-Accuracy:5.0596\n",
            " Epoch:156 Training-Error:0.351-> Training-Accuracy:0.867, Test-Error:2.429 -> Test-Accuracy:5.9064\n",
            " Epoch:157 Training-Error:0.356-> Training-Accuracy:0.874, Test-Error:2.764 -> Test-Accuracy:6.7542\n",
            " Epoch:158 Training-Error:0.365-> Training-Accuracy:0.867, Test-Error:3.121 -> Test-Accuracy:7.5922\n",
            " Epoch:159 Training-Error:0.349-> Training-Accuracy:0.88, Test-Error:3.466 -> Test-Accuracy:8.4397\n",
            " Epoch:160 Training-Error:0.366-> Training-Accuracy:0.878, Test-Error:0.340 -> Test-Accuracy:0.8469\n",
            " Epoch:161 Training-Error:0.354-> Training-Accuracy:0.877, Test-Error:0.704 -> Test-Accuracy:1.692\n",
            " Epoch:162 Training-Error:0.352-> Training-Accuracy:0.87, Test-Error:1.053 -> Test-Accuracy:2.5262\n",
            " Epoch:163 Training-Error:0.348-> Training-Accuracy:0.871, Test-Error:1.398 -> Test-Accuracy:3.3695\n",
            " Epoch:164 Training-Error:0.356-> Training-Accuracy:0.878, Test-Error:1.734 -> Test-Accuracy:4.2145\n",
            " Epoch:165 Training-Error:0.364-> Training-Accuracy:0.859, Test-Error:2.079 -> Test-Accuracy:5.0736\n",
            " Epoch:166 Training-Error:0.356-> Training-Accuracy:0.88, Test-Error:2.429 -> Test-Accuracy:5.9201\n",
            " Epoch:167 Training-Error:0.363-> Training-Accuracy:0.873, Test-Error:2.804 -> Test-Accuracy:6.7533\n",
            " Epoch:168 Training-Error:0.351-> Training-Accuracy:0.875, Test-Error:3.146 -> Test-Accuracy:7.6012\n",
            " Epoch:169 Training-Error:0.363-> Training-Accuracy:0.866, Test-Error:3.528 -> Test-Accuracy:8.3884\n",
            " Epoch:170 Training-Error:0.362-> Training-Accuracy:0.873, Test-Error:0.350 -> Test-Accuracy:0.8518\n",
            " Epoch:171 Training-Error:0.348-> Training-Accuracy:0.883, Test-Error:0.702 -> Test-Accuracy:1.6883\n",
            " Epoch:172 Training-Error:0.340-> Training-Accuracy:0.886, Test-Error:1.051 -> Test-Accuracy:2.5268\n",
            " Epoch:173 Training-Error:0.347-> Training-Accuracy:0.869, Test-Error:1.400 -> Test-Accuracy:3.3719\n",
            " Epoch:174 Training-Error:0.358-> Training-Accuracy:0.88, Test-Error:1.750 -> Test-Accuracy:4.2107\n",
            " Epoch:175 Training-Error:0.358-> Training-Accuracy:0.868, Test-Error:2.084 -> Test-Accuracy:5.0573\n",
            " Epoch:176 Training-Error:0.360-> Training-Accuracy:0.868, Test-Error:2.456 -> Test-Accuracy:5.8767\n",
            " Epoch:177 Training-Error:0.348-> Training-Accuracy:0.891, Test-Error:2.795 -> Test-Accuracy:6.7131\n",
            " Epoch:178 Training-Error:0.350-> Training-Accuracy:0.88, Test-Error:3.148 -> Test-Accuracy:7.563\n",
            " Epoch:179 Training-Error:0.356-> Training-Accuracy:0.88, Test-Error:3.491 -> Test-Accuracy:8.4049\n",
            " Epoch:180 Training-Error:0.355-> Training-Accuracy:0.88, Test-Error:0.331 -> Test-Accuracy:0.8437\n",
            " Epoch:181 Training-Error:0.358-> Training-Accuracy:0.876, Test-Error:0.688 -> Test-Accuracy:1.6766\n",
            " Epoch:182 Training-Error:0.353-> Training-Accuracy:0.874, Test-Error:1.041 -> Test-Accuracy:2.5146\n",
            " Epoch:183 Training-Error:0.376-> Training-Accuracy:0.88, Test-Error:1.388 -> Test-Accuracy:3.361\n",
            " Epoch:184 Training-Error:0.352-> Training-Accuracy:0.876, Test-Error:1.725 -> Test-Accuracy:4.1953\n",
            " Epoch:185 Training-Error:0.356-> Training-Accuracy:0.875, Test-Error:2.079 -> Test-Accuracy:5.0284\n",
            " Epoch:186 Training-Error:0.349-> Training-Accuracy:0.883, Test-Error:2.429 -> Test-Accuracy:5.8611\n",
            " Epoch:187 Training-Error:0.371-> Training-Accuracy:0.866, Test-Error:2.779 -> Test-Accuracy:6.7001\n",
            " Epoch:188 Training-Error:0.363-> Training-Accuracy:0.864, Test-Error:3.120 -> Test-Accuracy:7.5441\n",
            " Epoch:189 Training-Error:0.349-> Training-Accuracy:0.871, Test-Error:3.473 -> Test-Accuracy:8.3763\n",
            " Epoch:190 Training-Error:0.347-> Training-Accuracy:0.884, Test-Error:0.349 -> Test-Accuracy:0.841\n",
            " Epoch:191 Training-Error:0.363-> Training-Accuracy:0.867, Test-Error:0.707 -> Test-Accuracy:1.6772\n",
            " Epoch:192 Training-Error:0.351-> Training-Accuracy:0.878, Test-Error:1.042 -> Test-Accuracy:2.5195\n",
            " Epoch:193 Training-Error:0.359-> Training-Accuracy:0.882, Test-Error:1.386 -> Test-Accuracy:3.3628\n",
            " Epoch:194 Training-Error:0.355-> Training-Accuracy:0.875, Test-Error:1.748 -> Test-Accuracy:4.2036\n",
            " Epoch:195 Training-Error:0.370-> Training-Accuracy:0.869, Test-Error:2.102 -> Test-Accuracy:5.0369\n",
            " Epoch:196 Training-Error:0.346-> Training-Accuracy:0.883, Test-Error:2.465 -> Test-Accuracy:5.8708\n",
            " Epoch:197 Training-Error:0.352-> Training-Accuracy:0.878, Test-Error:2.836 -> Test-Accuracy:6.6824\n",
            " Epoch:198 Training-Error:0.360-> Training-Accuracy:0.869, Test-Error:3.185 -> Test-Accuracy:7.5218\n",
            " Epoch:199 Training-Error:0.347-> Training-Accuracy:0.889, Test-Error:3.538 -> Test-Accuracy:8.3651\n",
            " Epoch:200 Training-Error:0.362-> Training-Accuracy:0.87, Test-Error:0.375 -> Test-Accuracy:0.7865\n",
            " Epoch:201 Training-Error:0.358-> Training-Accuracy:0.861, Test-Error:0.747 -> Test-Accuracy:1.592\n",
            " Epoch:202 Training-Error:0.359-> Training-Accuracy:0.882, Test-Error:1.105 -> Test-Accuracy:2.4278\n",
            " Epoch:203 Training-Error:0.355-> Training-Accuracy:0.866, Test-Error:1.459 -> Test-Accuracy:3.2638\n",
            " Epoch:204 Training-Error:0.361-> Training-Accuracy:0.867, Test-Error:1.819 -> Test-Accuracy:4.1022\n",
            " Epoch:205 Training-Error:0.358-> Training-Accuracy:0.873, Test-Error:2.159 -> Test-Accuracy:4.9497\n",
            " Epoch:206 Training-Error:0.357-> Training-Accuracy:0.871, Test-Error:2.521 -> Test-Accuracy:5.7744\n",
            " Epoch:207 Training-Error:0.343-> Training-Accuracy:0.88, Test-Error:2.897 -> Test-Accuracy:6.577\n",
            " Epoch:208 Training-Error:0.360-> Training-Accuracy:0.877, Test-Error:3.257 -> Test-Accuracy:7.4188\n",
            " Epoch:209 Training-Error:0.356-> Training-Accuracy:0.876, Test-Error:3.615 -> Test-Accuracy:8.2642\n",
            " Epoch:210 Training-Error:0.371-> Training-Accuracy:0.866, Test-Error:0.350 -> Test-Accuracy:0.8375\n",
            " Epoch:211 Training-Error:0.356-> Training-Accuracy:0.882, Test-Error:0.729 -> Test-Accuracy:1.6531\n",
            " Epoch:212 Training-Error:0.353-> Training-Accuracy:0.882, Test-Error:1.069 -> Test-Accuracy:2.4958\n",
            " Epoch:213 Training-Error:0.360-> Training-Accuracy:0.89, Test-Error:1.415 -> Test-Accuracy:3.3377\n",
            " Epoch:214 Training-Error:0.351-> Training-Accuracy:0.867, Test-Error:1.767 -> Test-Accuracy:4.1638\n",
            " Epoch:215 Training-Error:0.354-> Training-Accuracy:0.876, Test-Error:2.110 -> Test-Accuracy:5.0068\n",
            " Epoch:216 Training-Error:0.365-> Training-Accuracy:0.871, Test-Error:2.464 -> Test-Accuracy:5.841\n",
            " Epoch:217 Training-Error:0.351-> Training-Accuracy:0.879, Test-Error:2.816 -> Test-Accuracy:6.6751\n",
            " Epoch:218 Training-Error:0.363-> Training-Accuracy:0.873, Test-Error:3.221 -> Test-Accuracy:7.4536\n",
            " Epoch:219 Training-Error:0.344-> Training-Accuracy:0.881, Test-Error:3.574 -> Test-Accuracy:8.2935\n",
            " Epoch:220 Training-Error:0.345-> Training-Accuracy:0.879, Test-Error:0.354 -> Test-Accuracy:0.8274\n",
            " Epoch:221 Training-Error:0.335-> Training-Accuracy:0.868, Test-Error:0.693 -> Test-Accuracy:1.6725\n",
            " Epoch:222 Training-Error:0.354-> Training-Accuracy:0.875, Test-Error:1.037 -> Test-Accuracy:2.5076\n",
            " Epoch:223 Training-Error:0.351-> Training-Accuracy:0.881, Test-Error:1.392 -> Test-Accuracy:3.3585\n",
            " Epoch:224 Training-Error:0.351-> Training-Accuracy:0.883, Test-Error:1.750 -> Test-Accuracy:4.1892\n",
            " Epoch:225 Training-Error:0.370-> Training-Accuracy:0.869, Test-Error:2.106 -> Test-Accuracy:5.0429\n",
            " Epoch:226 Training-Error:0.350-> Training-Accuracy:0.879, Test-Error:2.460 -> Test-Accuracy:5.8836\n",
            " Epoch:227 Training-Error:0.361-> Training-Accuracy:0.874, Test-Error:2.808 -> Test-Accuracy:6.7298\n",
            " Epoch:228 Training-Error:0.359-> Training-Accuracy:0.879, Test-Error:3.207 -> Test-Accuracy:7.5144\n",
            " Epoch:229 Training-Error:0.353-> Training-Accuracy:0.872, Test-Error:3.577 -> Test-Accuracy:8.348\n",
            " Epoch:230 Training-Error:0.346-> Training-Accuracy:0.884, Test-Error:0.359 -> Test-Accuracy:0.8438\n",
            " Epoch:231 Training-Error:0.356-> Training-Accuracy:0.881, Test-Error:0.705 -> Test-Accuracy:1.6945\n",
            " Epoch:232 Training-Error:0.337-> Training-Accuracy:0.901, Test-Error:1.049 -> Test-Accuracy:2.5437\n",
            " Epoch:233 Training-Error:0.345-> Training-Accuracy:0.878, Test-Error:1.401 -> Test-Accuracy:3.3808\n",
            " Epoch:234 Training-Error:0.375-> Training-Accuracy:0.859, Test-Error:1.765 -> Test-Accuracy:4.2154\n",
            " Epoch:235 Training-Error:0.350-> Training-Accuracy:0.867, Test-Error:2.100 -> Test-Accuracy:5.0551\n",
            " Epoch:236 Training-Error:0.365-> Training-Accuracy:0.877, Test-Error:2.492 -> Test-Accuracy:5.8491\n",
            " Epoch:237 Training-Error:0.357-> Training-Accuracy:0.871, Test-Error:2.849 -> Test-Accuracy:6.6811\n",
            " Epoch:238 Training-Error:0.367-> Training-Accuracy:0.864, Test-Error:3.208 -> Test-Accuracy:7.5257\n",
            " Epoch:239 Training-Error:0.361-> Training-Accuracy:0.875, Test-Error:3.558 -> Test-Accuracy:8.3699\n",
            " Epoch:240 Training-Error:0.366-> Training-Accuracy:0.851, Test-Error:0.423 -> Test-Accuracy:0.7602\n",
            " Epoch:241 Training-Error:0.356-> Training-Accuracy:0.887, Test-Error:0.784 -> Test-Accuracy:1.5868\n",
            " Epoch:242 Training-Error:0.351-> Training-Accuracy:0.876, Test-Error:1.162 -> Test-Accuracy:2.3956\n",
            " Epoch:243 Training-Error:0.360-> Training-Accuracy:0.87, Test-Error:1.502 -> Test-Accuracy:3.2391\n",
            " Epoch:244 Training-Error:0.356-> Training-Accuracy:0.876, Test-Error:1.856 -> Test-Accuracy:4.0745\n",
            " Epoch:245 Training-Error:0.362-> Training-Accuracy:0.861, Test-Error:2.206 -> Test-Accuracy:4.9263\n",
            " Epoch:246 Training-Error:0.355-> Training-Accuracy:0.88, Test-Error:2.562 -> Test-Accuracy:5.759\n",
            " Epoch:247 Training-Error:0.367-> Training-Accuracy:0.879, Test-Error:2.928 -> Test-Accuracy:6.5897\n",
            " Epoch:248 Training-Error:0.347-> Training-Accuracy:0.874, Test-Error:3.286 -> Test-Accuracy:7.4306\n",
            " Epoch:249 Training-Error:0.353-> Training-Accuracy:0.873, Test-Error:3.670 -> Test-Accuracy:8.227\n",
            " Epoch:250 Training-Error:0.354-> Training-Accuracy:0.889, Test-Error:0.351 -> Test-Accuracy:0.8468\n",
            " Epoch:251 Training-Error:0.341-> Training-Accuracy:0.87, Test-Error:0.715 -> Test-Accuracy:1.669\n",
            " Epoch:252 Training-Error:0.364-> Training-Accuracy:0.873, Test-Error:1.084 -> Test-Accuracy:2.4918\n",
            " Epoch:253 Training-Error:0.344-> Training-Accuracy:0.891, Test-Error:1.437 -> Test-Accuracy:3.3365\n",
            " Epoch:254 Training-Error:0.361-> Training-Accuracy:0.873, Test-Error:1.796 -> Test-Accuracy:4.1744\n",
            " Epoch:255 Training-Error:0.347-> Training-Accuracy:0.879, Test-Error:2.174 -> Test-Accuracy:4.9703\n",
            " Epoch:256 Training-Error:0.357-> Training-Accuracy:0.877, Test-Error:2.524 -> Test-Accuracy:5.816\n",
            " Epoch:257 Training-Error:0.363-> Training-Accuracy:0.873, Test-Error:2.870 -> Test-Accuracy:6.6566\n",
            " Epoch:258 Training-Error:0.364-> Training-Accuracy:0.873, Test-Error:3.234 -> Test-Accuracy:7.4916\n",
            " Epoch:259 Training-Error:0.339-> Training-Accuracy:0.88, Test-Error:3.588 -> Test-Accuracy:8.3247\n",
            " Epoch:260 Training-Error:0.366-> Training-Accuracy:0.88, Test-Error:0.362 -> Test-Accuracy:0.8296\n",
            " Epoch:261 Training-Error:0.366-> Training-Accuracy:0.875, Test-Error:0.720 -> Test-Accuracy:1.667\n",
            " Epoch:262 Training-Error:0.355-> Training-Accuracy:0.881, Test-Error:1.081 -> Test-Accuracy:2.5061\n",
            " Epoch:263 Training-Error:0.352-> Training-Accuracy:0.881, Test-Error:1.430 -> Test-Accuracy:3.3427\n",
            " Epoch:264 Training-Error:0.341-> Training-Accuracy:0.885, Test-Error:1.779 -> Test-Accuracy:4.1902\n",
            " Epoch:265 Training-Error:0.342-> Training-Accuracy:0.885, Test-Error:2.130 -> Test-Accuracy:5.0335\n",
            " Epoch:266 Training-Error:0.340-> Training-Accuracy:0.88, Test-Error:2.488 -> Test-Accuracy:5.8671\n",
            " Epoch:267 Training-Error:0.345-> Training-Accuracy:0.882, Test-Error:2.838 -> Test-Accuracy:6.7129\n",
            " Epoch:268 Training-Error:0.348-> Training-Accuracy:0.889, Test-Error:3.195 -> Test-Accuracy:7.5528\n",
            " Epoch:269 Training-Error:0.368-> Training-Accuracy:0.87, Test-Error:3.558 -> Test-Accuracy:8.3727\n",
            " Epoch:270 Training-Error:0.352-> Training-Accuracy:0.884, Test-Error:0.340 -> Test-Accuracy:0.8426\n",
            " Epoch:271 Training-Error:0.362-> Training-Accuracy:0.875, Test-Error:0.696 -> Test-Accuracy:1.6714\n",
            " Epoch:272 Training-Error:0.375-> Training-Accuracy:0.874, Test-Error:1.058 -> Test-Accuracy:2.5011\n",
            " Epoch:273 Training-Error:0.354-> Training-Accuracy:0.879, Test-Error:1.420 -> Test-Accuracy:3.311\n",
            " Epoch:274 Training-Error:0.363-> Training-Accuracy:0.879, Test-Error:1.774 -> Test-Accuracy:4.1437\n",
            " Epoch:275 Training-Error:0.357-> Training-Accuracy:0.881, Test-Error:2.152 -> Test-Accuracy:4.9604\n",
            " Epoch:276 Training-Error:0.366-> Training-Accuracy:0.878, Test-Error:2.526 -> Test-Accuracy:5.7598\n",
            " Epoch:277 Training-Error:0.370-> Training-Accuracy:0.875, Test-Error:2.888 -> Test-Accuracy:6.6055\n",
            " Epoch:278 Training-Error:0.373-> Training-Accuracy:0.871, Test-Error:3.237 -> Test-Accuracy:7.4475\n",
            " Epoch:279 Training-Error:0.357-> Training-Accuracy:0.883, Test-Error:3.588 -> Test-Accuracy:8.2875\n",
            " Epoch:280 Training-Error:0.372-> Training-Accuracy:0.876, Test-Error:0.390 -> Test-Accuracy:0.8039\n",
            " Epoch:281 Training-Error:0.366-> Training-Accuracy:0.865, Test-Error:0.764 -> Test-Accuracy:1.6294\n",
            " Epoch:282 Training-Error:0.348-> Training-Accuracy:0.887, Test-Error:1.161 -> Test-Accuracy:2.3885\n",
            " Epoch:283 Training-Error:0.356-> Training-Accuracy:0.889, Test-Error:1.521 -> Test-Accuracy:3.2228\n",
            " Epoch:284 Training-Error:0.348-> Training-Accuracy:0.882, Test-Error:1.865 -> Test-Accuracy:4.0599\n",
            " Epoch:285 Training-Error:0.339-> Training-Accuracy:0.886, Test-Error:2.215 -> Test-Accuracy:4.9028\n",
            " Epoch:286 Training-Error:0.364-> Training-Accuracy:0.888, Test-Error:2.564 -> Test-Accuracy:5.7475\n",
            " Epoch:287 Training-Error:0.367-> Training-Accuracy:0.874, Test-Error:2.947 -> Test-Accuracy:6.5536\n",
            " Epoch:288 Training-Error:0.359-> Training-Accuracy:0.884, Test-Error:3.298 -> Test-Accuracy:7.3945\n",
            " Epoch:289 Training-Error:0.363-> Training-Accuracy:0.882, Test-Error:3.656 -> Test-Accuracy:8.2302\n",
            " Epoch:290 Training-Error:0.361-> Training-Accuracy:0.89, Test-Error:0.358 -> Test-Accuracy:0.8409\n",
            " Epoch:291 Training-Error:0.350-> Training-Accuracy:0.884, Test-Error:0.713 -> Test-Accuracy:1.6939\n",
            " Epoch:292 Training-Error:0.353-> Training-Accuracy:0.888, Test-Error:1.062 -> Test-Accuracy:2.5277\n",
            " Epoch:293 Training-Error:0.365-> Training-Accuracy:0.877, Test-Error:1.412 -> Test-Accuracy:3.3662\n",
            " Epoch:294 Training-Error:0.364-> Training-Accuracy:0.868, Test-Error:1.764 -> Test-Accuracy:4.2074\n",
            " Epoch:295 Training-Error:0.364-> Training-Accuracy:0.876, Test-Error:2.125 -> Test-Accuracy:5.0475\n",
            " Epoch:296 Training-Error:0.356-> Training-Accuracy:0.878, Test-Error:2.478 -> Test-Accuracy:5.8844\n",
            " Epoch:297 Training-Error:0.371-> Training-Accuracy:0.877, Test-Error:2.839 -> Test-Accuracy:6.7015\n",
            " Epoch:298 Training-Error:0.359-> Training-Accuracy:0.875, Test-Error:3.190 -> Test-Accuracy:7.5447\n",
            " Epoch:299 Training-Error:0.342-> Training-Accuracy:0.883, Test-Error:0.413 -> Test-Accuracy:0.8065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnluE-gFBhlD"
      },
      "source": [
        "# **Adding Minibatch Gradient Descent (minibatch=64, lr=0.005) and experimented learning rate from 0.001 to 0.005**\n",
        "\n",
        "First run (minibatch =128, lr=0.001):\n",
        "\n",
        "Epoch:299 Training-Error:0.712-> Training-Accuracy:0.46, Test-Error:0.652 -> Test-Accuracy:0.6435\n",
        "\n",
        "Second run (minibatch =64, lr=0.001):\n",
        "\n",
        "Epoch:299 Training-Error:0.625-> Training-Accuracy:0.611, Test-Error:0.575 -> Test-Accuracy:0.7148\n",
        "\n",
        "Third run (minibatch=64, lr=0.005):\n",
        "\n",
        "Epoch:299 Training-Error:0.453-> Training-Accuracy:0.747, Test-Error:0.441 -> Test-Accuracy:0.8012\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCyxV6e1eBPU"
      },
      "source": [
        "### Load the MNIST digit dataset using (1000,28x28)/255 shape size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCGej8xmeBPZ"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "digits, labels = (X_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goWJp17yeGgO"
      },
      "source": [
        "### Do One Hot Encoding of Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7NeSNMteGgP"
      },
      "source": [
        "encode_labels = np.zeros((len(labels),10))\n",
        "\n",
        "## For Loop enumerating the encoded labels\n",
        "for i,l in enumerate(labels):\n",
        "    encode_labels[i][l] = 1\n",
        "labels = encode_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4FiJXW0eKTy"
      },
      "source": [
        "### Reshape the digits image in 3Dimension H=28px, W=28px, canal = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83NZ0oKReKTz"
      },
      "source": [
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "X_test = X_test.reshape(-1,28,28,1)\n",
        "\n",
        "# Reshape the test dataset to a one channel\n",
        "test_digits = X_test.reshape(len(X_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcSfTDjQewyR"
      },
      "source": [
        "### **Perform Grayscale Normalization of the data prior training **\n",
        "\n",
        "F. The code should normalize the input as discussed in the class before training (scaling the input)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQUC-jXzewyS"
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f-Mx3eVemqo"
      },
      "source": [
        "### Neural Nets Training with Minibatch Gradient Descent\n",
        "\n",
        "First run (minibatch =128, lr=0.001):\n",
        "\n",
        "Epoch:299 Training-Error:0.712-> Training-Accuracy:0.46, Test-Error:0.652 -> Test-Accuracy:0.6435\n",
        "\n",
        "Second run (minibatch =64, lr=0.001):\n",
        "\n",
        "Epoch:299 Training-Error:0.625-> Training-Accuracy:0.611, Test-Error:0.575 -> Test-Accuracy:0.7148\n",
        "\n",
        "Third run (minibatch =64, lr=0.005):\n",
        "\n",
        "Epoch:299 Training-Error:0.453-> Training-Accuracy:0.747, Test-Error:0.441 -> Test-Accuracy:0.8012\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP0rjx7oWjC6",
        "outputId": "0bf0842f-f9e0-4750-f238-c76bf8246da1"
      },
      "source": [
        "import numpy, sys\n",
        "np.random.seed(1)\n",
        "\n",
        "#Activation Function\n",
        "def Relu(x):\n",
        "    # returns x if x > 0\n",
        "    return ( x >= 0 ) * x\n",
        "\n",
        "def Relu_derivative(output):\n",
        "    # returns 1 for input > 0\n",
        "    return output >= 0 \n",
        "\n",
        "# Initialize Batch size\n",
        "minibatch = 64\n",
        "\n",
        "# Initialize and change parameters learning rate ( 0.005 ~ 0.001)\n",
        "lr, epoch, hidden_size, = (0.005, 300, 100)\n",
        "pixels, numLabels = (784, 10)\n",
        "\n",
        "weights0_1 = 0.2*np.random.random((pixels, hidden_size)) - 0.1\n",
        "weights1_2 = 0.2*np.random.random((hidden_size, numLabels)) - 0.1\n",
        "\n",
        "for j in range(epoch):\n",
        "    error, correctCnt = (0.0, 0)\n",
        "\n",
        "    # Feed forward through layers 0, 1, and 2 ( 3 layers) with minibatch\n",
        "    for i in range(int(len(digits) / minibatch)):\n",
        "        minibatch_start, minibatch_end = ((i * minibatch), ((i+1)*minibatch))\n",
        "\n",
        "        layer_0 = digits[minibatch_start:minibatch_end]\n",
        "        layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "\n",
        "        # Adding Dropout\n",
        "        dropOut_mask = np.random.randint(2, size=layer_1.shape)\n",
        "\n",
        "        layer_1 *= dropOut_mask * 2\n",
        "        layer_2 = np.dot(layer_1, weights1_2)  \n",
        "\n",
        "    # How much did we miss the target value(error)? with minibatch\n",
        "        error += np.sum((labels[minibatch_start:minibatch_end] - layer_2) ** 2)\n",
        "        for k in range(minibatch):\n",
        "            correctCnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[minibatch_start+k:minibatch_start+k+1]))\n",
        "            # correctCnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "\n",
        "    # Compute the gradient descent using relu activation function with minibatch\n",
        "        layer_2_deltaChange = (labels[minibatch_start:minibatch_end] - layer_2) / minibatch\n",
        "        layer_1_deltaChange = layer_2_deltaChange.dot(weights1_2.T) * Relu_derivative(layer_1)\n",
        "\n",
        "    # Adding DropOut\n",
        "        layer_1_deltaChange *+ dropOut_mask\n",
        "\n",
        "    # Updating the weights \n",
        "        weights1_2 += lr * layer_1.T.dot(layer_2_deltaChange)\n",
        "        weights0_1 += lr * layer_0.T.dot(layer_1_deltaChange)\n",
        "\n",
        "    # Test Digits Sample\n",
        "    if(j % 10 == 0 or j == epoch-1):\n",
        "        testError, testCorrectcnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(test_digits)):\n",
        "        # Feed forward through layers 0, 1, and 2 ( 3 layers) for test MNIST digit samples\n",
        "        layer_0 = test_digits[i:i+1]\n",
        "        layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "        layer_2 = np.dot(layer_1,weights1_2)\n",
        "\n",
        "        # how much did we miss the target value(error)?\n",
        "        testError += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "        testCorrectcnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "      \n",
        "\n",
        "    print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \"-> Training-Accuracy:\" + str(correctCnt/float(len(digits))) + \\\n",
        "          \", Test-Error:\" + str(testError/float(len(test_digits)))[0:5] + \" -> Test-Accuracy:\" + str(testCorrectcnt/float(len(test_digits))))\n",
        "    # print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \", Training-Accuracy:\" + str(correctCnt/float(len(digits))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch:0 Training-Error:1.722-> Training-Accuracy:0.081, Test-Error:1.134 -> Test-Accuracy:0.1119\n",
            " Epoch:1 Training-Error:1.439-> Training-Accuracy:0.104, Test-Error:2.166 -> Test-Accuracy:0.2711\n",
            " Epoch:2 Training-Error:1.332-> Training-Accuracy:0.152, Test-Error:3.148 -> Test-Accuracy:0.4721\n",
            " Epoch:3 Training-Error:1.277-> Training-Accuracy:0.146, Test-Error:4.091 -> Test-Accuracy:0.7134\n",
            " Epoch:4 Training-Error:1.189-> Training-Accuracy:0.183, Test-Error:5.003 -> Test-Accuracy:0.9908\n",
            " Epoch:5 Training-Error:1.139-> Training-Accuracy:0.206, Test-Error:5.888 -> Test-Accuracy:1.3057\n",
            " Epoch:6 Training-Error:1.116-> Training-Accuracy:0.21, Test-Error:6.748 -> Test-Accuracy:1.657\n",
            " Epoch:7 Training-Error:1.088-> Training-Accuracy:0.241, Test-Error:7.585 -> Test-Accuracy:2.0361\n",
            " Epoch:8 Training-Error:1.054-> Training-Accuracy:0.254, Test-Error:8.405 -> Test-Accuracy:2.4366\n",
            " Epoch:9 Training-Error:1.020-> Training-Accuracy:0.295, Test-Error:9.208 -> Test-Accuracy:2.8661\n",
            " Epoch:10 Training-Error:0.998-> Training-Accuracy:0.31, Test-Error:0.787 -> Test-Accuracy:0.4529\n",
            " Epoch:11 Training-Error:0.980-> Training-Accuracy:0.293, Test-Error:1.560 -> Test-Accuracy:0.9272\n",
            " Epoch:12 Training-Error:0.944-> Training-Accuracy:0.31, Test-Error:2.320 -> Test-Accuracy:1.4187\n",
            " Epoch:13 Training-Error:0.938-> Training-Accuracy:0.333, Test-Error:3.070 -> Test-Accuracy:1.9271\n",
            " Epoch:14 Training-Error:0.921-> Training-Accuracy:0.331, Test-Error:3.808 -> Test-Accuracy:2.4497\n",
            " Epoch:15 Training-Error:0.896-> Training-Accuracy:0.364, Test-Error:4.537 -> Test-Accuracy:2.9852\n",
            " Epoch:16 Training-Error:0.874-> Training-Accuracy:0.403, Test-Error:5.257 -> Test-Accuracy:3.5391\n",
            " Epoch:17 Training-Error:0.874-> Training-Accuracy:0.397, Test-Error:5.969 -> Test-Accuracy:4.1045\n",
            " Epoch:18 Training-Error:0.840-> Training-Accuracy:0.411, Test-Error:6.673 -> Test-Accuracy:4.6754\n",
            " Epoch:19 Training-Error:0.832-> Training-Accuracy:0.429, Test-Error:7.370 -> Test-Accuracy:5.258\n",
            " Epoch:20 Training-Error:0.833-> Training-Accuracy:0.432, Test-Error:0.691 -> Test-Accuracy:0.5934\n",
            " Epoch:21 Training-Error:0.813-> Training-Accuracy:0.449, Test-Error:1.375 -> Test-Accuracy:1.1932\n",
            " Epoch:22 Training-Error:0.817-> Training-Accuracy:0.429, Test-Error:2.054 -> Test-Accuracy:1.7989\n",
            " Epoch:23 Training-Error:0.798-> Training-Accuracy:0.474, Test-Error:2.727 -> Test-Accuracy:2.4128\n",
            " Epoch:24 Training-Error:0.795-> Training-Accuracy:0.501, Test-Error:3.396 -> Test-Accuracy:3.0347\n",
            " Epoch:25 Training-Error:0.771-> Training-Accuracy:0.488, Test-Error:4.060 -> Test-Accuracy:3.6631\n",
            " Epoch:26 Training-Error:0.774-> Training-Accuracy:0.475, Test-Error:4.719 -> Test-Accuracy:4.2976\n",
            " Epoch:27 Training-Error:0.772-> Training-Accuracy:0.498, Test-Error:5.373 -> Test-Accuracy:4.9362\n",
            " Epoch:28 Training-Error:0.754-> Training-Accuracy:0.534, Test-Error:6.024 -> Test-Accuracy:5.5807\n",
            " Epoch:29 Training-Error:0.756-> Training-Accuracy:0.501, Test-Error:6.671 -> Test-Accuracy:6.2296\n",
            " Epoch:30 Training-Error:0.736-> Training-Accuracy:0.527, Test-Error:0.642 -> Test-Accuracy:0.6537\n",
            " Epoch:31 Training-Error:0.740-> Training-Accuracy:0.517, Test-Error:1.281 -> Test-Accuracy:1.3086\n",
            " Epoch:32 Training-Error:0.732-> Training-Accuracy:0.546, Test-Error:1.917 -> Test-Accuracy:1.9663\n",
            " Epoch:33 Training-Error:0.725-> Training-Accuracy:0.528, Test-Error:2.549 -> Test-Accuracy:2.6315\n",
            " Epoch:34 Training-Error:0.717-> Training-Accuracy:0.538, Test-Error:3.178 -> Test-Accuracy:3.2998\n",
            " Epoch:35 Training-Error:0.717-> Training-Accuracy:0.553, Test-Error:3.804 -> Test-Accuracy:3.97\n",
            " Epoch:36 Training-Error:0.698-> Training-Accuracy:0.547, Test-Error:4.428 -> Test-Accuracy:4.6429\n",
            " Epoch:37 Training-Error:0.702-> Training-Accuracy:0.571, Test-Error:5.048 -> Test-Accuracy:5.3184\n",
            " Epoch:38 Training-Error:0.706-> Training-Accuracy:0.55, Test-Error:5.666 -> Test-Accuracy:5.9966\n",
            " Epoch:39 Training-Error:0.692-> Training-Accuracy:0.574, Test-Error:6.281 -> Test-Accuracy:6.6766\n",
            " Epoch:40 Training-Error:0.689-> Training-Accuracy:0.575, Test-Error:0.612 -> Test-Accuracy:0.6814\n",
            " Epoch:41 Training-Error:0.682-> Training-Accuracy:0.581, Test-Error:1.222 -> Test-Accuracy:1.3666\n",
            " Epoch:42 Training-Error:0.688-> Training-Accuracy:0.584, Test-Error:1.830 -> Test-Accuracy:2.0536\n",
            " Epoch:43 Training-Error:0.674-> Training-Accuracy:0.595, Test-Error:2.435 -> Test-Accuracy:2.7429\n",
            " Epoch:44 Training-Error:0.676-> Training-Accuracy:0.586, Test-Error:3.038 -> Test-Accuracy:3.4344\n",
            " Epoch:45 Training-Error:0.661-> Training-Accuracy:0.593, Test-Error:3.639 -> Test-Accuracy:4.124\n",
            " Epoch:46 Training-Error:0.663-> Training-Accuracy:0.6, Test-Error:4.238 -> Test-Accuracy:4.8182\n",
            " Epoch:47 Training-Error:0.658-> Training-Accuracy:0.595, Test-Error:4.834 -> Test-Accuracy:5.5157\n",
            " Epoch:48 Training-Error:0.657-> Training-Accuracy:0.601, Test-Error:5.429 -> Test-Accuracy:6.2141\n",
            " Epoch:49 Training-Error:0.654-> Training-Accuracy:0.604, Test-Error:6.022 -> Test-Accuracy:6.9133\n",
            " Epoch:50 Training-Error:0.649-> Training-Accuracy:0.608, Test-Error:0.591 -> Test-Accuracy:0.7003\n",
            " Epoch:51 Training-Error:0.641-> Training-Accuracy:0.634, Test-Error:1.179 -> Test-Accuracy:1.4053\n",
            " Epoch:52 Training-Error:0.652-> Training-Accuracy:0.603, Test-Error:1.766 -> Test-Accuracy:2.1107\n",
            " Epoch:53 Training-Error:0.647-> Training-Accuracy:0.585, Test-Error:2.351 -> Test-Accuracy:2.8171\n",
            " Epoch:54 Training-Error:0.646-> Training-Accuracy:0.61, Test-Error:2.935 -> Test-Accuracy:3.5248\n",
            " Epoch:55 Training-Error:0.635-> Training-Accuracy:0.629, Test-Error:3.516 -> Test-Accuracy:4.2356\n",
            " Epoch:56 Training-Error:0.640-> Training-Accuracy:0.6, Test-Error:4.097 -> Test-Accuracy:4.9473\n",
            " Epoch:57 Training-Error:0.637-> Training-Accuracy:0.613, Test-Error:4.675 -> Test-Accuracy:5.6583\n",
            " Epoch:58 Training-Error:0.628-> Training-Accuracy:0.63, Test-Error:5.253 -> Test-Accuracy:6.3699\n",
            " Epoch:59 Training-Error:0.628-> Training-Accuracy:0.624, Test-Error:5.828 -> Test-Accuracy:7.0843\n",
            " Epoch:60 Training-Error:0.624-> Training-Accuracy:0.642, Test-Error:0.574 -> Test-Accuracy:0.7166\n",
            " Epoch:61 Training-Error:0.626-> Training-Accuracy:0.633, Test-Error:1.147 -> Test-Accuracy:1.4343\n",
            " Epoch:62 Training-Error:0.621-> Training-Accuracy:0.635, Test-Error:1.718 -> Test-Accuracy:2.1518\n",
            " Epoch:63 Training-Error:0.628-> Training-Accuracy:0.619, Test-Error:2.288 -> Test-Accuracy:2.8699\n",
            " Epoch:64 Training-Error:0.622-> Training-Accuracy:0.637, Test-Error:2.857 -> Test-Accuracy:3.5899\n",
            " Epoch:65 Training-Error:0.616-> Training-Accuracy:0.63, Test-Error:3.424 -> Test-Accuracy:4.3107\n",
            " Epoch:66 Training-Error:0.618-> Training-Accuracy:0.628, Test-Error:3.990 -> Test-Accuracy:5.0336\n",
            " Epoch:67 Training-Error:0.608-> Training-Accuracy:0.642, Test-Error:4.555 -> Test-Accuracy:5.7552\n",
            " Epoch:68 Training-Error:0.608-> Training-Accuracy:0.633, Test-Error:5.118 -> Test-Accuracy:6.4788\n",
            " Epoch:69 Training-Error:0.598-> Training-Accuracy:0.647, Test-Error:5.680 -> Test-Accuracy:7.2039\n",
            " Epoch:70 Training-Error:0.601-> Training-Accuracy:0.646, Test-Error:0.560 -> Test-Accuracy:0.7252\n",
            " Epoch:71 Training-Error:0.608-> Training-Accuracy:0.644, Test-Error:1.120 -> Test-Accuracy:1.4518\n",
            " Epoch:72 Training-Error:0.597-> Training-Accuracy:0.652, Test-Error:1.678 -> Test-Accuracy:2.1776\n",
            " Epoch:73 Training-Error:0.598-> Training-Accuracy:0.661, Test-Error:2.235 -> Test-Accuracy:2.9053\n",
            " Epoch:74 Training-Error:0.593-> Training-Accuracy:0.662, Test-Error:2.791 -> Test-Accuracy:3.6344\n",
            " Epoch:75 Training-Error:0.598-> Training-Accuracy:0.632, Test-Error:3.346 -> Test-Accuracy:4.3641\n",
            " Epoch:76 Training-Error:0.593-> Training-Accuracy:0.666, Test-Error:3.900 -> Test-Accuracy:5.0956\n",
            " Epoch:77 Training-Error:0.587-> Training-Accuracy:0.669, Test-Error:4.452 -> Test-Accuracy:5.83\n",
            " Epoch:78 Training-Error:0.592-> Training-Accuracy:0.655, Test-Error:5.003 -> Test-Accuracy:6.5637\n",
            " Epoch:79 Training-Error:0.584-> Training-Accuracy:0.662, Test-Error:5.553 -> Test-Accuracy:7.298\n",
            " Epoch:80 Training-Error:0.576-> Training-Accuracy:0.673, Test-Error:0.548 -> Test-Accuracy:0.7346\n",
            " Epoch:81 Training-Error:0.590-> Training-Accuracy:0.666, Test-Error:1.096 -> Test-Accuracy:1.4704\n",
            " Epoch:82 Training-Error:0.583-> Training-Accuracy:0.666, Test-Error:1.642 -> Test-Accuracy:2.2066\n",
            " Epoch:83 Training-Error:0.589-> Training-Accuracy:0.644, Test-Error:2.187 -> Test-Accuracy:2.9431\n",
            " Epoch:84 Training-Error:0.578-> Training-Accuracy:0.667, Test-Error:2.732 -> Test-Accuracy:3.6803\n",
            " Epoch:85 Training-Error:0.577-> Training-Accuracy:0.671, Test-Error:3.275 -> Test-Accuracy:4.4171\n",
            " Epoch:86 Training-Error:0.580-> Training-Accuracy:0.653, Test-Error:3.817 -> Test-Accuracy:5.1543\n",
            " Epoch:87 Training-Error:0.585-> Training-Accuracy:0.653, Test-Error:4.358 -> Test-Accuracy:5.8927\n",
            " Epoch:88 Training-Error:0.578-> Training-Accuracy:0.669, Test-Error:4.898 -> Test-Accuracy:6.6315\n",
            " Epoch:89 Training-Error:0.569-> Training-Accuracy:0.672, Test-Error:5.438 -> Test-Accuracy:7.3704\n",
            " Epoch:90 Training-Error:0.569-> Training-Accuracy:0.675, Test-Error:0.538 -> Test-Accuracy:0.7391\n",
            " Epoch:91 Training-Error:0.570-> Training-Accuracy:0.682, Test-Error:1.076 -> Test-Accuracy:1.478\n",
            " Epoch:92 Training-Error:0.557-> Training-Accuracy:0.685, Test-Error:1.612 -> Test-Accuracy:2.2195\n",
            " Epoch:93 Training-Error:0.557-> Training-Accuracy:0.69, Test-Error:2.148 -> Test-Accuracy:2.96\n",
            " Epoch:94 Training-Error:0.557-> Training-Accuracy:0.704, Test-Error:2.682 -> Test-Accuracy:3.7007\n",
            " Epoch:95 Training-Error:0.559-> Training-Accuracy:0.681, Test-Error:3.216 -> Test-Accuracy:4.443\n",
            " Epoch:96 Training-Error:0.556-> Training-Accuracy:0.676, Test-Error:3.749 -> Test-Accuracy:5.1846\n",
            " Epoch:97 Training-Error:0.559-> Training-Accuracy:0.687, Test-Error:4.281 -> Test-Accuracy:5.9269\n",
            " Epoch:98 Training-Error:0.565-> Training-Accuracy:0.675, Test-Error:4.812 -> Test-Accuracy:6.6693\n",
            " Epoch:99 Training-Error:0.559-> Training-Accuracy:0.691, Test-Error:5.342 -> Test-Accuracy:7.4125\n",
            " Epoch:100 Training-Error:0.562-> Training-Accuracy:0.68, Test-Error:0.529 -> Test-Accuracy:0.7445\n",
            " Epoch:101 Training-Error:0.554-> Training-Accuracy:0.68, Test-Error:1.058 -> Test-Accuracy:1.4891\n",
            " Epoch:102 Training-Error:0.555-> Training-Accuracy:0.678, Test-Error:1.585 -> Test-Accuracy:2.2351\n",
            " Epoch:103 Training-Error:0.552-> Training-Accuracy:0.678, Test-Error:2.112 -> Test-Accuracy:2.9822\n",
            " Epoch:104 Training-Error:0.558-> Training-Accuracy:0.679, Test-Error:2.638 -> Test-Accuracy:3.7289\n",
            " Epoch:105 Training-Error:0.566-> Training-Accuracy:0.654, Test-Error:3.164 -> Test-Accuracy:4.4751\n",
            " Epoch:106 Training-Error:0.549-> Training-Accuracy:0.699, Test-Error:3.688 -> Test-Accuracy:5.2233\n",
            " Epoch:107 Training-Error:0.557-> Training-Accuracy:0.684, Test-Error:4.212 -> Test-Accuracy:5.9711\n",
            " Epoch:108 Training-Error:0.544-> Training-Accuracy:0.692, Test-Error:4.735 -> Test-Accuracy:6.7196\n",
            " Epoch:109 Training-Error:0.542-> Training-Accuracy:0.694, Test-Error:5.257 -> Test-Accuracy:7.4667\n",
            " Epoch:110 Training-Error:0.550-> Training-Accuracy:0.669, Test-Error:0.521 -> Test-Accuracy:0.7488\n",
            " Epoch:111 Training-Error:0.544-> Training-Accuracy:0.699, Test-Error:1.041 -> Test-Accuracy:1.4984\n",
            " Epoch:112 Training-Error:0.547-> Training-Accuracy:0.69, Test-Error:1.561 -> Test-Accuracy:2.2499\n",
            " Epoch:113 Training-Error:0.547-> Training-Accuracy:0.69, Test-Error:2.079 -> Test-Accuracy:3.0021\n",
            " Epoch:114 Training-Error:0.551-> Training-Accuracy:0.678, Test-Error:2.597 -> Test-Accuracy:3.7539\n",
            " Epoch:115 Training-Error:0.553-> Training-Accuracy:0.682, Test-Error:3.114 -> Test-Accuracy:4.5053\n",
            " Epoch:116 Training-Error:0.540-> Training-Accuracy:0.704, Test-Error:3.631 -> Test-Accuracy:5.2573\n",
            " Epoch:117 Training-Error:0.541-> Training-Accuracy:0.687, Test-Error:4.147 -> Test-Accuracy:6.0101\n",
            " Epoch:118 Training-Error:0.534-> Training-Accuracy:0.695, Test-Error:4.663 -> Test-Accuracy:6.7635\n",
            " Epoch:119 Training-Error:0.538-> Training-Accuracy:0.714, Test-Error:5.177 -> Test-Accuracy:7.5175\n",
            " Epoch:120 Training-Error:0.532-> Training-Accuracy:0.703, Test-Error:0.513 -> Test-Accuracy:0.7539\n",
            " Epoch:121 Training-Error:0.533-> Training-Accuracy:0.699, Test-Error:1.026 -> Test-Accuracy:1.5082\n",
            " Epoch:122 Training-Error:0.544-> Training-Accuracy:0.675, Test-Error:1.539 -> Test-Accuracy:2.2641\n",
            " Epoch:123 Training-Error:0.534-> Training-Accuracy:0.696, Test-Error:2.051 -> Test-Accuracy:3.0196\n",
            " Epoch:124 Training-Error:0.541-> Training-Accuracy:0.682, Test-Error:2.561 -> Test-Accuracy:3.7766\n",
            " Epoch:125 Training-Error:0.539-> Training-Accuracy:0.705, Test-Error:3.071 -> Test-Accuracy:4.5335\n",
            " Epoch:126 Training-Error:0.545-> Training-Accuracy:0.677, Test-Error:3.581 -> Test-Accuracy:5.2925\n",
            " Epoch:127 Training-Error:0.542-> Training-Accuracy:0.691, Test-Error:4.090 -> Test-Accuracy:6.0497\n",
            " Epoch:128 Training-Error:0.532-> Training-Accuracy:0.697, Test-Error:4.598 -> Test-Accuracy:6.8078\n",
            " Epoch:129 Training-Error:0.533-> Training-Accuracy:0.694, Test-Error:5.105 -> Test-Accuracy:7.5664\n",
            " Epoch:130 Training-Error:0.530-> Training-Accuracy:0.699, Test-Error:0.506 -> Test-Accuracy:0.7595\n",
            " Epoch:131 Training-Error:0.523-> Training-Accuracy:0.709, Test-Error:1.012 -> Test-Accuracy:1.5199\n",
            " Epoch:132 Training-Error:0.523-> Training-Accuracy:0.711, Test-Error:1.518 -> Test-Accuracy:2.2798\n",
            " Epoch:133 Training-Error:0.541-> Training-Accuracy:0.686, Test-Error:2.023 -> Test-Accuracy:3.0388\n",
            " Epoch:134 Training-Error:0.523-> Training-Accuracy:0.715, Test-Error:2.527 -> Test-Accuracy:3.8003\n",
            " Epoch:135 Training-Error:0.525-> Training-Accuracy:0.696, Test-Error:3.031 -> Test-Accuracy:4.5623\n",
            " Epoch:136 Training-Error:0.522-> Training-Accuracy:0.702, Test-Error:3.534 -> Test-Accuracy:5.3214\n",
            " Epoch:137 Training-Error:0.528-> Training-Accuracy:0.698, Test-Error:4.037 -> Test-Accuracy:6.0831\n",
            " Epoch:138 Training-Error:0.517-> Training-Accuracy:0.711, Test-Error:4.539 -> Test-Accuracy:6.8447\n",
            " Epoch:139 Training-Error:0.521-> Training-Accuracy:0.697, Test-Error:5.041 -> Test-Accuracy:7.607\n",
            " Epoch:140 Training-Error:0.521-> Training-Accuracy:0.704, Test-Error:0.500 -> Test-Accuracy:0.7644\n",
            " Epoch:141 Training-Error:0.526-> Training-Accuracy:0.713, Test-Error:1.001 -> Test-Accuracy:1.5284\n",
            " Epoch:142 Training-Error:0.522-> Training-Accuracy:0.697, Test-Error:1.501 -> Test-Accuracy:2.2926\n",
            " Epoch:143 Training-Error:0.515-> Training-Accuracy:0.717, Test-Error:2.000 -> Test-Accuracy:3.057\n",
            " Epoch:144 Training-Error:0.519-> Training-Accuracy:0.719, Test-Error:2.499 -> Test-Accuracy:3.8212\n",
            " Epoch:145 Training-Error:0.526-> Training-Accuracy:0.695, Test-Error:2.997 -> Test-Accuracy:4.5862\n",
            " Epoch:146 Training-Error:0.523-> Training-Accuracy:0.71, Test-Error:3.494 -> Test-Accuracy:5.3513\n",
            " Epoch:147 Training-Error:0.516-> Training-Accuracy:0.712, Test-Error:3.991 -> Test-Accuracy:6.1176\n",
            " Epoch:148 Training-Error:0.520-> Training-Accuracy:0.716, Test-Error:4.487 -> Test-Accuracy:6.8832\n",
            " Epoch:149 Training-Error:0.521-> Training-Accuracy:0.708, Test-Error:4.983 -> Test-Accuracy:7.6481\n",
            " Epoch:150 Training-Error:0.521-> Training-Accuracy:0.705, Test-Error:0.495 -> Test-Accuracy:0.766\n",
            " Epoch:151 Training-Error:0.520-> Training-Accuracy:0.688, Test-Error:0.989 -> Test-Accuracy:1.5312\n",
            " Epoch:152 Training-Error:0.515-> Training-Accuracy:0.707, Test-Error:1.483 -> Test-Accuracy:2.298\n",
            " Epoch:153 Training-Error:0.507-> Training-Accuracy:0.716, Test-Error:1.977 -> Test-Accuracy:3.0636\n",
            " Epoch:154 Training-Error:0.515-> Training-Accuracy:0.718, Test-Error:2.470 -> Test-Accuracy:3.8308\n",
            " Epoch:155 Training-Error:0.519-> Training-Accuracy:0.708, Test-Error:2.963 -> Test-Accuracy:4.5983\n",
            " Epoch:156 Training-Error:0.512-> Training-Accuracy:0.711, Test-Error:3.455 -> Test-Accuracy:5.3661\n",
            " Epoch:157 Training-Error:0.518-> Training-Accuracy:0.703, Test-Error:3.946 -> Test-Accuracy:6.1343\n",
            " Epoch:158 Training-Error:0.514-> Training-Accuracy:0.7, Test-Error:4.437 -> Test-Accuracy:6.9018\n",
            " Epoch:159 Training-Error:0.516-> Training-Accuracy:0.707, Test-Error:4.928 -> Test-Accuracy:7.6707\n",
            " Epoch:160 Training-Error:0.506-> Training-Accuracy:0.724, Test-Error:0.489 -> Test-Accuracy:0.7698\n",
            " Epoch:161 Training-Error:0.521-> Training-Accuracy:0.697, Test-Error:0.979 -> Test-Accuracy:1.5395\n",
            " Epoch:162 Training-Error:0.507-> Training-Accuracy:0.712, Test-Error:1.468 -> Test-Accuracy:2.3104\n",
            " Epoch:163 Training-Error:0.513-> Training-Accuracy:0.721, Test-Error:1.957 -> Test-Accuracy:3.0797\n",
            " Epoch:164 Training-Error:0.507-> Training-Accuracy:0.718, Test-Error:2.444 -> Test-Accuracy:3.8509\n",
            " Epoch:165 Training-Error:0.511-> Training-Accuracy:0.719, Test-Error:2.932 -> Test-Accuracy:4.6212\n",
            " Epoch:166 Training-Error:0.507-> Training-Accuracy:0.713, Test-Error:3.418 -> Test-Accuracy:5.3919\n",
            " Epoch:167 Training-Error:0.503-> Training-Accuracy:0.731, Test-Error:3.905 -> Test-Accuracy:6.1623\n",
            " Epoch:168 Training-Error:0.502-> Training-Accuracy:0.72, Test-Error:4.391 -> Test-Accuracy:6.9333\n",
            " Epoch:169 Training-Error:0.504-> Training-Accuracy:0.71, Test-Error:4.877 -> Test-Accuracy:7.7041\n",
            " Epoch:170 Training-Error:0.507-> Training-Accuracy:0.726, Test-Error:0.485 -> Test-Accuracy:0.7708\n",
            " Epoch:171 Training-Error:0.505-> Training-Accuracy:0.719, Test-Error:0.970 -> Test-Accuracy:1.5432\n",
            " Epoch:172 Training-Error:0.506-> Training-Accuracy:0.712, Test-Error:1.454 -> Test-Accuracy:2.3153\n",
            " Epoch:173 Training-Error:0.505-> Training-Accuracy:0.713, Test-Error:1.938 -> Test-Accuracy:3.0875\n",
            " Epoch:174 Training-Error:0.503-> Training-Accuracy:0.715, Test-Error:2.421 -> Test-Accuracy:3.8601\n",
            " Epoch:175 Training-Error:0.499-> Training-Accuracy:0.72, Test-Error:2.903 -> Test-Accuracy:4.6337\n",
            " Epoch:176 Training-Error:0.501-> Training-Accuracy:0.719, Test-Error:3.385 -> Test-Accuracy:5.4058\n",
            " Epoch:177 Training-Error:0.494-> Training-Accuracy:0.732, Test-Error:3.867 -> Test-Accuracy:6.1803\n",
            " Epoch:178 Training-Error:0.498-> Training-Accuracy:0.72, Test-Error:4.348 -> Test-Accuracy:6.9537\n",
            " Epoch:179 Training-Error:0.503-> Training-Accuracy:0.718, Test-Error:4.828 -> Test-Accuracy:7.7268\n",
            " Epoch:180 Training-Error:0.512-> Training-Accuracy:0.708, Test-Error:0.480 -> Test-Accuracy:0.7733\n",
            " Epoch:181 Training-Error:0.498-> Training-Accuracy:0.73, Test-Error:0.960 -> Test-Accuracy:1.5483\n",
            " Epoch:182 Training-Error:0.494-> Training-Accuracy:0.723, Test-Error:1.439 -> Test-Accuracy:2.3224\n",
            " Epoch:183 Training-Error:0.495-> Training-Accuracy:0.712, Test-Error:1.918 -> Test-Accuracy:3.0973\n",
            " Epoch:184 Training-Error:0.498-> Training-Accuracy:0.729, Test-Error:2.396 -> Test-Accuracy:3.8714\n",
            " Epoch:185 Training-Error:0.497-> Training-Accuracy:0.728, Test-Error:2.874 -> Test-Accuracy:4.6476\n",
            " Epoch:186 Training-Error:0.502-> Training-Accuracy:0.713, Test-Error:3.351 -> Test-Accuracy:5.424\n",
            " Epoch:187 Training-Error:0.501-> Training-Accuracy:0.715, Test-Error:3.829 -> Test-Accuracy:6.2005\n",
            " Epoch:188 Training-Error:0.502-> Training-Accuracy:0.72, Test-Error:4.306 -> Test-Accuracy:6.9765\n",
            " Epoch:189 Training-Error:0.496-> Training-Accuracy:0.723, Test-Error:4.782 -> Test-Accuracy:7.7537\n",
            " Epoch:190 Training-Error:0.499-> Training-Accuracy:0.723, Test-Error:0.475 -> Test-Accuracy:0.7777\n",
            " Epoch:191 Training-Error:0.501-> Training-Accuracy:0.706, Test-Error:0.950 -> Test-Accuracy:1.5545\n",
            " Epoch:192 Training-Error:0.485-> Training-Accuracy:0.725, Test-Error:1.425 -> Test-Accuracy:2.3321\n",
            " Epoch:193 Training-Error:0.493-> Training-Accuracy:0.726, Test-Error:1.900 -> Test-Accuracy:3.1108\n",
            " Epoch:194 Training-Error:0.496-> Training-Accuracy:0.701, Test-Error:2.374 -> Test-Accuracy:3.8898\n",
            " Epoch:195 Training-Error:0.489-> Training-Accuracy:0.736, Test-Error:2.848 -> Test-Accuracy:4.6682\n",
            " Epoch:196 Training-Error:0.492-> Training-Accuracy:0.727, Test-Error:3.321 -> Test-Accuracy:5.446\n",
            " Epoch:197 Training-Error:0.496-> Training-Accuracy:0.725, Test-Error:3.794 -> Test-Accuracy:6.2252\n",
            " Epoch:198 Training-Error:0.481-> Training-Accuracy:0.739, Test-Error:4.266 -> Test-Accuracy:7.0043\n",
            " Epoch:199 Training-Error:0.487-> Training-Accuracy:0.736, Test-Error:4.738 -> Test-Accuracy:7.7842\n",
            " Epoch:200 Training-Error:0.489-> Training-Accuracy:0.715, Test-Error:0.471 -> Test-Accuracy:0.7794\n",
            " Epoch:201 Training-Error:0.491-> Training-Accuracy:0.725, Test-Error:0.942 -> Test-Accuracy:1.5597\n",
            " Epoch:202 Training-Error:0.501-> Training-Accuracy:0.711, Test-Error:1.413 -> Test-Accuracy:2.3397\n",
            " Epoch:203 Training-Error:0.480-> Training-Accuracy:0.739, Test-Error:1.883 -> Test-Accuracy:3.1189\n",
            " Epoch:204 Training-Error:0.490-> Training-Accuracy:0.717, Test-Error:2.354 -> Test-Accuracy:3.8984\n",
            " Epoch:205 Training-Error:0.480-> Training-Accuracy:0.716, Test-Error:2.823 -> Test-Accuracy:4.6789\n",
            " Epoch:206 Training-Error:0.493-> Training-Accuracy:0.722, Test-Error:3.292 -> Test-Accuracy:5.4599\n",
            " Epoch:207 Training-Error:0.489-> Training-Accuracy:0.718, Test-Error:3.761 -> Test-Accuracy:6.2404\n",
            " Epoch:208 Training-Error:0.485-> Training-Accuracy:0.729, Test-Error:4.230 -> Test-Accuracy:7.0218\n",
            " Epoch:209 Training-Error:0.490-> Training-Accuracy:0.701, Test-Error:4.698 -> Test-Accuracy:7.8031\n",
            " Epoch:210 Training-Error:0.488-> Training-Accuracy:0.742, Test-Error:0.467 -> Test-Accuracy:0.78\n",
            " Epoch:211 Training-Error:0.486-> Training-Accuracy:0.727, Test-Error:0.934 -> Test-Accuracy:1.5625\n",
            " Epoch:212 Training-Error:0.487-> Training-Accuracy:0.738, Test-Error:1.402 -> Test-Accuracy:2.3433\n",
            " Epoch:213 Training-Error:0.481-> Training-Accuracy:0.733, Test-Error:1.868 -> Test-Accuracy:3.1261\n",
            " Epoch:214 Training-Error:0.475-> Training-Accuracy:0.751, Test-Error:2.335 -> Test-Accuracy:3.9097\n",
            " Epoch:215 Training-Error:0.486-> Training-Accuracy:0.732, Test-Error:2.800 -> Test-Accuracy:4.6928\n",
            " Epoch:216 Training-Error:0.481-> Training-Accuracy:0.73, Test-Error:3.266 -> Test-Accuracy:5.4771\n",
            " Epoch:217 Training-Error:0.484-> Training-Accuracy:0.725, Test-Error:3.731 -> Test-Accuracy:6.262\n",
            " Epoch:218 Training-Error:0.485-> Training-Accuracy:0.725, Test-Error:4.196 -> Test-Accuracy:7.0483\n",
            " Epoch:219 Training-Error:0.485-> Training-Accuracy:0.737, Test-Error:4.660 -> Test-Accuracy:7.8332\n",
            " Epoch:220 Training-Error:0.484-> Training-Accuracy:0.719, Test-Error:0.463 -> Test-Accuracy:0.7841\n",
            " Epoch:221 Training-Error:0.480-> Training-Accuracy:0.715, Test-Error:0.926 -> Test-Accuracy:1.5682\n",
            " Epoch:222 Training-Error:0.480-> Training-Accuracy:0.735, Test-Error:1.390 -> Test-Accuracy:2.3532\n",
            " Epoch:223 Training-Error:0.487-> Training-Accuracy:0.723, Test-Error:1.852 -> Test-Accuracy:3.1381\n",
            " Epoch:224 Training-Error:0.491-> Training-Accuracy:0.73, Test-Error:2.315 -> Test-Accuracy:3.9226\n",
            " Epoch:225 Training-Error:0.487-> Training-Accuracy:0.719, Test-Error:2.777 -> Test-Accuracy:4.7078\n",
            " Epoch:226 Training-Error:0.477-> Training-Accuracy:0.732, Test-Error:3.239 -> Test-Accuracy:5.4939\n",
            " Epoch:227 Training-Error:0.485-> Training-Accuracy:0.733, Test-Error:3.700 -> Test-Accuracy:6.2799\n",
            " Epoch:228 Training-Error:0.472-> Training-Accuracy:0.741, Test-Error:4.161 -> Test-Accuracy:7.0659\n",
            " Epoch:229 Training-Error:0.484-> Training-Accuracy:0.713, Test-Error:4.622 -> Test-Accuracy:7.8534\n",
            " Epoch:230 Training-Error:0.479-> Training-Accuracy:0.733, Test-Error:0.460 -> Test-Accuracy:0.7875\n",
            " Epoch:231 Training-Error:0.487-> Training-Accuracy:0.727, Test-Error:0.920 -> Test-Accuracy:1.5757\n",
            " Epoch:232 Training-Error:0.478-> Training-Accuracy:0.748, Test-Error:1.379 -> Test-Accuracy:2.3643\n",
            " Epoch:233 Training-Error:0.467-> Training-Accuracy:0.748, Test-Error:1.839 -> Test-Accuracy:3.1534\n",
            " Epoch:234 Training-Error:0.483-> Training-Accuracy:0.724, Test-Error:2.298 -> Test-Accuracy:3.9417\n",
            " Epoch:235 Training-Error:0.479-> Training-Accuracy:0.731, Test-Error:2.756 -> Test-Accuracy:4.7308\n",
            " Epoch:236 Training-Error:0.477-> Training-Accuracy:0.738, Test-Error:3.214 -> Test-Accuracy:5.5203\n",
            " Epoch:237 Training-Error:0.481-> Training-Accuracy:0.721, Test-Error:3.672 -> Test-Accuracy:6.3098\n",
            " Epoch:238 Training-Error:0.483-> Training-Accuracy:0.729, Test-Error:4.129 -> Test-Accuracy:7.101\n",
            " Epoch:239 Training-Error:0.470-> Training-Accuracy:0.749, Test-Error:4.586 -> Test-Accuracy:7.8923\n",
            " Epoch:240 Training-Error:0.477-> Training-Accuracy:0.732, Test-Error:0.456 -> Test-Accuracy:0.7908\n",
            " Epoch:241 Training-Error:0.475-> Training-Accuracy:0.737, Test-Error:0.912 -> Test-Accuracy:1.5808\n",
            " Epoch:242 Training-Error:0.466-> Training-Accuracy:0.749, Test-Error:1.368 -> Test-Accuracy:2.3713\n",
            " Epoch:243 Training-Error:0.468-> Training-Accuracy:0.743, Test-Error:1.824 -> Test-Accuracy:3.1617\n",
            " Epoch:244 Training-Error:0.484-> Training-Accuracy:0.731, Test-Error:2.279 -> Test-Accuracy:3.9525\n",
            " Epoch:245 Training-Error:0.476-> Training-Accuracy:0.728, Test-Error:2.734 -> Test-Accuracy:4.7438\n",
            " Epoch:246 Training-Error:0.476-> Training-Accuracy:0.731, Test-Error:3.188 -> Test-Accuracy:5.5349\n",
            " Epoch:247 Training-Error:0.475-> Training-Accuracy:0.747, Test-Error:3.643 -> Test-Accuracy:6.3259\n",
            " Epoch:248 Training-Error:0.475-> Training-Accuracy:0.737, Test-Error:4.097 -> Test-Accuracy:7.1162\n",
            " Epoch:249 Training-Error:0.474-> Training-Accuracy:0.744, Test-Error:4.551 -> Test-Accuracy:7.9073\n",
            " Epoch:250 Training-Error:0.468-> Training-Accuracy:0.742, Test-Error:0.453 -> Test-Accuracy:0.791\n",
            " Epoch:251 Training-Error:0.479-> Training-Accuracy:0.744, Test-Error:0.906 -> Test-Accuracy:1.5824\n",
            " Epoch:252 Training-Error:0.470-> Training-Accuracy:0.74, Test-Error:1.359 -> Test-Accuracy:2.3743\n",
            " Epoch:253 Training-Error:0.468-> Training-Accuracy:0.739, Test-Error:1.812 -> Test-Accuracy:3.1656\n",
            " Epoch:254 Training-Error:0.478-> Training-Accuracy:0.726, Test-Error:2.264 -> Test-Accuracy:3.9572\n",
            " Epoch:255 Training-Error:0.480-> Training-Accuracy:0.722, Test-Error:2.717 -> Test-Accuracy:4.749\n",
            " Epoch:256 Training-Error:0.467-> Training-Accuracy:0.746, Test-Error:3.169 -> Test-Accuracy:5.5404\n",
            " Epoch:257 Training-Error:0.476-> Training-Accuracy:0.745, Test-Error:3.621 -> Test-Accuracy:6.3331\n",
            " Epoch:258 Training-Error:0.471-> Training-Accuracy:0.73, Test-Error:4.073 -> Test-Accuracy:7.1253\n",
            " Epoch:259 Training-Error:0.469-> Training-Accuracy:0.746, Test-Error:4.525 -> Test-Accuracy:7.917\n",
            " Epoch:260 Training-Error:0.469-> Training-Accuracy:0.743, Test-Error:0.451 -> Test-Accuracy:0.7928\n",
            " Epoch:261 Training-Error:0.472-> Training-Accuracy:0.758, Test-Error:0.902 -> Test-Accuracy:1.5857\n",
            " Epoch:262 Training-Error:0.468-> Training-Accuracy:0.736, Test-Error:1.353 -> Test-Accuracy:2.3796\n",
            " Epoch:263 Training-Error:0.470-> Training-Accuracy:0.735, Test-Error:1.803 -> Test-Accuracy:3.1735\n",
            " Epoch:264 Training-Error:0.482-> Training-Accuracy:0.729, Test-Error:2.254 -> Test-Accuracy:3.967\n",
            " Epoch:265 Training-Error:0.467-> Training-Accuracy:0.728, Test-Error:2.703 -> Test-Accuracy:4.7616\n",
            " Epoch:266 Training-Error:0.473-> Training-Accuracy:0.743, Test-Error:3.153 -> Test-Accuracy:5.5549\n",
            " Epoch:267 Training-Error:0.475-> Training-Accuracy:0.737, Test-Error:3.603 -> Test-Accuracy:6.3494\n",
            " Epoch:268 Training-Error:0.466-> Training-Accuracy:0.731, Test-Error:4.052 -> Test-Accuracy:7.1449\n",
            " Epoch:269 Training-Error:0.470-> Training-Accuracy:0.726, Test-Error:4.501 -> Test-Accuracy:7.9394\n",
            " Epoch:270 Training-Error:0.464-> Training-Accuracy:0.739, Test-Error:0.448 -> Test-Accuracy:0.7947\n",
            " Epoch:271 Training-Error:0.468-> Training-Accuracy:0.738, Test-Error:0.897 -> Test-Accuracy:1.5899\n",
            " Epoch:272 Training-Error:0.452-> Training-Accuracy:0.751, Test-Error:1.346 -> Test-Accuracy:2.3849\n",
            " Epoch:273 Training-Error:0.462-> Training-Accuracy:0.75, Test-Error:1.794 -> Test-Accuracy:3.179\n",
            " Epoch:274 Training-Error:0.465-> Training-Accuracy:0.729, Test-Error:2.242 -> Test-Accuracy:3.9726\n",
            " Epoch:275 Training-Error:0.459-> Training-Accuracy:0.744, Test-Error:2.689 -> Test-Accuracy:4.7674\n",
            " Epoch:276 Training-Error:0.451-> Training-Accuracy:0.765, Test-Error:3.136 -> Test-Accuracy:5.5622\n",
            " Epoch:277 Training-Error:0.465-> Training-Accuracy:0.75, Test-Error:3.584 -> Test-Accuracy:6.3583\n",
            " Epoch:278 Training-Error:0.467-> Training-Accuracy:0.736, Test-Error:4.030 -> Test-Accuracy:7.1534\n",
            " Epoch:279 Training-Error:0.456-> Training-Accuracy:0.744, Test-Error:4.477 -> Test-Accuracy:7.9501\n",
            " Epoch:280 Training-Error:0.461-> Training-Accuracy:0.758, Test-Error:0.446 -> Test-Accuracy:0.796\n",
            " Epoch:281 Training-Error:0.466-> Training-Accuracy:0.743, Test-Error:0.892 -> Test-Accuracy:1.5913\n",
            " Epoch:282 Training-Error:0.461-> Training-Accuracy:0.752, Test-Error:1.337 -> Test-Accuracy:2.3877\n",
            " Epoch:283 Training-Error:0.456-> Training-Accuracy:0.761, Test-Error:1.782 -> Test-Accuracy:3.186\n",
            " Epoch:284 Training-Error:0.463-> Training-Accuracy:0.74, Test-Error:2.228 -> Test-Accuracy:3.9855\n",
            " Epoch:285 Training-Error:0.464-> Training-Accuracy:0.733, Test-Error:2.672 -> Test-Accuracy:4.7832\n",
            " Epoch:286 Training-Error:0.460-> Training-Accuracy:0.749, Test-Error:3.117 -> Test-Accuracy:5.5829\n",
            " Epoch:287 Training-Error:0.459-> Training-Accuracy:0.756, Test-Error:3.561 -> Test-Accuracy:6.3837\n",
            " Epoch:288 Training-Error:0.462-> Training-Accuracy:0.743, Test-Error:4.005 -> Test-Accuracy:7.1826\n",
            " Epoch:289 Training-Error:0.462-> Training-Accuracy:0.749, Test-Error:4.448 -> Test-Accuracy:7.983\n",
            " Epoch:290 Training-Error:0.467-> Training-Accuracy:0.752, Test-Error:0.443 -> Test-Accuracy:0.7997\n",
            " Epoch:291 Training-Error:0.463-> Training-Accuracy:0.731, Test-Error:0.886 -> Test-Accuracy:1.5997\n",
            " Epoch:292 Training-Error:0.460-> Training-Accuracy:0.738, Test-Error:1.329 -> Test-Accuracy:2.4001\n",
            " Epoch:293 Training-Error:0.462-> Training-Accuracy:0.734, Test-Error:1.772 -> Test-Accuracy:3.2014\n",
            " Epoch:294 Training-Error:0.451-> Training-Accuracy:0.749, Test-Error:2.214 -> Test-Accuracy:4.0015\n",
            " Epoch:295 Training-Error:0.462-> Training-Accuracy:0.744, Test-Error:2.656 -> Test-Accuracy:4.802\n",
            " Epoch:296 Training-Error:0.463-> Training-Accuracy:0.753, Test-Error:3.098 -> Test-Accuracy:5.6036\n",
            " Epoch:297 Training-Error:0.465-> Training-Accuracy:0.748, Test-Error:3.540 -> Test-Accuracy:6.404\n",
            " Epoch:298 Training-Error:0.463-> Training-Accuracy:0.739, Test-Error:3.981 -> Test-Accuracy:7.2046\n",
            " Epoch:299 Training-Error:0.453-> Training-Accuracy:0.747, Test-Error:0.441 -> Test-Accuracy:0.8012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L8mCEoifG5O"
      },
      "source": [
        "# **Adding Data Augmentation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8wK6x9djOFv"
      },
      "source": [
        "First run (minibatch =64, lr=0.001):\n",
        "\n",
        "Epoch:299 Training-Error:0.625-> Training-Accuracy:0.611, Test-Error:0.575 -> Test-Accuracy:0.7148\n",
        "\n",
        "Second run (minibatch =64, lr=0.005):\n",
        "\n",
        "Epoch:299 Training-Error:0.453-> Training-Accuracy:0.747, Test-Error:0.441 -> Test-Accuracy:0.8012\n",
        "\n",
        "Third run (minibatch =100, lr=0.005):\n",
        "\n",
        "Epoch:299 Training-Error:0.512-> Training-Accuracy:0.75, Test-Error:0.472 -> Test-Accuracy:0.7804\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhZrEhzGjOF9"
      },
      "source": [
        "### Load the MNIST digit dataset using (1000,28x28)/255 shape size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sQb4PQVjOGA"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "digits, labels = (X_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fUWLD3UjOGA"
      },
      "source": [
        "### Do One Hot Encoding of Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiQKrwpajOGB"
      },
      "source": [
        "encode_labels = np.zeros((len(labels),10))\n",
        "\n",
        "## For Loop enumerating the encoded labels\n",
        "for i,l in enumerate(labels):\n",
        "    encode_labels[i][l] = 1\n",
        "labels = encode_labels"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2pNmdGKjOGB"
      },
      "source": [
        "### Reshape the digits image in 3Dimension H=28px, W=28px, canal = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3P_ZybCjOGB"
      },
      "source": [
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "X_test = X_test.reshape(-1,28,28,1)\n",
        "\n",
        "# Reshape the test dataset to a one channel\n",
        "test_digits = X_test.reshape(len(X_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "\n",
        "# Convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbZvWxNvl1eI"
      },
      "source": [
        "### **ImageDataGenerator **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "obzRwww1wDbr",
        "outputId": "c46c1dfa-4206-476f-98ac-99a883abc598"
      },
      "source": [
        "datagen = ImageDataGenerator(rotation_range=90)\n",
        "# fit parameters from data\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
        "  # create a 3x3 grid images\n",
        "  for i in range(0,9):\n",
        "    pyplot.subplot(330 + 1 +i)\n",
        "    pyplot.imshow(X_batch[i].reshape(28,28), cmap=pyplot.get_cmap('gray'))\n",
        "  # show the digit images\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STvGCES2jOGC"
      },
      "source": [
        "### **Perform Grayscale Normalization of the data prior training **\n",
        "\n",
        "F. The code should normalize the input as discussed in the class before training (scaling the input)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh3TIimojOGC"
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_pyD0bCXoeM"
      },
      "source": [
        "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=(2))"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XNnH25gAgTpL",
        "outputId": "98c9cfc5-2cd2-4857-dc4c-ca0b2ff7b4b1"
      },
      "source": [
        "plt.imshow(X_train[129][:,:,0])"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff9481e82d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOHklEQVR4nO3dbYxc5XnG8esC1nZtIMIFHBcbAsE0vCQxaOuAQCnUJAX3gyFSALdCTkK1aYsrokRVSfIhJK0U1JBAGgWCAYNBFEIDyP5gtbhuJEqTUBbiYIMTMK7BGGPz0hRDwV68dz/sOFnMzjPrmTMv7P3/SaOZOffMObdGe+05c86Z8zgiBGDiO6DbDQDoDMIOJEHYgSQIO5AEYQeSOKiTC5vkyTFF0zq5SCCVt/SGdscuj1VrKey2z5P0XUkHSro5Iq4uvX6Kpuljnt/KIgEUPBxr6taa3oy3faCk70s6X9JJkhbZPqnZ+QFor1a+s8+TtDEiNkXEbkl3S1pYTVsAqtZK2I+StGXU8+dr097B9oDtQduDQ9rVwuIAtKLte+MjYmlE9EdEf58mt3txAOpoJexbJc0e9XxWbRqAHtRK2B+RNMf2sbYnSbpE0spq2gJQtaYPvUXE27aXSPpXjRx6WxYRT1TWGYBKtXScPSJWSVpVUS8A2ojTZYEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKKjl5IGRttzzmnF+jXLbijWT55U/vM9+fYldWvHfvmnxfdORKzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJjrOjrZ66fl7d2s1/fEvxvSdOKq+LhjVcXniUy9mwZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDjOjqIDpk4t1neffmKx/s35/1y3dtaUt4rv3Tm8u1hf9cYxxfqxK98o1rNpKey2N0vaKWmPpLcjor+KpgBUr4o1+zkR8XIF8wHQRnxnB5JoNewh6QHbj9oeGOsFtgdsD9oeHNKuFhcHoFmtbsafFRFbbR8pabXtX0bEg6NfEBFLJS2VpEM9nZ8mAF3S0po9IrbW7ndIul9S/Z84AeiqpsNue5rtQ/Y+lvRJSeuragxAtVrZjJ8h6X7be+fzTxHxL5V0hZ7x3BVzi/XHlny3bcu++FeLivWDzn2uwRwer66ZCaDpsEfEJkkfrbAXAG3EoTcgCcIOJEHYgSQIO5AEYQeS4CeuycWZ5UNrdw5c22AOza8vlr9W/olq398cUqxzOub+Yc0OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwnH2C23POacX6wI33FusnTyr/iTQaNvlDKy6vW/v9Zf9XfG/8nMsjVIk1O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXH2CWD4D0+tW1uy9J7ie8+f+j8N5l5eH/zo9fcX6yfcXn9Y5hjkOHonsWYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4zj4BfHXZ8rq1M6bsamneJz/4uWL9+L/cXJ7Brxk2uVc0XLPbXmZ7h+31o6ZNt73a9tO1+8Pa2yaAVo1nM/42SeftM+1KSWsiYo6kNbXnAHpYw7BHxIOSXt1n8kJJe7cdl0u6oOK+AFSs2e/sMyJiW+3xi5Jm1Huh7QFJA5I0RVObXByAVrW8Nz4iQoUx9iJiaUT0R0R/nya3ujgATWo27Nttz5Sk2v2O6loC0A7Nhn2lpMW1x4slraimHQDt0vA7u+27JJ0t6XDbz0v6mqSrJd1j+zJJz0q6qJ1NTnQHzSz/JvzXt5b3dXx00k8K1b4mOvqtWbeU/0Re+tRJxfpHBtY1veynv1me98EPbSzW97yy737l3BqGPSIW1SnNr7gXAG3E6bJAEoQdSIKwA0kQdiAJwg4kwU9ce8Dmzx5XrC+c8VCxPvWA1g6vlRzz908V6z+Y/e9tW/a3/u7lYv0nF3+4PAMOvb0Da3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILj7D1g1vznivWvH/nzBnNo3//sW4/+j2J9KMrLvviZfa9V+lu/eHZW8b0PfPx7xfqJK14o1peeUD5/IRvW7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBMfZe8CO+48u1oe/PNyhTt5tqO5YPyM2DA0V6+tfmFm3dvyl5fMHzr3+i8X6qgXXFes7L/7TurVDfviz4nsnItbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEx9k7wJMnF+uzP72pQ53sv/8dfqtY/9mbc4r1WTe375r22D8N1+y2l9neYXv9qGlX2d5qe23ttqC9bQJo1Xg242+TNNblRq6NiLm126pq2wJQtYZhj4gHJTGODvAe18oOuiW2H69t5h9W70W2B2wP2h4c0q4WFgegFc2G/QZJH5Q0V9I2Sd+u98KIWBoR/RHR36fyjioA7dNU2CNie0TsiYhhSTdJmldtWwCq1lTYbY/+3eKFktbXey2A3tDwOLvtuySdLelw289L+pqks23PlRSSNkv6fBt7fO/7yAnF8sIjV3eokf33je1nF+vPXDijWO/b8mjTy77m3LuL9XW76/9WXsr5m/WShmGPiEVjTL6lDb0AaCNOlwWSIOxAEoQdSIKwA0kQdiAJfuLaASfc8Mti/RPTNjaYQ/vOPPzWKx8u1jf+2THF+vCOLcX6rgV/ULf219f9sPjeW184s1iPzzX6XDY3qOfCmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuA4ewV2XnJ6sb7kiLoX8pEkzTiwfcfRT7xvSbH+oesbXF7w5VeK5WduPbFYv27eHXVr39/yR8X3vnn17xXrkzYNFut4J9bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEx9krcMjd5UsWr/tG+ZLHxxxUPpbditv+5MZi/TMHlK8CfsopO4v19cfftN897XXHpPJw0Hr0v4vlPU0vOSfW7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQhCOiYws71NPjY57fseX1ilf+/Ixi/T+//o8d6mT/HdBgfTCs4WL9r7acU7e29tbyNesPv/GnxTre7eFYo9fiVY9Va7hmtz3b9o9tP2n7CdtX1KZPt73a9tO1+8OqbhxAdcazGf+2pC9FxEmSTpd0ue2TJF0paU1EzJG0pvYcQI9qGPaI2BYRj9Ue75S0QdJRkhZKWl572XJJF7SrSQCt269z421/QNKpkh6WNCMittVKL0qaUec9A5IGJGmKpjbbJ4AWjXtvvO2DJd0r6QsR8droWozs5RtzT19ELI2I/ojo72vjAIUAysYVdtt9Ggn6nRFxX23ydtsza/WZkna0p0UAVWi4GW/bkm6RtCEivjOqtFLSYklX1+5XtKXDCWDqS+UfY24aGirWj+vrq7KdSi1/rTyk8wt/cXTd2uFrObTWSeP5zn6mpEslrbO9tjbtKxoJ+T22L5P0rKSL2tMigCo0DHtEPCRpzIP0kvKdIQO8R3G6LJAEYQeSIOxAEoQdSIKwA0lwKekO+J0V/1Wsf/bgLxbrr89u/n/ym+8v/wT1yU9/r+l5S9LiQ58t1n9wxvvq1o5YW7eENmDNDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcClpYAJp6VLSACYGwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiiYdhtz7b9Y9tP2n7C9hW16VfZ3mp7be22oP3tAmjWeAaJeFvSlyLiMduHSHrU9upa7dqIuKZ97QGoynjGZ98maVvt8U7bGyQd1e7GAFRrv76z2/6ApFMlPVybtMT247aX2T6sznsGbA/aHhzSrpaaBdC8cYfd9sGS7pX0hYh4TdINkj4oaa5G1vzfHut9EbE0Ivojor9PkytoGUAzxhV2230aCfqdEXGfJEXE9ojYExHDkm6SNK99bQJo1Xj2xlvSLZI2RMR3Rk2fOeplF0paX317AKoynr3xZ0q6VNI623sH2f2KpEW250oKSZslfb4tHQKoxHj2xj8kaazrUK+qvh0A7cIZdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQcEZ1bmP2SpGdHTTpc0ssda2D/9GpvvdqXRG/NqrK3YyLiiLEKHQ37uxZuD0ZEf9caKOjV3nq1L4nemtWp3tiMB5Ig7EAS3Q770i4vv6RXe+vVviR6a1ZHeuvqd3YAndPtNTuADiHsQBJdCbvt82z/yvZG21d2o4d6bG+2va42DPVgl3tZZnuH7fWjpk23vdr207X7McfY61JvPTGMd2GY8a5+dt0e/rzj39ltHyjpKUmfkPS8pEckLYqIJzvaSB22N0vqj4iun4Bh++OSXpd0e0ScUpv2D5JejYira/8oD4uIv+2R3q6S9Hq3h/GujVY0c/Qw45IukPQZdfGzK/R1kTrwuXVjzT5P0saI2BQRuyXdLWlhF/roeRHxoKRX95m8UNLy2uPlGvlj6bg6vfWEiNgWEY/VHu+UtHeY8a5+doW+OqIbYT9K0pZRz59Xb433HpIesP2o7YFuNzOGGRGxrfb4RUkzutnMGBoO491J+wwz3jOfXTPDn7eKHXTvdlZEnCbpfEmX1zZXe1KMfAfrpWOn4xrGu1PGGGb8N7r52TU7/HmruhH2rZJmj3o+qzatJ0TE1tr9Dkn3q/eGot6+dwTd2v2OLvfzG700jPdYw4yrBz67bg5/3o2wPyJpju1jbU+SdImklV3o411sT6vtOJHtaZI+qd4binqlpMW1x4slrehiL+/QK8N41xtmXF3+7Lo+/HlEdPwmaYFG9sg/I+mr3eihTl/HSfpF7fZEt3uTdJdGNuuGNLJv4zJJvytpjaSnJf2bpOk91NsdktZJelwjwZrZpd7O0sgm+uOS1tZuC7r92RX66sjnxumyQBLsoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJP4f2PEk7kNgrE0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad3L36GijOGC"
      },
      "source": [
        "### Neural Nets Training with Dropout, Data Augmentation, Minibatch Gradient Descent and Normalization.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n0evzcajOGC",
        "outputId": "b21c8e71-4f0d-40b1-bf3d-2b65f6cde567"
      },
      "source": [
        "import numpy, sys\n",
        "np.random.seed(1)\n",
        "\n",
        "#Activation Function\n",
        "def Relu(x):\n",
        "    # returns x if x > 0\n",
        "    return ( x >= 0 ) * x\n",
        "\n",
        "def Relu_derivative(output):\n",
        "    # returns 1 for input > 0\n",
        "    return output >= 0 \n",
        "\n",
        "# Initialize Batch size\n",
        "minibatch = 64\n",
        "\n",
        "# Initialize and change parameters learning rate ( 0.005 ~ 0.001)\n",
        "lr, epoch, hidden_size, = (0.005, 300, 100)\n",
        "pixels, numLabels = (784, 10)\n",
        "\n",
        "weights0_1 = 0.2*np.random.random((pixels, hidden_size)) - 0.1\n",
        "weights1_2 = 0.2*np.random.random((hidden_size, numLabels)) - 0.1\n",
        "\n",
        "for j in range(epoch):\n",
        "    error, correctCnt = (0.0, 0)\n",
        "\n",
        "    # Feed forward through layers 0, 1, and 2 ( 3 layers) with minibatch\n",
        "    for i in range(int(len(digits) / minibatch)):\n",
        "        minibatch_start, minibatch_end = ((i * minibatch), ((i+1)*minibatch))\n",
        "\n",
        "        layer_0 = digits[minibatch_start:minibatch_end]\n",
        "        layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "\n",
        "        # Adding Dropout\n",
        "        dropOut_mask = np.random.randint(2, size=layer_1.shape)\n",
        "\n",
        "        layer_1 *= dropOut_mask * 2\n",
        "        layer_2 = np.dot(layer_1, weights1_2)  \n",
        "\n",
        "    # How much did we miss the target value(error)? with minibatch\n",
        "        error += np.sum((labels[minibatch_start:minibatch_end] - layer_2) ** 2)\n",
        "        for k in range(minibatch):\n",
        "            correctCnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[minibatch_start+k:minibatch_start+k+1]))\n",
        "            # correctCnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "\n",
        "    # Compute the gradient descent using relu activation function with minibatch\n",
        "        layer_2_deltaChange = (labels[minibatch_start:minibatch_end] - layer_2) / minibatch\n",
        "        layer_1_deltaChange = layer_2_deltaChange.dot(weights1_2.T) * Relu_derivative(layer_1)\n",
        "\n",
        "    # Adding DropOut\n",
        "        layer_1_deltaChange *+ dropOut_mask\n",
        "\n",
        "    # Updating the weights \n",
        "        weights1_2 += lr * layer_1.T.dot(layer_2_deltaChange)\n",
        "        weights0_1 += lr * layer_0.T.dot(layer_1_deltaChange)\n",
        "\n",
        "    # Test Digits Sample\n",
        "    if(j % 10 == 0 or j == epoch-1):\n",
        "        testError, testCorrectcnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(test_digits)):\n",
        "        # Feed forward through layers 0, 1, and 2 ( 3 layers) for test MNIST digit samples\n",
        "        layer_0 = test_digits[i:i+1]\n",
        "        layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "        layer_2 = np.dot(layer_1,weights1_2)\n",
        "\n",
        "        # how much did we miss the target value(error)?\n",
        "        testError += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "        testCorrectcnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "      \n",
        "\n",
        "    print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \"-> Training-Accuracy:\" + str(correctCnt/float(len(digits))) + \\\n",
        "          \", Test-Error:\" + str(testError/float(len(test_digits)))[0:5] + \" -> Test-Accuracy:\" + str(testCorrectcnt/float(len(test_digits))))\n",
        "    # print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \", Training-Accuracy:\" + str(correctCnt/float(len(digits))))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch:0 Training-Error:1.722-> Training-Accuracy:0.081, Test-Error:1.134 -> Test-Accuracy:0.1119\n",
            " Epoch:1 Training-Error:1.439-> Training-Accuracy:0.104, Test-Error:2.166 -> Test-Accuracy:0.2711\n",
            " Epoch:2 Training-Error:1.332-> Training-Accuracy:0.152, Test-Error:3.148 -> Test-Accuracy:0.4721\n",
            " Epoch:3 Training-Error:1.277-> Training-Accuracy:0.146, Test-Error:4.091 -> Test-Accuracy:0.7134\n",
            " Epoch:4 Training-Error:1.189-> Training-Accuracy:0.183, Test-Error:5.003 -> Test-Accuracy:0.9908\n",
            " Epoch:5 Training-Error:1.139-> Training-Accuracy:0.206, Test-Error:5.888 -> Test-Accuracy:1.3057\n",
            " Epoch:6 Training-Error:1.116-> Training-Accuracy:0.21, Test-Error:6.748 -> Test-Accuracy:1.657\n",
            " Epoch:7 Training-Error:1.088-> Training-Accuracy:0.241, Test-Error:7.585 -> Test-Accuracy:2.0361\n",
            " Epoch:8 Training-Error:1.054-> Training-Accuracy:0.254, Test-Error:8.405 -> Test-Accuracy:2.4366\n",
            " Epoch:9 Training-Error:1.020-> Training-Accuracy:0.295, Test-Error:9.208 -> Test-Accuracy:2.8661\n",
            " Epoch:10 Training-Error:0.998-> Training-Accuracy:0.31, Test-Error:0.787 -> Test-Accuracy:0.4529\n",
            " Epoch:11 Training-Error:0.980-> Training-Accuracy:0.293, Test-Error:1.560 -> Test-Accuracy:0.9272\n",
            " Epoch:12 Training-Error:0.944-> Training-Accuracy:0.31, Test-Error:2.320 -> Test-Accuracy:1.4187\n",
            " Epoch:13 Training-Error:0.938-> Training-Accuracy:0.333, Test-Error:3.070 -> Test-Accuracy:1.9271\n",
            " Epoch:14 Training-Error:0.921-> Training-Accuracy:0.331, Test-Error:3.808 -> Test-Accuracy:2.4497\n",
            " Epoch:15 Training-Error:0.896-> Training-Accuracy:0.364, Test-Error:4.537 -> Test-Accuracy:2.9852\n",
            " Epoch:16 Training-Error:0.874-> Training-Accuracy:0.403, Test-Error:5.257 -> Test-Accuracy:3.5391\n",
            " Epoch:17 Training-Error:0.874-> Training-Accuracy:0.397, Test-Error:5.969 -> Test-Accuracy:4.1045\n",
            " Epoch:18 Training-Error:0.840-> Training-Accuracy:0.411, Test-Error:6.673 -> Test-Accuracy:4.6754\n",
            " Epoch:19 Training-Error:0.832-> Training-Accuracy:0.429, Test-Error:7.370 -> Test-Accuracy:5.258\n",
            " Epoch:20 Training-Error:0.833-> Training-Accuracy:0.432, Test-Error:0.691 -> Test-Accuracy:0.5934\n",
            " Epoch:21 Training-Error:0.813-> Training-Accuracy:0.449, Test-Error:1.375 -> Test-Accuracy:1.1932\n",
            " Epoch:22 Training-Error:0.817-> Training-Accuracy:0.429, Test-Error:2.054 -> Test-Accuracy:1.7989\n",
            " Epoch:23 Training-Error:0.798-> Training-Accuracy:0.474, Test-Error:2.727 -> Test-Accuracy:2.4128\n",
            " Epoch:24 Training-Error:0.795-> Training-Accuracy:0.501, Test-Error:3.396 -> Test-Accuracy:3.0347\n",
            " Epoch:25 Training-Error:0.771-> Training-Accuracy:0.488, Test-Error:4.060 -> Test-Accuracy:3.6631\n",
            " Epoch:26 Training-Error:0.774-> Training-Accuracy:0.475, Test-Error:4.719 -> Test-Accuracy:4.2976\n",
            " Epoch:27 Training-Error:0.772-> Training-Accuracy:0.498, Test-Error:5.373 -> Test-Accuracy:4.9362\n",
            " Epoch:28 Training-Error:0.754-> Training-Accuracy:0.534, Test-Error:6.024 -> Test-Accuracy:5.5807\n",
            " Epoch:29 Training-Error:0.756-> Training-Accuracy:0.501, Test-Error:6.671 -> Test-Accuracy:6.2296\n",
            " Epoch:30 Training-Error:0.736-> Training-Accuracy:0.527, Test-Error:0.642 -> Test-Accuracy:0.6537\n",
            " Epoch:31 Training-Error:0.740-> Training-Accuracy:0.517, Test-Error:1.281 -> Test-Accuracy:1.3086\n",
            " Epoch:32 Training-Error:0.732-> Training-Accuracy:0.546, Test-Error:1.917 -> Test-Accuracy:1.9663\n",
            " Epoch:33 Training-Error:0.725-> Training-Accuracy:0.528, Test-Error:2.549 -> Test-Accuracy:2.6315\n",
            " Epoch:34 Training-Error:0.717-> Training-Accuracy:0.538, Test-Error:3.178 -> Test-Accuracy:3.2998\n",
            " Epoch:35 Training-Error:0.717-> Training-Accuracy:0.553, Test-Error:3.804 -> Test-Accuracy:3.97\n",
            " Epoch:36 Training-Error:0.698-> Training-Accuracy:0.547, Test-Error:4.428 -> Test-Accuracy:4.6429\n",
            " Epoch:37 Training-Error:0.702-> Training-Accuracy:0.571, Test-Error:5.048 -> Test-Accuracy:5.3184\n",
            " Epoch:38 Training-Error:0.706-> Training-Accuracy:0.55, Test-Error:5.666 -> Test-Accuracy:5.9966\n",
            " Epoch:39 Training-Error:0.692-> Training-Accuracy:0.574, Test-Error:6.281 -> Test-Accuracy:6.6766\n",
            " Epoch:40 Training-Error:0.689-> Training-Accuracy:0.575, Test-Error:0.612 -> Test-Accuracy:0.6814\n",
            " Epoch:41 Training-Error:0.682-> Training-Accuracy:0.581, Test-Error:1.222 -> Test-Accuracy:1.3666\n",
            " Epoch:42 Training-Error:0.688-> Training-Accuracy:0.584, Test-Error:1.830 -> Test-Accuracy:2.0536\n",
            " Epoch:43 Training-Error:0.674-> Training-Accuracy:0.595, Test-Error:2.435 -> Test-Accuracy:2.7429\n",
            " Epoch:44 Training-Error:0.676-> Training-Accuracy:0.586, Test-Error:3.038 -> Test-Accuracy:3.4344\n",
            " Epoch:45 Training-Error:0.661-> Training-Accuracy:0.593, Test-Error:3.639 -> Test-Accuracy:4.124\n",
            " Epoch:46 Training-Error:0.663-> Training-Accuracy:0.6, Test-Error:4.238 -> Test-Accuracy:4.8182\n",
            " Epoch:47 Training-Error:0.658-> Training-Accuracy:0.595, Test-Error:4.834 -> Test-Accuracy:5.5157\n",
            " Epoch:48 Training-Error:0.657-> Training-Accuracy:0.601, Test-Error:5.429 -> Test-Accuracy:6.2141\n",
            " Epoch:49 Training-Error:0.654-> Training-Accuracy:0.604, Test-Error:6.022 -> Test-Accuracy:6.9133\n",
            " Epoch:50 Training-Error:0.649-> Training-Accuracy:0.608, Test-Error:0.591 -> Test-Accuracy:0.7003\n",
            " Epoch:51 Training-Error:0.641-> Training-Accuracy:0.634, Test-Error:1.179 -> Test-Accuracy:1.4053\n",
            " Epoch:52 Training-Error:0.652-> Training-Accuracy:0.603, Test-Error:1.766 -> Test-Accuracy:2.1107\n",
            " Epoch:53 Training-Error:0.647-> Training-Accuracy:0.585, Test-Error:2.351 -> Test-Accuracy:2.8171\n",
            " Epoch:54 Training-Error:0.646-> Training-Accuracy:0.61, Test-Error:2.935 -> Test-Accuracy:3.5248\n",
            " Epoch:55 Training-Error:0.635-> Training-Accuracy:0.629, Test-Error:3.516 -> Test-Accuracy:4.2356\n",
            " Epoch:56 Training-Error:0.640-> Training-Accuracy:0.6, Test-Error:4.097 -> Test-Accuracy:4.9473\n",
            " Epoch:57 Training-Error:0.637-> Training-Accuracy:0.613, Test-Error:4.675 -> Test-Accuracy:5.6583\n",
            " Epoch:58 Training-Error:0.628-> Training-Accuracy:0.63, Test-Error:5.253 -> Test-Accuracy:6.3699\n",
            " Epoch:59 Training-Error:0.628-> Training-Accuracy:0.624, Test-Error:5.828 -> Test-Accuracy:7.0843\n",
            " Epoch:60 Training-Error:0.624-> Training-Accuracy:0.642, Test-Error:0.574 -> Test-Accuracy:0.7166\n",
            " Epoch:61 Training-Error:0.626-> Training-Accuracy:0.633, Test-Error:1.147 -> Test-Accuracy:1.4343\n",
            " Epoch:62 Training-Error:0.621-> Training-Accuracy:0.635, Test-Error:1.718 -> Test-Accuracy:2.1518\n",
            " Epoch:63 Training-Error:0.628-> Training-Accuracy:0.619, Test-Error:2.288 -> Test-Accuracy:2.8699\n",
            " Epoch:64 Training-Error:0.622-> Training-Accuracy:0.637, Test-Error:2.857 -> Test-Accuracy:3.5899\n",
            " Epoch:65 Training-Error:0.616-> Training-Accuracy:0.63, Test-Error:3.424 -> Test-Accuracy:4.3107\n",
            " Epoch:66 Training-Error:0.618-> Training-Accuracy:0.628, Test-Error:3.990 -> Test-Accuracy:5.0336\n",
            " Epoch:67 Training-Error:0.608-> Training-Accuracy:0.642, Test-Error:4.555 -> Test-Accuracy:5.7552\n",
            " Epoch:68 Training-Error:0.608-> Training-Accuracy:0.633, Test-Error:5.118 -> Test-Accuracy:6.4788\n",
            " Epoch:69 Training-Error:0.598-> Training-Accuracy:0.647, Test-Error:5.680 -> Test-Accuracy:7.2039\n",
            " Epoch:70 Training-Error:0.601-> Training-Accuracy:0.646, Test-Error:0.560 -> Test-Accuracy:0.7252\n",
            " Epoch:71 Training-Error:0.608-> Training-Accuracy:0.644, Test-Error:1.120 -> Test-Accuracy:1.4518\n",
            " Epoch:72 Training-Error:0.597-> Training-Accuracy:0.652, Test-Error:1.678 -> Test-Accuracy:2.1776\n",
            " Epoch:73 Training-Error:0.598-> Training-Accuracy:0.661, Test-Error:2.235 -> Test-Accuracy:2.9053\n",
            " Epoch:74 Training-Error:0.593-> Training-Accuracy:0.662, Test-Error:2.791 -> Test-Accuracy:3.6344\n",
            " Epoch:75 Training-Error:0.598-> Training-Accuracy:0.632, Test-Error:3.346 -> Test-Accuracy:4.3641\n",
            " Epoch:76 Training-Error:0.593-> Training-Accuracy:0.666, Test-Error:3.900 -> Test-Accuracy:5.0956\n",
            " Epoch:77 Training-Error:0.587-> Training-Accuracy:0.669, Test-Error:4.452 -> Test-Accuracy:5.83\n",
            " Epoch:78 Training-Error:0.592-> Training-Accuracy:0.655, Test-Error:5.003 -> Test-Accuracy:6.5637\n",
            " Epoch:79 Training-Error:0.584-> Training-Accuracy:0.662, Test-Error:5.553 -> Test-Accuracy:7.298\n",
            " Epoch:80 Training-Error:0.576-> Training-Accuracy:0.673, Test-Error:0.548 -> Test-Accuracy:0.7346\n",
            " Epoch:81 Training-Error:0.590-> Training-Accuracy:0.666, Test-Error:1.096 -> Test-Accuracy:1.4704\n",
            " Epoch:82 Training-Error:0.583-> Training-Accuracy:0.666, Test-Error:1.642 -> Test-Accuracy:2.2066\n",
            " Epoch:83 Training-Error:0.589-> Training-Accuracy:0.644, Test-Error:2.187 -> Test-Accuracy:2.9431\n",
            " Epoch:84 Training-Error:0.578-> Training-Accuracy:0.667, Test-Error:2.732 -> Test-Accuracy:3.6803\n",
            " Epoch:85 Training-Error:0.577-> Training-Accuracy:0.671, Test-Error:3.275 -> Test-Accuracy:4.4171\n",
            " Epoch:86 Training-Error:0.580-> Training-Accuracy:0.653, Test-Error:3.817 -> Test-Accuracy:5.1543\n",
            " Epoch:87 Training-Error:0.585-> Training-Accuracy:0.653, Test-Error:4.358 -> Test-Accuracy:5.8927\n",
            " Epoch:88 Training-Error:0.578-> Training-Accuracy:0.669, Test-Error:4.898 -> Test-Accuracy:6.6315\n",
            " Epoch:89 Training-Error:0.569-> Training-Accuracy:0.672, Test-Error:5.438 -> Test-Accuracy:7.3704\n",
            " Epoch:90 Training-Error:0.569-> Training-Accuracy:0.675, Test-Error:0.538 -> Test-Accuracy:0.7391\n",
            " Epoch:91 Training-Error:0.570-> Training-Accuracy:0.682, Test-Error:1.076 -> Test-Accuracy:1.478\n",
            " Epoch:92 Training-Error:0.557-> Training-Accuracy:0.685, Test-Error:1.612 -> Test-Accuracy:2.2195\n",
            " Epoch:93 Training-Error:0.557-> Training-Accuracy:0.69, Test-Error:2.148 -> Test-Accuracy:2.96\n",
            " Epoch:94 Training-Error:0.557-> Training-Accuracy:0.704, Test-Error:2.682 -> Test-Accuracy:3.7007\n",
            " Epoch:95 Training-Error:0.559-> Training-Accuracy:0.681, Test-Error:3.216 -> Test-Accuracy:4.443\n",
            " Epoch:96 Training-Error:0.556-> Training-Accuracy:0.676, Test-Error:3.749 -> Test-Accuracy:5.1846\n",
            " Epoch:97 Training-Error:0.559-> Training-Accuracy:0.687, Test-Error:4.281 -> Test-Accuracy:5.9269\n",
            " Epoch:98 Training-Error:0.565-> Training-Accuracy:0.675, Test-Error:4.812 -> Test-Accuracy:6.6693\n",
            " Epoch:99 Training-Error:0.559-> Training-Accuracy:0.691, Test-Error:5.342 -> Test-Accuracy:7.4125\n",
            " Epoch:100 Training-Error:0.562-> Training-Accuracy:0.68, Test-Error:0.529 -> Test-Accuracy:0.7445\n",
            " Epoch:101 Training-Error:0.554-> Training-Accuracy:0.68, Test-Error:1.058 -> Test-Accuracy:1.4891\n",
            " Epoch:102 Training-Error:0.555-> Training-Accuracy:0.678, Test-Error:1.585 -> Test-Accuracy:2.2351\n",
            " Epoch:103 Training-Error:0.552-> Training-Accuracy:0.678, Test-Error:2.112 -> Test-Accuracy:2.9822\n",
            " Epoch:104 Training-Error:0.558-> Training-Accuracy:0.679, Test-Error:2.638 -> Test-Accuracy:3.7289\n",
            " Epoch:105 Training-Error:0.566-> Training-Accuracy:0.654, Test-Error:3.164 -> Test-Accuracy:4.4751\n",
            " Epoch:106 Training-Error:0.549-> Training-Accuracy:0.699, Test-Error:3.688 -> Test-Accuracy:5.2233\n",
            " Epoch:107 Training-Error:0.557-> Training-Accuracy:0.684, Test-Error:4.212 -> Test-Accuracy:5.9711\n",
            " Epoch:108 Training-Error:0.544-> Training-Accuracy:0.692, Test-Error:4.735 -> Test-Accuracy:6.7196\n",
            " Epoch:109 Training-Error:0.542-> Training-Accuracy:0.694, Test-Error:5.257 -> Test-Accuracy:7.4667\n",
            " Epoch:110 Training-Error:0.550-> Training-Accuracy:0.669, Test-Error:0.521 -> Test-Accuracy:0.7488\n",
            " Epoch:111 Training-Error:0.544-> Training-Accuracy:0.699, Test-Error:1.041 -> Test-Accuracy:1.4984\n",
            " Epoch:112 Training-Error:0.547-> Training-Accuracy:0.69, Test-Error:1.561 -> Test-Accuracy:2.2499\n",
            " Epoch:113 Training-Error:0.547-> Training-Accuracy:0.69, Test-Error:2.079 -> Test-Accuracy:3.0021\n",
            " Epoch:114 Training-Error:0.551-> Training-Accuracy:0.678, Test-Error:2.597 -> Test-Accuracy:3.7539\n",
            " Epoch:115 Training-Error:0.553-> Training-Accuracy:0.682, Test-Error:3.114 -> Test-Accuracy:4.5053\n",
            " Epoch:116 Training-Error:0.540-> Training-Accuracy:0.704, Test-Error:3.631 -> Test-Accuracy:5.2573\n",
            " Epoch:117 Training-Error:0.541-> Training-Accuracy:0.687, Test-Error:4.147 -> Test-Accuracy:6.0101\n",
            " Epoch:118 Training-Error:0.534-> Training-Accuracy:0.695, Test-Error:4.663 -> Test-Accuracy:6.7635\n",
            " Epoch:119 Training-Error:0.538-> Training-Accuracy:0.714, Test-Error:5.177 -> Test-Accuracy:7.5175\n",
            " Epoch:120 Training-Error:0.532-> Training-Accuracy:0.703, Test-Error:0.513 -> Test-Accuracy:0.7539\n",
            " Epoch:121 Training-Error:0.533-> Training-Accuracy:0.699, Test-Error:1.026 -> Test-Accuracy:1.5082\n",
            " Epoch:122 Training-Error:0.544-> Training-Accuracy:0.675, Test-Error:1.539 -> Test-Accuracy:2.2641\n",
            " Epoch:123 Training-Error:0.534-> Training-Accuracy:0.696, Test-Error:2.051 -> Test-Accuracy:3.0196\n",
            " Epoch:124 Training-Error:0.541-> Training-Accuracy:0.682, Test-Error:2.561 -> Test-Accuracy:3.7766\n",
            " Epoch:125 Training-Error:0.539-> Training-Accuracy:0.705, Test-Error:3.071 -> Test-Accuracy:4.5335\n",
            " Epoch:126 Training-Error:0.545-> Training-Accuracy:0.677, Test-Error:3.581 -> Test-Accuracy:5.2925\n",
            " Epoch:127 Training-Error:0.542-> Training-Accuracy:0.691, Test-Error:4.090 -> Test-Accuracy:6.0497\n",
            " Epoch:128 Training-Error:0.532-> Training-Accuracy:0.697, Test-Error:4.598 -> Test-Accuracy:6.8078\n",
            " Epoch:129 Training-Error:0.533-> Training-Accuracy:0.694, Test-Error:5.105 -> Test-Accuracy:7.5664\n",
            " Epoch:130 Training-Error:0.530-> Training-Accuracy:0.699, Test-Error:0.506 -> Test-Accuracy:0.7595\n",
            " Epoch:131 Training-Error:0.523-> Training-Accuracy:0.709, Test-Error:1.012 -> Test-Accuracy:1.5199\n",
            " Epoch:132 Training-Error:0.523-> Training-Accuracy:0.711, Test-Error:1.518 -> Test-Accuracy:2.2798\n",
            " Epoch:133 Training-Error:0.541-> Training-Accuracy:0.686, Test-Error:2.023 -> Test-Accuracy:3.0388\n",
            " Epoch:134 Training-Error:0.523-> Training-Accuracy:0.715, Test-Error:2.527 -> Test-Accuracy:3.8003\n",
            " Epoch:135 Training-Error:0.525-> Training-Accuracy:0.696, Test-Error:3.031 -> Test-Accuracy:4.5623\n",
            " Epoch:136 Training-Error:0.522-> Training-Accuracy:0.702, Test-Error:3.534 -> Test-Accuracy:5.3214\n",
            " Epoch:137 Training-Error:0.528-> Training-Accuracy:0.698, Test-Error:4.037 -> Test-Accuracy:6.0831\n",
            " Epoch:138 Training-Error:0.517-> Training-Accuracy:0.711, Test-Error:4.539 -> Test-Accuracy:6.8447\n",
            " Epoch:139 Training-Error:0.521-> Training-Accuracy:0.697, Test-Error:5.041 -> Test-Accuracy:7.607\n",
            " Epoch:140 Training-Error:0.521-> Training-Accuracy:0.704, Test-Error:0.500 -> Test-Accuracy:0.7644\n",
            " Epoch:141 Training-Error:0.526-> Training-Accuracy:0.713, Test-Error:1.001 -> Test-Accuracy:1.5284\n",
            " Epoch:142 Training-Error:0.522-> Training-Accuracy:0.697, Test-Error:1.501 -> Test-Accuracy:2.2926\n",
            " Epoch:143 Training-Error:0.515-> Training-Accuracy:0.717, Test-Error:2.000 -> Test-Accuracy:3.057\n",
            " Epoch:144 Training-Error:0.519-> Training-Accuracy:0.719, Test-Error:2.499 -> Test-Accuracy:3.8212\n",
            " Epoch:145 Training-Error:0.526-> Training-Accuracy:0.695, Test-Error:2.997 -> Test-Accuracy:4.5862\n",
            " Epoch:146 Training-Error:0.523-> Training-Accuracy:0.71, Test-Error:3.494 -> Test-Accuracy:5.3513\n",
            " Epoch:147 Training-Error:0.516-> Training-Accuracy:0.712, Test-Error:3.991 -> Test-Accuracy:6.1176\n",
            " Epoch:148 Training-Error:0.520-> Training-Accuracy:0.716, Test-Error:4.487 -> Test-Accuracy:6.8832\n",
            " Epoch:149 Training-Error:0.521-> Training-Accuracy:0.708, Test-Error:4.983 -> Test-Accuracy:7.6481\n",
            " Epoch:150 Training-Error:0.521-> Training-Accuracy:0.705, Test-Error:0.495 -> Test-Accuracy:0.766\n",
            " Epoch:151 Training-Error:0.520-> Training-Accuracy:0.688, Test-Error:0.989 -> Test-Accuracy:1.5312\n",
            " Epoch:152 Training-Error:0.515-> Training-Accuracy:0.707, Test-Error:1.483 -> Test-Accuracy:2.298\n",
            " Epoch:153 Training-Error:0.507-> Training-Accuracy:0.716, Test-Error:1.977 -> Test-Accuracy:3.0636\n",
            " Epoch:154 Training-Error:0.515-> Training-Accuracy:0.718, Test-Error:2.470 -> Test-Accuracy:3.8308\n",
            " Epoch:155 Training-Error:0.519-> Training-Accuracy:0.708, Test-Error:2.963 -> Test-Accuracy:4.5983\n",
            " Epoch:156 Training-Error:0.512-> Training-Accuracy:0.711, Test-Error:3.455 -> Test-Accuracy:5.3661\n",
            " Epoch:157 Training-Error:0.518-> Training-Accuracy:0.703, Test-Error:3.946 -> Test-Accuracy:6.1343\n",
            " Epoch:158 Training-Error:0.514-> Training-Accuracy:0.7, Test-Error:4.437 -> Test-Accuracy:6.9018\n",
            " Epoch:159 Training-Error:0.516-> Training-Accuracy:0.707, Test-Error:4.928 -> Test-Accuracy:7.6707\n",
            " Epoch:160 Training-Error:0.506-> Training-Accuracy:0.724, Test-Error:0.489 -> Test-Accuracy:0.7698\n",
            " Epoch:161 Training-Error:0.521-> Training-Accuracy:0.697, Test-Error:0.979 -> Test-Accuracy:1.5395\n",
            " Epoch:162 Training-Error:0.507-> Training-Accuracy:0.712, Test-Error:1.468 -> Test-Accuracy:2.3104\n",
            " Epoch:163 Training-Error:0.513-> Training-Accuracy:0.721, Test-Error:1.957 -> Test-Accuracy:3.0797\n",
            " Epoch:164 Training-Error:0.507-> Training-Accuracy:0.718, Test-Error:2.444 -> Test-Accuracy:3.8509\n",
            " Epoch:165 Training-Error:0.511-> Training-Accuracy:0.719, Test-Error:2.932 -> Test-Accuracy:4.6212\n",
            " Epoch:166 Training-Error:0.507-> Training-Accuracy:0.713, Test-Error:3.418 -> Test-Accuracy:5.3919\n",
            " Epoch:167 Training-Error:0.503-> Training-Accuracy:0.731, Test-Error:3.905 -> Test-Accuracy:6.1623\n",
            " Epoch:168 Training-Error:0.502-> Training-Accuracy:0.72, Test-Error:4.391 -> Test-Accuracy:6.9333\n",
            " Epoch:169 Training-Error:0.504-> Training-Accuracy:0.71, Test-Error:4.877 -> Test-Accuracy:7.7041\n",
            " Epoch:170 Training-Error:0.507-> Training-Accuracy:0.726, Test-Error:0.485 -> Test-Accuracy:0.7708\n",
            " Epoch:171 Training-Error:0.505-> Training-Accuracy:0.719, Test-Error:0.970 -> Test-Accuracy:1.5432\n",
            " Epoch:172 Training-Error:0.506-> Training-Accuracy:0.712, Test-Error:1.454 -> Test-Accuracy:2.3153\n",
            " Epoch:173 Training-Error:0.505-> Training-Accuracy:0.713, Test-Error:1.938 -> Test-Accuracy:3.0875\n",
            " Epoch:174 Training-Error:0.503-> Training-Accuracy:0.715, Test-Error:2.421 -> Test-Accuracy:3.8601\n",
            " Epoch:175 Training-Error:0.499-> Training-Accuracy:0.72, Test-Error:2.903 -> Test-Accuracy:4.6337\n",
            " Epoch:176 Training-Error:0.501-> Training-Accuracy:0.719, Test-Error:3.385 -> Test-Accuracy:5.4058\n",
            " Epoch:177 Training-Error:0.494-> Training-Accuracy:0.732, Test-Error:3.867 -> Test-Accuracy:6.1803\n",
            " Epoch:178 Training-Error:0.498-> Training-Accuracy:0.72, Test-Error:4.348 -> Test-Accuracy:6.9537\n",
            " Epoch:179 Training-Error:0.503-> Training-Accuracy:0.718, Test-Error:4.828 -> Test-Accuracy:7.7268\n",
            " Epoch:180 Training-Error:0.512-> Training-Accuracy:0.708, Test-Error:0.480 -> Test-Accuracy:0.7733\n",
            " Epoch:181 Training-Error:0.498-> Training-Accuracy:0.73, Test-Error:0.960 -> Test-Accuracy:1.5483\n",
            " Epoch:182 Training-Error:0.494-> Training-Accuracy:0.723, Test-Error:1.439 -> Test-Accuracy:2.3224\n",
            " Epoch:183 Training-Error:0.495-> Training-Accuracy:0.712, Test-Error:1.918 -> Test-Accuracy:3.0973\n",
            " Epoch:184 Training-Error:0.498-> Training-Accuracy:0.729, Test-Error:2.396 -> Test-Accuracy:3.8714\n",
            " Epoch:185 Training-Error:0.497-> Training-Accuracy:0.728, Test-Error:2.874 -> Test-Accuracy:4.6476\n",
            " Epoch:186 Training-Error:0.502-> Training-Accuracy:0.713, Test-Error:3.351 -> Test-Accuracy:5.424\n",
            " Epoch:187 Training-Error:0.501-> Training-Accuracy:0.715, Test-Error:3.829 -> Test-Accuracy:6.2005\n",
            " Epoch:188 Training-Error:0.502-> Training-Accuracy:0.72, Test-Error:4.306 -> Test-Accuracy:6.9765\n",
            " Epoch:189 Training-Error:0.496-> Training-Accuracy:0.723, Test-Error:4.782 -> Test-Accuracy:7.7537\n",
            " Epoch:190 Training-Error:0.499-> Training-Accuracy:0.723, Test-Error:0.475 -> Test-Accuracy:0.7777\n",
            " Epoch:191 Training-Error:0.501-> Training-Accuracy:0.706, Test-Error:0.950 -> Test-Accuracy:1.5545\n",
            " Epoch:192 Training-Error:0.485-> Training-Accuracy:0.725, Test-Error:1.425 -> Test-Accuracy:2.3321\n",
            " Epoch:193 Training-Error:0.493-> Training-Accuracy:0.726, Test-Error:1.900 -> Test-Accuracy:3.1108\n",
            " Epoch:194 Training-Error:0.496-> Training-Accuracy:0.701, Test-Error:2.374 -> Test-Accuracy:3.8898\n",
            " Epoch:195 Training-Error:0.489-> Training-Accuracy:0.736, Test-Error:2.848 -> Test-Accuracy:4.6682\n",
            " Epoch:196 Training-Error:0.492-> Training-Accuracy:0.727, Test-Error:3.321 -> Test-Accuracy:5.446\n",
            " Epoch:197 Training-Error:0.496-> Training-Accuracy:0.725, Test-Error:3.794 -> Test-Accuracy:6.2252\n",
            " Epoch:198 Training-Error:0.481-> Training-Accuracy:0.739, Test-Error:4.266 -> Test-Accuracy:7.0043\n",
            " Epoch:199 Training-Error:0.487-> Training-Accuracy:0.736, Test-Error:4.738 -> Test-Accuracy:7.7842\n",
            " Epoch:200 Training-Error:0.489-> Training-Accuracy:0.715, Test-Error:0.471 -> Test-Accuracy:0.7794\n",
            " Epoch:201 Training-Error:0.491-> Training-Accuracy:0.725, Test-Error:0.942 -> Test-Accuracy:1.5597\n",
            " Epoch:202 Training-Error:0.501-> Training-Accuracy:0.711, Test-Error:1.413 -> Test-Accuracy:2.3397\n",
            " Epoch:203 Training-Error:0.480-> Training-Accuracy:0.739, Test-Error:1.883 -> Test-Accuracy:3.1189\n",
            " Epoch:204 Training-Error:0.490-> Training-Accuracy:0.717, Test-Error:2.354 -> Test-Accuracy:3.8984\n",
            " Epoch:205 Training-Error:0.480-> Training-Accuracy:0.716, Test-Error:2.823 -> Test-Accuracy:4.6789\n",
            " Epoch:206 Training-Error:0.493-> Training-Accuracy:0.722, Test-Error:3.292 -> Test-Accuracy:5.4599\n",
            " Epoch:207 Training-Error:0.489-> Training-Accuracy:0.718, Test-Error:3.761 -> Test-Accuracy:6.2404\n",
            " Epoch:208 Training-Error:0.485-> Training-Accuracy:0.729, Test-Error:4.230 -> Test-Accuracy:7.0218\n",
            " Epoch:209 Training-Error:0.490-> Training-Accuracy:0.701, Test-Error:4.698 -> Test-Accuracy:7.8031\n",
            " Epoch:210 Training-Error:0.488-> Training-Accuracy:0.742, Test-Error:0.467 -> Test-Accuracy:0.78\n",
            " Epoch:211 Training-Error:0.486-> Training-Accuracy:0.727, Test-Error:0.934 -> Test-Accuracy:1.5625\n",
            " Epoch:212 Training-Error:0.487-> Training-Accuracy:0.738, Test-Error:1.402 -> Test-Accuracy:2.3433\n",
            " Epoch:213 Training-Error:0.481-> Training-Accuracy:0.733, Test-Error:1.868 -> Test-Accuracy:3.1261\n",
            " Epoch:214 Training-Error:0.475-> Training-Accuracy:0.751, Test-Error:2.335 -> Test-Accuracy:3.9097\n",
            " Epoch:215 Training-Error:0.486-> Training-Accuracy:0.732, Test-Error:2.800 -> Test-Accuracy:4.6928\n",
            " Epoch:216 Training-Error:0.481-> Training-Accuracy:0.73, Test-Error:3.266 -> Test-Accuracy:5.4771\n",
            " Epoch:217 Training-Error:0.484-> Training-Accuracy:0.725, Test-Error:3.731 -> Test-Accuracy:6.262\n",
            " Epoch:218 Training-Error:0.485-> Training-Accuracy:0.725, Test-Error:4.196 -> Test-Accuracy:7.0483\n",
            " Epoch:219 Training-Error:0.485-> Training-Accuracy:0.737, Test-Error:4.660 -> Test-Accuracy:7.8332\n",
            " Epoch:220 Training-Error:0.484-> Training-Accuracy:0.719, Test-Error:0.463 -> Test-Accuracy:0.7841\n",
            " Epoch:221 Training-Error:0.480-> Training-Accuracy:0.715, Test-Error:0.926 -> Test-Accuracy:1.5682\n",
            " Epoch:222 Training-Error:0.480-> Training-Accuracy:0.735, Test-Error:1.390 -> Test-Accuracy:2.3532\n",
            " Epoch:223 Training-Error:0.487-> Training-Accuracy:0.723, Test-Error:1.852 -> Test-Accuracy:3.1381\n",
            " Epoch:224 Training-Error:0.491-> Training-Accuracy:0.73, Test-Error:2.315 -> Test-Accuracy:3.9226\n",
            " Epoch:225 Training-Error:0.487-> Training-Accuracy:0.719, Test-Error:2.777 -> Test-Accuracy:4.7078\n",
            " Epoch:226 Training-Error:0.477-> Training-Accuracy:0.732, Test-Error:3.239 -> Test-Accuracy:5.4939\n",
            " Epoch:227 Training-Error:0.485-> Training-Accuracy:0.733, Test-Error:3.700 -> Test-Accuracy:6.2799\n",
            " Epoch:228 Training-Error:0.472-> Training-Accuracy:0.741, Test-Error:4.161 -> Test-Accuracy:7.0659\n",
            " Epoch:229 Training-Error:0.484-> Training-Accuracy:0.713, Test-Error:4.622 -> Test-Accuracy:7.8534\n",
            " Epoch:230 Training-Error:0.479-> Training-Accuracy:0.733, Test-Error:0.460 -> Test-Accuracy:0.7875\n",
            " Epoch:231 Training-Error:0.487-> Training-Accuracy:0.727, Test-Error:0.920 -> Test-Accuracy:1.5757\n",
            " Epoch:232 Training-Error:0.478-> Training-Accuracy:0.748, Test-Error:1.379 -> Test-Accuracy:2.3643\n",
            " Epoch:233 Training-Error:0.467-> Training-Accuracy:0.748, Test-Error:1.839 -> Test-Accuracy:3.1534\n",
            " Epoch:234 Training-Error:0.483-> Training-Accuracy:0.724, Test-Error:2.298 -> Test-Accuracy:3.9417\n",
            " Epoch:235 Training-Error:0.479-> Training-Accuracy:0.731, Test-Error:2.756 -> Test-Accuracy:4.7308\n",
            " Epoch:236 Training-Error:0.477-> Training-Accuracy:0.738, Test-Error:3.214 -> Test-Accuracy:5.5203\n",
            " Epoch:237 Training-Error:0.481-> Training-Accuracy:0.721, Test-Error:3.672 -> Test-Accuracy:6.3098\n",
            " Epoch:238 Training-Error:0.483-> Training-Accuracy:0.729, Test-Error:4.129 -> Test-Accuracy:7.101\n",
            " Epoch:239 Training-Error:0.470-> Training-Accuracy:0.749, Test-Error:4.586 -> Test-Accuracy:7.8923\n",
            " Epoch:240 Training-Error:0.477-> Training-Accuracy:0.732, Test-Error:0.456 -> Test-Accuracy:0.7908\n",
            " Epoch:241 Training-Error:0.475-> Training-Accuracy:0.737, Test-Error:0.912 -> Test-Accuracy:1.5808\n",
            " Epoch:242 Training-Error:0.466-> Training-Accuracy:0.749, Test-Error:1.368 -> Test-Accuracy:2.3713\n",
            " Epoch:243 Training-Error:0.468-> Training-Accuracy:0.743, Test-Error:1.824 -> Test-Accuracy:3.1617\n",
            " Epoch:244 Training-Error:0.484-> Training-Accuracy:0.731, Test-Error:2.279 -> Test-Accuracy:3.9525\n",
            " Epoch:245 Training-Error:0.476-> Training-Accuracy:0.728, Test-Error:2.734 -> Test-Accuracy:4.7438\n",
            " Epoch:246 Training-Error:0.476-> Training-Accuracy:0.731, Test-Error:3.188 -> Test-Accuracy:5.5349\n",
            " Epoch:247 Training-Error:0.475-> Training-Accuracy:0.747, Test-Error:3.643 -> Test-Accuracy:6.3259\n",
            " Epoch:248 Training-Error:0.475-> Training-Accuracy:0.737, Test-Error:4.097 -> Test-Accuracy:7.1162\n",
            " Epoch:249 Training-Error:0.474-> Training-Accuracy:0.744, Test-Error:4.551 -> Test-Accuracy:7.9073\n",
            " Epoch:250 Training-Error:0.468-> Training-Accuracy:0.742, Test-Error:0.453 -> Test-Accuracy:0.791\n",
            " Epoch:251 Training-Error:0.479-> Training-Accuracy:0.744, Test-Error:0.906 -> Test-Accuracy:1.5824\n",
            " Epoch:252 Training-Error:0.470-> Training-Accuracy:0.74, Test-Error:1.359 -> Test-Accuracy:2.3743\n",
            " Epoch:253 Training-Error:0.468-> Training-Accuracy:0.739, Test-Error:1.812 -> Test-Accuracy:3.1656\n",
            " Epoch:254 Training-Error:0.478-> Training-Accuracy:0.726, Test-Error:2.264 -> Test-Accuracy:3.9572\n",
            " Epoch:255 Training-Error:0.480-> Training-Accuracy:0.722, Test-Error:2.717 -> Test-Accuracy:4.749\n",
            " Epoch:256 Training-Error:0.467-> Training-Accuracy:0.746, Test-Error:3.169 -> Test-Accuracy:5.5404\n",
            " Epoch:257 Training-Error:0.476-> Training-Accuracy:0.745, Test-Error:3.621 -> Test-Accuracy:6.3331\n",
            " Epoch:258 Training-Error:0.471-> Training-Accuracy:0.73, Test-Error:4.073 -> Test-Accuracy:7.1253\n",
            " Epoch:259 Training-Error:0.469-> Training-Accuracy:0.746, Test-Error:4.525 -> Test-Accuracy:7.917\n",
            " Epoch:260 Training-Error:0.469-> Training-Accuracy:0.743, Test-Error:0.451 -> Test-Accuracy:0.7928\n",
            " Epoch:261 Training-Error:0.472-> Training-Accuracy:0.758, Test-Error:0.902 -> Test-Accuracy:1.5857\n",
            " Epoch:262 Training-Error:0.468-> Training-Accuracy:0.736, Test-Error:1.353 -> Test-Accuracy:2.3796\n",
            " Epoch:263 Training-Error:0.470-> Training-Accuracy:0.735, Test-Error:1.803 -> Test-Accuracy:3.1735\n",
            " Epoch:264 Training-Error:0.482-> Training-Accuracy:0.729, Test-Error:2.254 -> Test-Accuracy:3.967\n",
            " Epoch:265 Training-Error:0.467-> Training-Accuracy:0.728, Test-Error:2.703 -> Test-Accuracy:4.7616\n",
            " Epoch:266 Training-Error:0.473-> Training-Accuracy:0.743, Test-Error:3.153 -> Test-Accuracy:5.5549\n",
            " Epoch:267 Training-Error:0.475-> Training-Accuracy:0.737, Test-Error:3.603 -> Test-Accuracy:6.3494\n",
            " Epoch:268 Training-Error:0.466-> Training-Accuracy:0.731, Test-Error:4.052 -> Test-Accuracy:7.1449\n",
            " Epoch:269 Training-Error:0.470-> Training-Accuracy:0.726, Test-Error:4.501 -> Test-Accuracy:7.9394\n",
            " Epoch:270 Training-Error:0.464-> Training-Accuracy:0.739, Test-Error:0.448 -> Test-Accuracy:0.7947\n",
            " Epoch:271 Training-Error:0.468-> Training-Accuracy:0.738, Test-Error:0.897 -> Test-Accuracy:1.5899\n",
            " Epoch:272 Training-Error:0.452-> Training-Accuracy:0.751, Test-Error:1.346 -> Test-Accuracy:2.3849\n",
            " Epoch:273 Training-Error:0.462-> Training-Accuracy:0.75, Test-Error:1.794 -> Test-Accuracy:3.179\n",
            " Epoch:274 Training-Error:0.465-> Training-Accuracy:0.729, Test-Error:2.242 -> Test-Accuracy:3.9726\n",
            " Epoch:275 Training-Error:0.459-> Training-Accuracy:0.744, Test-Error:2.689 -> Test-Accuracy:4.7674\n",
            " Epoch:276 Training-Error:0.451-> Training-Accuracy:0.765, Test-Error:3.136 -> Test-Accuracy:5.5622\n",
            " Epoch:277 Training-Error:0.465-> Training-Accuracy:0.75, Test-Error:3.584 -> Test-Accuracy:6.3583\n",
            " Epoch:278 Training-Error:0.467-> Training-Accuracy:0.736, Test-Error:4.030 -> Test-Accuracy:7.1534\n",
            " Epoch:279 Training-Error:0.456-> Training-Accuracy:0.744, Test-Error:4.477 -> Test-Accuracy:7.9501\n",
            " Epoch:280 Training-Error:0.461-> Training-Accuracy:0.758, Test-Error:0.446 -> Test-Accuracy:0.796\n",
            " Epoch:281 Training-Error:0.466-> Training-Accuracy:0.743, Test-Error:0.892 -> Test-Accuracy:1.5913\n",
            " Epoch:282 Training-Error:0.461-> Training-Accuracy:0.752, Test-Error:1.337 -> Test-Accuracy:2.3877\n",
            " Epoch:283 Training-Error:0.456-> Training-Accuracy:0.761, Test-Error:1.782 -> Test-Accuracy:3.186\n",
            " Epoch:284 Training-Error:0.463-> Training-Accuracy:0.74, Test-Error:2.228 -> Test-Accuracy:3.9855\n",
            " Epoch:285 Training-Error:0.464-> Training-Accuracy:0.733, Test-Error:2.672 -> Test-Accuracy:4.7832\n",
            " Epoch:286 Training-Error:0.460-> Training-Accuracy:0.749, Test-Error:3.117 -> Test-Accuracy:5.5829\n",
            " Epoch:287 Training-Error:0.459-> Training-Accuracy:0.756, Test-Error:3.561 -> Test-Accuracy:6.3837\n",
            " Epoch:288 Training-Error:0.462-> Training-Accuracy:0.743, Test-Error:4.005 -> Test-Accuracy:7.1826\n",
            " Epoch:289 Training-Error:0.462-> Training-Accuracy:0.749, Test-Error:4.448 -> Test-Accuracy:7.983\n",
            " Epoch:290 Training-Error:0.467-> Training-Accuracy:0.752, Test-Error:0.443 -> Test-Accuracy:0.7997\n",
            " Epoch:291 Training-Error:0.463-> Training-Accuracy:0.731, Test-Error:0.886 -> Test-Accuracy:1.5997\n",
            " Epoch:292 Training-Error:0.460-> Training-Accuracy:0.738, Test-Error:1.329 -> Test-Accuracy:2.4001\n",
            " Epoch:293 Training-Error:0.462-> Training-Accuracy:0.734, Test-Error:1.772 -> Test-Accuracy:3.2014\n",
            " Epoch:294 Training-Error:0.451-> Training-Accuracy:0.749, Test-Error:2.214 -> Test-Accuracy:4.0015\n",
            " Epoch:295 Training-Error:0.462-> Training-Accuracy:0.744, Test-Error:2.656 -> Test-Accuracy:4.802\n",
            " Epoch:296 Training-Error:0.463-> Training-Accuracy:0.753, Test-Error:3.098 -> Test-Accuracy:5.6036\n",
            " Epoch:297 Training-Error:0.465-> Training-Accuracy:0.748, Test-Error:3.540 -> Test-Accuracy:6.404\n",
            " Epoch:298 Training-Error:0.463-> Training-Accuracy:0.739, Test-Error:3.981 -> Test-Accuracy:7.2046\n",
            " Epoch:299 Training-Error:0.453-> Training-Accuracy:0.747, Test-Error:0.441 -> Test-Accuracy:0.8012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKraEWJ0-uMG"
      },
      "source": [
        "### Plot the results and confusion matrix\n",
        "\n",
        "Epoch:229 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2WCDJclINjk",
        "outputId": "a780bdc0-4f89-43c9-ea65-c690f878f171"
      },
      "source": [
        "import numpy as np, sys\n",
        "\n",
        "class Relu:\n",
        "  def __call__(self, input_):\n",
        "      self.input_ = input_\n",
        "      self.output = np.clip(self.input_, 0, None)\n",
        "      return self.output\n",
        "  \n",
        "  def backward(self, output_gradient):\n",
        "    # import pdb; pdb.set_trace()  # By the way, this is how you can debug\n",
        "    self.input_gradient = (self.input_ > 0) * output_gradient\n",
        "    return self.input_gradient\n",
        "\n",
        "class MSE:\n",
        "  def __call__(self, y_pred, y_true):\n",
        "    self.y_pred = y_pred\n",
        "    self.y_true = y_true\n",
        "    return ((y_pred - y_true) ** 2).mean()\n",
        "\n",
        "  def backward(self):\n",
        "    n = self.y_true.shape[0]\n",
        "    self.gradient = 2. * (self.y_pred - self.y_true) / n\n",
        "    # print('MSE backward', self.y_pred.shape, self.y_true.shape, self.gradient.shape)\n",
        "    return self.gradient\n",
        "\n",
        "\n",
        "class Linear:\n",
        "  def __init__(self, input: int, hidden_size: int = 10):\n",
        "\n",
        "    # The initialization is important to properly deal with different\n",
        "    # input sizes (otherwise gradients quickly go to 0).\n",
        "    self.weights = np.random.randn(input, hidden_size) * np.sqrt(2. / input)\n",
        "    self.bias = np.zeros(hidden_size)\n",
        "  \n",
        "  \n",
        "  def __call__(self, x):\n",
        "    self.x = x\n",
        "    # print(x.shape)\n",
        "    # print(self.weights.shape)\n",
        "    output = x @ self.weights + self.bias\n",
        "    return output\n",
        "\n",
        "  def backward(self, gradient):\n",
        "    self.weights_gradient = self.x.T @ gradient\n",
        "    self.bias_gradient = gradient.sum(axis=0)\n",
        "    self.x_gradient = gradient @ self.weights.T\n",
        "    return self.x_gradient\n",
        "\n",
        "  def update(self, lr):\n",
        "    self.weights = self.weights - lr * self.weights_gradient\n",
        "    self.bias = self.bias - lr * self.bias_gradient\n",
        "\n",
        "\n",
        "class Model():\n",
        "\n",
        "  def __init__(self, input, hidden_size, output):\n",
        "    self.linear1 = Linear(input, hidden_size)\n",
        "    self.relu1 = Relu()\n",
        "    self.relu2 = Relu()\n",
        "    self.linear2 = Linear(hidden_size, output)\n",
        "\n",
        "  def __call__(self, input):\n",
        "    l1 = self.linear1(input)\n",
        "    r1 = self.relu1(l1)\n",
        "    r2 = self.relu2(r1)\n",
        "    l2 = self.linear2(r2)\n",
        "    return l2\n",
        "\n",
        "  #Activation Function\n",
        "  def Relu(x):\n",
        "      # returns x if x > 0\n",
        "      return ( x >= 0 ) * x\n",
        "\n",
        "  def Relu_derivative(out):\n",
        "      # returns 1 for input > 0\n",
        "      return out >= 0 \n",
        "\n",
        "  def backward(self, output_gradient):\n",
        "    linear2_gradient = self.linear2.backward(output_gradient)\n",
        "    relu2_gradient = self.relu2.backward(linear2_gradient)\n",
        "    relu1_gradient = self.relu1.backward(relu2_gradient)\n",
        "    linear1_gradient = self.linear1.backward(relu1_gradient)\n",
        "    # print('Model backward', linear2_gradient.shape, relu_gradient.shape, linear1_gradient.shape)\n",
        "    # import pdb; pdb.set_trace()\n",
        "    return linear1_gradient\n",
        "\n",
        "  def update(self, lr):\n",
        "    self.linear2.update(lr)\n",
        "    self.linear1.update(lr)\n",
        "\n",
        "\n",
        "loss = MSE()\n",
        "digits = digits.reshape(len(digits),28*28) / 255\n",
        "model = Model(784, 300, 10)\n",
        "y_pred = model(digits)\n",
        "loss_value = loss(y_pred, labels)\n",
        "loss_gradient = loss.backward()\n",
        "# print(loss_value)\n",
        "model.backward(loss_gradient)\n",
        "\n",
        "# Initialize Batch size\n",
        "minibatch = 64\n",
        "# Initialize and change parameters learning rate ( 0.005 ~ 0.001)\n",
        "lr, epoch, hidden_size, = (0.01, 235, 100)\n",
        "pixels, numLabels = (784, 10)\n",
        "\n",
        "weights0_1 = 0.2*np.random.random((pixels, hidden_size)) - 0.1\n",
        "weights1_2 = 0.2*np.random.random((hidden_size, numLabels)) - 0.1\n",
        "  \n",
        "for j in range(epoch):\n",
        "    error, correctCnt = (0.0, 0)\n",
        "\n",
        "    # Feed forward through layers 0, 1, and 2 ( 3 layers) with minibatch\n",
        "    for i in range(int(len(digits) / minibatch)):\n",
        "        minibatch_start, minibatch_end = ((i * minibatch), ((i+1)*minibatch))\n",
        "       \n",
        "        # Note : Didnt use dropout it causes some data imbalance during training.\n",
        "        # layer_0 = digits[minibatch_start:minibatch_end]\n",
        "        # layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "        # # Adding Dropout\n",
        "        # dropOut_mask = np.random.randint(2, size=layer_1.shape)\n",
        "        # layer_1 *= dropOut_mask * 2\n",
        "        # layer_2 = np.dot(layer_1, weights1_2)  \n",
        "\n",
        "        x = digits[minibatch_start:minibatch_end]\n",
        "        y = labels[minibatch_start:minibatch_end]\n",
        "        y_pred = model(x)\n",
        "        loss_value = loss(y_pred, y)\n",
        "        print(f'Epoch {epoch}, loss {loss_value}')\n",
        "        gradient_from_loss = loss.backward()\n",
        "        model.backward(gradient_from_loss)\n",
        "        model.update(lr)\n",
        "\n",
        "    # How much did we miss the target value(error)? with minibatch\n",
        "        error += np.sum((labels[minibatch_start:minibatch_end] - y_pred) ** 2)\n",
        "        \n",
        "        for k in range(minibatch):\n",
        "            correctCnt += int(np.argmax(y_pred[k:k+1]) == np.argmax(labels[k:k+1]))\n",
        "            # correctCnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "\n",
        "    # # Compute the gradient descent using relu activation function with minibatch\n",
        "        layer_2_deltaChange = (labels[minibatch_start:minibatch_end] - y_pred) / minibatch\n",
        "        layer_1_deltaChange = layer_2_deltaChange.dot(weights1_2.T) * Relu_derivative(layer_1)\n",
        "\n",
        "    # Adding DropOut\n",
        "        # layer_1_deltaChange *+ dropOut_mask\n",
        "\n",
        "    # # Updating the weights \n",
        "        # weights1_2 += lr * layer_1.T.dot(layer_2_deltaChange)\n",
        "        # weights0_1 += lr * layer_0.T.dot(layer_1_deltaChange)\n",
        "\n",
        "    # Test Digits Sample\n",
        "    if(j % 10 == 0 or j == epoch-1):\n",
        "        testError, testCorrectcnt = (0.0, 0)\n",
        "\n",
        "    for i in range(len(test_digits)):\n",
        "\n",
        "        # Feed forward through layers 0, 1, and 2 ( 3 layers) for test MNIST digit samples\n",
        "        # layer_0 = test_digits[i:i+1]\n",
        "        # layer_1 = Relu(np.dot(layer_0,weights0_1))\n",
        "        # layer_2 = np.dot(layer_1,weights1_2)\n",
        "\n",
        "        # how much did we miss the target value(error)?\n",
        "        testError += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "        testCorrectcnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "    \n",
        "\n",
        "    print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \"-> Training-Accuracy:\" + str(correctCnt/float(len(digits))) + \\\n",
        "          \", Test-Error:\" + str(testError/float(len(test_digits)))[0:5] + \" -> Test-Accuracy:\" + str(testCorrectcnt/float(len(test_digits))))\n",
        "    # print(\"\\r Epoch:\" + str(j) + \" Training-Error:\" + str(error/float(len(digits)))[0:5] + \", Training-Accuracy:\" + str(correctCnt/float(len(digits))))"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 235, loss 0.1\n",
            "Epoch 235, loss 0.09942443207708304\n",
            "Epoch 235, loss 0.09884050735380054\n",
            "Epoch 235, loss 0.09814251863214071\n",
            "Epoch 235, loss 0.09762985465515314\n",
            "Epoch 235, loss 0.0969805116431153\n",
            "Epoch 235, loss 0.09657058221917016\n",
            "Epoch 235, loss 0.09612540732769244\n",
            "Epoch 235, loss 0.0957651560620518\n",
            "Epoch 235, loss 0.09530873333157011\n",
            "Epoch 235, loss 0.09488039302634807\n",
            "Epoch 235, loss 0.09489847854092597\n",
            "Epoch 235, loss 0.09439259635632817\n",
            "Epoch 235, loss 0.0941082006708843\n",
            "Epoch 235, loss 0.09364184308096858\n",
            " Epoch:0 Training-Error:0.925-> Training-Accuracy:0.112, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09347084145030968\n",
            "Epoch 235, loss 0.09312149878273937\n",
            "Epoch 235, loss 0.09296672562005198\n",
            "Epoch 235, loss 0.09282888466816863\n",
            "Epoch 235, loss 0.09253483021715478\n",
            "Epoch 235, loss 0.09211614105174702\n",
            "Epoch 235, loss 0.09221201109818715\n",
            "Epoch 235, loss 0.0921063382694894\n",
            "Epoch 235, loss 0.09205968646915223\n",
            "Epoch 235, loss 0.09175436018989289\n",
            "Epoch 235, loss 0.09154437633680956\n",
            "Epoch 235, loss 0.0919917328130531\n",
            "Epoch 235, loss 0.09161368149473732\n",
            "Epoch 235, loss 0.0914869352191254\n",
            "Epoch 235, loss 0.09108183319355201\n",
            " Epoch:1 Training-Error:0.885-> Training-Accuracy:0.118, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09119541729831959\n",
            "Epoch 235, loss 0.09092875097402528\n",
            "Epoch 235, loss 0.0909812576322594\n",
            "Epoch 235, loss 0.09100193091424919\n",
            "Epoch 235, loss 0.09079934005116129\n",
            "Epoch 235, loss 0.09044903127004914\n",
            "Epoch 235, loss 0.09071442995663889\n",
            "Epoch 235, loss 0.09070511627967523\n",
            "Epoch 235, loss 0.09079269610346716\n",
            "Epoch 235, loss 0.09052601831129019\n",
            "Epoch 235, loss 0.09041404674102302\n",
            "Epoch 235, loss 0.09098672281392646\n",
            "Epoch 235, loss 0.0906613094936243\n",
            "Epoch 235, loss 0.09058830175569409\n",
            "Epoch 235, loss 0.0901801652072581\n",
            " Epoch:2 Training-Error:0.870-> Training-Accuracy:0.105, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09041811634291143\n",
            "Epoch 235, loss 0.09014475002931036\n",
            "Epoch 235, loss 0.09032179801025789\n",
            "Epoch 235, loss 0.09036157744136626\n",
            "Epoch 235, loss 0.09021388256064218\n",
            "Epoch 235, loss 0.08988670657669143\n",
            "Epoch 235, loss 0.09019605832091618\n",
            "Epoch 235, loss 0.09020144376784961\n",
            "Epoch 235, loss 0.09035571232563933\n",
            "Epoch 235, loss 0.09009832003953752\n",
            "Epoch 235, loss 0.09004029912361913\n",
            "Epoch 235, loss 0.09062720955072869\n",
            "Epoch 235, loss 0.09033142127821694\n",
            "Epoch 235, loss 0.0902800226210048\n",
            "Epoch 235, loss 0.08985783472355867\n",
            " Epoch:3 Training-Error:0.866-> Training-Accuracy:0.105, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09015334333424903\n",
            "Epoch 235, loss 0.08985243064720208\n",
            "Epoch 235, loss 0.09011384360028676\n",
            "Epoch 235, loss 0.09012958575682876\n",
            "Epoch 235, loss 0.0900222210102315\n",
            "Epoch 235, loss 0.08970616589042169\n",
            "Epoch 235, loss 0.09001492948276589\n",
            "Epoch 235, loss 0.0900106165609283\n",
            "Epoch 235, loss 0.09020262279456406\n",
            "Epoch 235, loss 0.08994811797263806\n",
            "Epoch 235, loss 0.08992418553504587\n",
            "Epoch 235, loss 0.09049016677538996\n",
            "Epoch 235, loss 0.09021477665388014\n",
            "Epoch 235, loss 0.0901747481316879\n",
            "Epoch 235, loss 0.08974059015217521\n",
            " Epoch:4 Training-Error:0.864-> Training-Accuracy:0.105, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09006395201537284\n",
            "Epoch 235, loss 0.08973583724860722\n",
            "Epoch 235, loss 0.09005681097967218\n",
            "Epoch 235, loss 0.09004052830066549\n",
            "Epoch 235, loss 0.08996400602951034\n",
            "Epoch 235, loss 0.08965569060260617\n",
            "Epoch 235, loss 0.0899506964918184\n",
            "Epoch 235, loss 0.08993209832343921\n",
            "Epoch 235, loss 0.09014736523906666\n",
            "Epoch 235, loss 0.08989481892976034\n",
            "Epoch 235, loss 0.08989374775354497\n",
            "Epoch 235, loss 0.09043241006938238\n",
            "Epoch 235, loss 0.09017191210952887\n",
            "Epoch 235, loss 0.09013942146093393\n",
            "Epoch 235, loss 0.08969717316657538\n",
            " Epoch:5 Training-Error:0.863-> Training-Accuracy:0.105, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09003441165002753\n",
            "Epoch 235, loss 0.08968471652712706\n",
            "Epoch 235, loss 0.09004784940081817\n",
            "Epoch 235, loss 0.09000318014049709\n",
            "Epoch 235, loss 0.08994974483373057\n",
            "Epoch 235, loss 0.08964765252899565\n",
            "Epoch 235, loss 0.08992738342480067\n",
            "Epoch 235, loss 0.08989610856396084\n",
            "Epoch 235, loss 0.09012634472706457\n",
            "Epoch 235, loss 0.08987568215448263\n",
            "Epoch 235, loss 0.0898901385706746\n",
            "Epoch 235, loss 0.09040480986180535\n",
            "Epoch 235, loss 0.09015509837626454\n",
            "Epoch 235, loss 0.09012815017609524\n",
            "Epoch 235, loss 0.0896808741487312\n",
            " Epoch:6 Training-Error:0.863-> Training-Accuracy:0.111, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002511660177037\n",
            "Epoch 235, loss 0.08965968897308914\n",
            "Epoch 235, loss 0.09005233520271103\n",
            "Epoch 235, loss 0.08998566370006542\n",
            "Epoch 235, loss 0.08994895038225004\n",
            "Epoch 235, loss 0.08965187069918704\n",
            "Epoch 235, loss 0.08991861022275846\n",
            "Epoch 235, loss 0.08987763538206023\n",
            "Epoch 235, loss 0.09011766352579897\n",
            "Epoch 235, loss 0.08986872213523334\n",
            "Epoch 235, loss 0.08989365334181708\n",
            "Epoch 235, loss 0.09038993472487501\n",
            "Epoch 235, loss 0.09014784041009906\n",
            "Epoch 235, loss 0.09012504106479742\n",
            "Epoch 235, loss 0.08967474876342704\n",
            " Epoch:7 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002251765578717\n",
            "Epoch 235, loss 0.08964609430230748\n",
            "Epoch 235, loss 0.0900591134881856\n",
            "Epoch 235, loss 0.08997646614632665\n",
            "Epoch 235, loss 0.08995150696604592\n",
            "Epoch 235, loss 0.08965832455966152\n",
            "Epoch 235, loss 0.08991512232435706\n",
            "Epoch 235, loss 0.0898672164705991\n",
            "Epoch 235, loss 0.0901136676705713\n",
            "Epoch 235, loss 0.08986615378432386\n",
            "Epoch 235, loss 0.0898980622543902\n",
            "Epoch 235, loss 0.0903811755051179\n",
            "Epoch 235, loss 0.0901443242629761\n",
            "Epoch 235, loss 0.0901245860152469\n",
            "Epoch 235, loss 0.08967250855384439\n",
            " Epoch:8 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002202038345208\n",
            "Epoch 235, loss 0.08963809737631753\n",
            "Epoch 235, loss 0.09006499499530121\n",
            "Epoch 235, loss 0.08997117914202893\n",
            "Epoch 235, loss 0.08995428281877055\n",
            "Epoch 235, loss 0.08966402167042264\n",
            "Epoch 235, loss 0.089913624647158\n",
            "Epoch 235, loss 0.08986095330175611\n",
            "Epoch 235, loss 0.09011160451264846\n",
            "Epoch 235, loss 0.08986518869070592\n",
            "Epoch 235, loss 0.0899016843073222\n",
            "Epoch 235, loss 0.09037574223642661\n",
            "Epoch 235, loss 0.09014242302064948\n",
            "Epoch 235, loss 0.09012489413099822\n",
            "Epoch 235, loss 0.08967176294883934\n",
            " Epoch:9 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002210320212152\n",
            "Epoch 235, loss 0.08963314523128167\n",
            "Epoch 235, loss 0.09006938962485353\n",
            "Epoch 235, loss 0.0899679547169083\n",
            "Epoch 235, loss 0.08995648330798392\n",
            "Epoch 235, loss 0.08966834661134218\n",
            "Epoch 235, loss 0.08991291785530105\n",
            "Epoch 235, loss 0.08985704876883871\n",
            "Epoch 235, loss 0.09011043191958512\n",
            "Epoch 235, loss 0.08986481640778159\n",
            "Epoch 235, loss 0.08990429276819929\n",
            "Epoch 235, loss 0.0903722864392787\n",
            "Epoch 235, loss 0.09014130630274822\n",
            "Epoch 235, loss 0.09012533850558972\n",
            "Epoch 235, loss 0.08967158352708564\n",
            " Epoch:10 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002228950294153\n",
            "Epoch 235, loss 0.08962998873127155\n",
            "Epoch 235, loss 0.09007246798360048\n",
            "Epoch 235, loss 0.08996592278456249\n",
            "Epoch 235, loss 0.08995804610241401\n",
            "Epoch 235, loss 0.08967141818394946\n",
            "Epoch 235, loss 0.08991255027076954\n",
            "Epoch 235, loss 0.08985457100656244\n",
            "Epoch 235, loss 0.09010972106278643\n",
            "Epoch 235, loss 0.08986466658260679\n",
            "Epoch 235, loss 0.08990606080137528\n",
            "Epoch 235, loss 0.09037006767290397\n",
            "Epoch 235, loss 0.09014061623011982\n",
            "Epoch 235, loss 0.09012573142796196\n",
            "Epoch 235, loss 0.08967160512455287\n",
            " Epoch:11 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002244932852868\n",
            "Epoch 235, loss 0.08962794780376315\n",
            "Epoch 235, loss 0.09007455318085782\n",
            "Epoch 235, loss 0.08996462245389737\n",
            "Epoch 235, loss 0.08995909897558188\n",
            "Epoch 235, loss 0.08967352299825282\n",
            "Epoch 235, loss 0.0899123426052386\n",
            "Epoch 235, loss 0.08985298769920566\n",
            "Epoch 235, loss 0.09010927430651275\n",
            "Epoch 235, loss 0.08986460196101868\n",
            "Epoch 235, loss 0.08990722013864821\n",
            "Epoch 235, loss 0.09036864099424152\n",
            "Epoch 235, loss 0.09014017856622608\n",
            "Epoch 235, loss 0.09012603367954793\n",
            "Epoch 235, loss 0.08967168495040624\n",
            " Epoch:12 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002256113900303\n",
            "Epoch 235, loss 0.08962662038009162\n",
            "Epoch 235, loss 0.09007593840254274\n",
            "Epoch 235, loss 0.08996378564735866\n",
            "Epoch 235, loss 0.08995978762750527\n",
            "Epoch 235, loss 0.08967493455665351\n",
            "Epoch 235, loss 0.08991221810741006\n",
            "Epoch 235, loss 0.08985197469208848\n",
            "Epoch 235, loss 0.09010898877229498\n",
            "Epoch 235, loss 0.0898645710827424\n",
            "Epoch 235, loss 0.08990796519244798\n",
            "Epoch 235, loss 0.09036772543089587\n",
            "Epoch 235, loss 0.09013989799821702\n",
            "Epoch 235, loss 0.09012625226948306\n",
            "Epoch 235, loss 0.08967176952824182\n",
            " Epoch:13 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002263262558799\n",
            "Epoch 235, loss 0.08962575581162809\n",
            "Epoch 235, loss 0.0900768474131266\n",
            "Epoch 235, loss 0.08996324684303256\n",
            "Epoch 235, loss 0.08996022982415086\n",
            "Epoch 235, loss 0.08967586789010207\n",
            "Epoch 235, loss 0.08991214064968511\n",
            "Epoch 235, loss 0.08985132753932543\n",
            "Epoch 235, loss 0.0901088052143834\n",
            "Epoch 235, loss 0.08986455436535139\n",
            "Epoch 235, loss 0.08990843771969578\n",
            "Epoch 235, loss 0.0903671397206263\n",
            "Epoch 235, loss 0.09013971769553494\n",
            "Epoch 235, loss 0.09012640517422453\n",
            "Epoch 235, loss 0.08967184132106351\n",
            " Epoch:14 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002267596901029\n",
            "Epoch 235, loss 0.08962519318811792\n",
            "Epoch 235, loss 0.09007743902391221\n",
            "Epoch 235, loss 0.08996290055240405\n",
            "Epoch 235, loss 0.08996051023905824\n",
            "Epoch 235, loss 0.08967647893307433\n",
            "Epoch 235, loss 0.08991209144772179\n",
            "Epoch 235, loss 0.08985091521413462\n",
            "Epoch 235, loss 0.0901086871870923\n",
            "Epoch 235, loss 0.08986454417302144\n",
            "Epoch 235, loss 0.08990873464987023\n",
            "Epoch 235, loss 0.09036676623399106\n",
            "Epoch 235, loss 0.09013960200854973\n",
            "Epoch 235, loss 0.09012650994449087\n",
            "Epoch 235, loss 0.08967189686650592\n",
            " Epoch:15 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002270123575215\n",
            "Epoch 235, loss 0.08962482774559762\n",
            "Epoch 235, loss 0.09007782179903563\n",
            "Epoch 235, loss 0.0899626786133645\n",
            "Epoch 235, loss 0.08996068644326209\n",
            "Epoch 235, loss 0.08967687606632005\n",
            "Epoch 235, loss 0.08991205986231854\n",
            "Epoch 235, loss 0.08985065329990763\n",
            "Epoch 235, loss 0.09010861147265115\n",
            "Epoch 235, loss 0.08986453738917564\n",
            "Epoch 235, loss 0.08990891996599279\n",
            "Epoch 235, loss 0.09036652873772874\n",
            "Epoch 235, loss 0.09013952802655058\n",
            "Epoch 235, loss 0.09012658070325837\n",
            "Epoch 235, loss 0.08967193774800933\n",
            " Epoch:16 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002271543910095\n",
            "Epoch 235, loss 0.08962459091104086\n",
            "Epoch 235, loss 0.09007806835506156\n",
            "Epoch 235, loss 0.08996253680642445\n",
            "Epoch 235, loss 0.08996079637124671\n",
            "Epoch 235, loss 0.08967713273126517\n",
            "Epoch 235, loss 0.08991203948680729\n",
            "Epoch 235, loss 0.08985048741972577\n",
            "Epoch 235, loss 0.09010856306072125\n",
            "Epoch 235, loss 0.0898645326327107\n",
            "Epoch 235, loss 0.0899090350036966\n",
            "Epoch 235, loss 0.09036637803298155\n",
            "Epoch 235, loss 0.09013948090055504\n",
            "Epoch 235, loss 0.09012662795256626\n",
            "Epoch 235, loss 0.08967196692256539\n",
            " Epoch:17 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.0900227230991528\n",
            "Epoch 235, loss 0.08962443776817242\n",
            "Epoch 235, loss 0.09007822660139342\n",
            "Epoch 235, loss 0.08996244646877206\n",
            "Epoch 235, loss 0.08996086453422103\n",
            "Epoch 235, loss 0.08967729787532235\n",
            "Epoch 235, loss 0.08991202631511522\n",
            "Epoch 235, loss 0.08985038264067953\n",
            "Epoch 235, loss 0.0901085322115512\n",
            "Epoch 235, loss 0.08986452921035482\n",
            "Epoch 235, loss 0.08990910609135987\n",
            "Epoch 235, loss 0.09036628252369514\n",
            "Epoch 235, loss 0.09013945100272795\n",
            "Epoch 235, loss 0.09012665918852583\n",
            "Epoch 235, loss 0.08967198731280121\n",
            " Epoch:18 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002272700041739\n",
            "Epoch 235, loss 0.08962433894214392\n",
            "Epoch 235, loss 0.09007832785597307\n",
            "Epoch 235, loss 0.08996238907645901\n",
            "Epoch 235, loss 0.08996090656194286\n",
            "Epoch 235, loss 0.0896774037459281\n",
            "Epoch 235, loss 0.08991201779075557\n",
            "Epoch 235, loss 0.08985031660299639\n",
            "Epoch 235, loss 0.09010851261595257\n",
            "Epoch 235, loss 0.08986452672020664\n",
            "Epoch 235, loss 0.08990914983362289\n",
            "Epoch 235, loss 0.09036622201333133\n",
            "Epoch 235, loss 0.09013943211070198\n",
            "Epoch 235, loss 0.09012667963206815\n",
            "Epoch 235, loss 0.08967200135033662\n",
            " Epoch:19 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002272880506196\n",
            "Epoch 235, loss 0.0896242752715473\n",
            "Epoch 235, loss 0.09007839245740386\n",
            "Epoch 235, loss 0.08996235270251181\n",
            "Epoch 235, loss 0.08996093232624644\n",
            "Epoch 235, loss 0.08967747140877763\n",
            "Epoch 235, loss 0.08991201226666645\n",
            "Epoch 235, loss 0.08985027505000101\n",
            "Epoch 235, loss 0.09010850020291737\n",
            "Epoch 235, loss 0.08986452489930964\n",
            "Epoch 235, loss 0.08990917662759544\n",
            "Epoch 235, loss 0.09036618364452784\n",
            "Epoch 235, loss 0.09013942022136169\n",
            "Epoch 235, loss 0.09012669286071036\n",
            "Epoch 235, loss 0.08967201090344668\n",
            " Epoch:20 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002272947980242\n",
            "Epoch 235, loss 0.08962423429401464\n",
            "Epoch 235, loss 0.09007843355020448\n",
            "Epoch 235, loss 0.08996232969680744\n",
            "Epoch 235, loss 0.08996094801710679\n",
            "Epoch 235, loss 0.0896775145363213\n",
            "Epoch 235, loss 0.08991200867802641\n",
            "Epoch 235, loss 0.08985024892553203\n",
            "Epoch 235, loss 0.0901084923575775\n",
            "Epoch 235, loss 0.08986452356232959\n",
            "Epoch 235, loss 0.08990919294850748\n",
            "Epoch 235, loss 0.09036615925950989\n",
            "Epoch 235, loss 0.09013941277162336\n",
            "Epoch 235, loss 0.09012670129728337\n",
            "Epoch 235, loss 0.08967201734408892\n",
            " Epoch:21 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002272957287877\n",
            "Epoch 235, loss 0.08962420792829956\n",
            "Epoch 235, loss 0.09007845959801\n",
            "Epoch 235, loss 0.08996231517016681\n",
            "Epoch 235, loss 0.08996095749343519\n",
            "Epoch 235, loss 0.08967754195750033\n",
            "Epoch 235, loss 0.08991200633621842\n",
            "Epoch 235, loss 0.08985023249683018\n",
            "Epoch 235, loss 0.09010848740785474\n",
            "Epoch 235, loss 0.08986452257419857\n",
            "Epoch 235, loss 0.08990920281248131\n",
            "Epoch 235, loss 0.09036614369592413\n",
            "Epoch 235, loss 0.09013940812776897\n",
            "Epoch 235, loss 0.09012670656799625\n",
            "Epoch 235, loss 0.08967202165110841\n",
            " Epoch:22 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002272938660068\n",
            "Epoch 235, loss 0.08962419094909924\n",
            "Epoch 235, loss 0.09007847603458827\n",
            "Epoch 235, loss 0.08996230600822228\n",
            "Epoch 235, loss 0.08996096314941156\n",
            "Epoch 235, loss 0.0896775593503036\n",
            "Epoch 235, loss 0.08991200479643158\n",
            "Epoch 235, loss 0.08985022214635335\n",
            "Epoch 235, loss 0.09010848428886473\n",
            "Epoch 235, loss 0.08986452183565215\n",
            "Epoch 235, loss 0.08990920870249666\n",
            "Epoch 235, loss 0.0903661336934001\n",
            "Epoch 235, loss 0.09013940525261195\n",
            "Epoch 235, loss 0.09012670975660106\n",
            "Epoch 235, loss 0.08967202450918285\n",
            " Epoch:23 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002272908191014\n",
            "Epoch 235, loss 0.08962417998680498\n",
            "Epoch 235, loss 0.09007848634031002\n",
            "Epoch 235, loss 0.08996230023301104\n",
            "Epoch 235, loss 0.08996096646436655\n",
            "Epoch 235, loss 0.08967757035409275\n",
            "Epoch 235, loss 0.08991200377183309\n",
            "Epoch 235, loss 0.08985021559781116\n",
            "Epoch 235, loss 0.09010848232480724\n",
            "Epoch 235, loss 0.0898645212740357\n",
            "Epoch 235, loss 0.08990921214987187\n",
            "Epoch 235, loss 0.09036612719564538\n",
            "Epoch 235, loss 0.0901394034899428\n",
            "Epoch 235, loss 0.09012671158111668\n",
            "Epoch 235, loss 0.08967202639042378\n",
            " Epoch:24 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.090022728740382\n",
            "Epoch 235, loss 0.08962417287385685\n",
            "Epoch 235, loss 0.09007849274010397\n",
            "Epoch 235, loss 0.08996229659161706\n",
            "Epoch 235, loss 0.08996096834906091\n",
            "Epoch 235, loss 0.08967757729506406\n",
            "Epoch 235, loss 0.08991200307779205\n",
            "Epoch 235, loss 0.0898502114225463\n",
            "Epoch 235, loss 0.09010848108807688\n",
            "Epoch 235, loss 0.08986452083666595\n",
            "Epoch 235, loss 0.08990921409721662\n",
            "Epoch 235, loss 0.09036612290689956\n",
            "Epoch 235, loss 0.09013940242579088\n",
            "Epoch 235, loss 0.09012671251491577\n",
            "Epoch 235, loss 0.08967202761689873\n",
            " Epoch:25 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002272840026801\n",
            "Epoch 235, loss 0.08962416821910224\n",
            "Epoch 235, loss 0.09007849665406042\n",
            "Epoch 235, loss 0.08996229429225215\n",
            "Epoch 235, loss 0.08996096936238741\n",
            "Epoch 235, loss 0.08967758165659048\n",
            "Epoch 235, loss 0.08991200259565776\n",
            "Epoch 235, loss 0.08985020872597349\n",
            "Epoch 235, loss 0.09010848030877237\n",
            "Epoch 235, loss 0.08986452048576063\n",
            "Epoch 235, loss 0.08990921512392773\n",
            "Epoch 235, loss 0.09036612001099566\n",
            "Epoch 235, loss 0.09013940179962714\n",
            "Epoch 235, loss 0.09012671286877533\n",
            "Epoch 235, loss 0.08967202840651238\n",
            " Epoch:26 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002272807702949\n",
            "Epoch 235, loss 0.08962416513154939\n",
            "Epoch 235, loss 0.0900784989873655\n",
            "Epoch 235, loss 0.0899622928355823\n",
            "Epoch 235, loss 0.08996096984628549\n",
            "Epoch 235, loss 0.08967758438271287\n",
            "Epoch 235, loss 0.08991200224928513\n",
            "Epoch 235, loss 0.08985020694910756\n",
            "Epoch 235, loss 0.09010847981686868\n",
            "Epoch 235, loss 0.08986452019452287\n",
            "Epoch 235, loss 0.08990921558577536\n",
            "Epoch 235, loss 0.09036611799387481\n",
            "Epoch 235, loss 0.09013940144780785\n",
            "Epoch 235, loss 0.09012671284599057\n",
            "Epoch 235, loss 0.08967202890574273\n",
            " Epoch:27 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002272777476457\n",
            "Epoch 235, loss 0.08962416304163143\n",
            "Epoch 235, loss 0.0900785003163512\n",
            "Epoch 235, loss 0.08996229190729285\n",
            "Epoch 235, loss 0.08996097000936978\n",
            "Epoch 235, loss 0.08967758607321122\n",
            "Epoch 235, loss 0.08991200198985973\n",
            "Epoch 235, loss 0.08985020574333802\n",
            "Epoch 235, loss 0.09010847950542175\n",
            "Epoch 235, loss 0.08986451994414493\n",
            "Epoch 235, loss 0.08990921570106225\n",
            "Epoch 235, loss 0.0903661165316705\n",
            "Epoch 235, loss 0.09013940126770303\n",
            "Epoch 235, loss 0.09012671257913213\n",
            "Epoch 235, loss 0.08967202921254647\n",
            " Epoch:28 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.0900227274923865\n",
            "Epoch 235, loss 0.08962416158588796\n",
            "Epoch 235, loss 0.09007850100761947\n",
            "Epoch 235, loss 0.08996229130986359\n",
            "Epoch 235, loss 0.08996096997857131\n",
            "Epoch 235, loss 0.08967758710858664\n",
            "Epoch 235, loss 0.08991200178611206\n",
            "Epoch 235, loss 0.08985020489164205\n",
            "Epoch 235, loss 0.09010847930724177\n",
            "Epoch 235, loss 0.08986451972155238\n",
            "Epoch 235, loss 0.08990921560368637\n",
            "Epoch 235, loss 0.09036611542022902\n",
            "Epoch 235, loss 0.09013940119502377\n",
            "Epoch 235, loss 0.09012671215441562\n",
            "Epoch 235, loss 0.08967202939215915\n",
            " Epoch:29 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002272722683388\n",
            "Epoch 235, loss 0.08962416053275363\n",
            "Epoch 235, loss 0.09007850129417541\n",
            "Epoch 235, loss 0.08996229091935734\n",
            "Epoch 235, loss 0.08996096983091784\n",
            "Epoch 235, loss 0.08967758772992232\n",
            "Epoch 235, loss 0.0899120016180214\n",
            "Epoch 235, loss 0.08985020425913992\n",
            "Epoch 235, loss 0.09010847918014876\n",
            "Epoch 235, loss 0.089864519517735\n",
            "Epoch 235, loss 0.0899092153757636\n",
            "Epoch 235, loss 0.09036611453075995\n",
            "Epoch 235, loss 0.09013940118953344\n",
            "Epoch 235, loss 0.09012671162777688\n",
            "Epoch 235, loss 0.08967202948787771\n",
            " Epoch:30 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002272697464286\n",
            "Epoch 235, loss 0.08962415973491229\n",
            "Epoch 235, loss 0.09007850132401064\n",
            "Epoch 235, loss 0.08996229065811487\n",
            "Epoch 235, loss 0.08996096961303186\n",
            "Epoch 235, loss 0.08967758808979748\n",
            "Epoch 235, loss 0.08991200147277224\n",
            "Epoch 235, loss 0.08985020376213568\n",
            "Epoch 235, loss 0.09010847909767623\n",
            "Epoch 235, loss 0.08986451932653172\n",
            "Epoch 235, loss 0.08990921506765802\n",
            "Epoch 235, loss 0.09036611378193776\n",
            "Epoch 235, loss 0.09013940122606398\n",
            "Epoch 235, loss 0.09012671103543124\n",
            "Epoch 235, loss 0.08967202952835814\n",
            " Epoch:31 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002272673264192\n",
            "Epoch 235, loss 0.08962415909877228\n",
            "Epoch 235, loss 0.09007850119106567\n",
            "Epoch 235, loss 0.08996229047753632\n",
            "Epoch 235, loss 0.0899609693530585\n",
            "Epoch 235, loss 0.089677588284684\n",
            "Epoch 235, loss 0.08991200134216126\n",
            "Epoch 235, loss 0.0898502033487721\n",
            "Epoch 235, loss 0.09010847904322086\n",
            "Epoch 235, loss 0.08986451914375922\n",
            "Epoch 235, loss 0.08990921471026872\n",
            "Epoch 235, loss 0.09036611312235197\n",
            "Epoch 235, loss 0.09013940128887807\n",
            "Epoch 235, loss 0.09012671040078316\n",
            "Epoch 235, loss 0.08967202953252237\n",
            " Epoch:32 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002272649819679\n",
            "Epoch 235, loss 0.08962415856494817\n",
            "Epoch 235, loss 0.09007850095494119\n",
            "Epoch 235, loss 0.08996229034724301\n",
            "Epoch 235, loss 0.08996096906794293\n",
            "Epoch 235, loss 0.08967758837552608\n",
            "Epoch 235, loss 0.08991200122093648\n",
            "Epoch 235, loss 0.08985020298696553\n",
            "Epoch 235, loss 0.09010847900636645\n",
            "Epoch 235, loss 0.08986451896659502\n",
            "Epoch 235, loss 0.08990921432256209\n",
            "Epoch 235, loss 0.09036611251946328\n",
            "Epoch 235, loss 0.09013940136813663\n",
            "Epoch 235, loss 0.09012670973893389\n",
            "Epoch 235, loss 0.08967202951284078\n",
            " Epoch:33 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002272626923942\n",
            "Epoch 235, loss 0.08962415809580264\n",
            "Epoch 235, loss 0.09007850065343478\n",
            "Epoch 235, loss 0.08996229024826673\n",
            "Epoch 235, loss 0.08996096876785883\n",
            "Epoch 235, loss 0.08967758840079465\n",
            "Epoch 235, loss 0.08991200110573434\n",
            "Epoch 235, loss 0.08985020265689433\n",
            "Epoch 235, loss 0.0901084789805768\n",
            "Epoch 235, loss 0.08986451879314564\n",
            "Epoch 235, loss 0.08990921391618785\n",
            "Epoch 235, loss 0.0903661119526494\n",
            "Epoch 235, loss 0.0901394014576878\n",
            "Epoch 235, loss 0.09012670905961342\n",
            "Epoch 235, loss 0.08967202947751858\n",
            " Epoch:34 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.0900227260442051\n",
            "Epoch 235, loss 0.08962415766750764\n",
            "Epoch 235, loss 0.09007850031050843\n",
            "Epoch 235, loss 0.08996229016877608\n",
            "Epoch 235, loss 0.08996096845889656\n",
            "Epoch 235, loss 0.08967758838475795\n",
            "Epoch 235, loss 0.08991200099439955\n",
            "Epoch 235, loss 0.08985020234632961\n",
            "Epoch 235, loss 0.0901084789617486\n",
            "Epoch 235, loss 0.0898645186221474\n",
            "Epoch 235, loss 0.08990921349830734\n",
            "Epoch 235, loss 0.09036611140882275\n",
            "Epoch 235, loss 0.0901394015536843\n",
            "Epoch 235, loss 0.09012670836908329\n",
            "Epoch 235, loss 0.08967202943194708\n",
            " Epoch:35 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002272582194033\n",
            "Epoch 235, loss 0.08962415726499276\n",
            "Epoch 235, loss 0.0900784999413482\n",
            "Epoch 235, loss 0.08996229010139845\n",
            "Epoch 235, loss 0.08996096814469061\n",
            "Epoch 235, loss 0.08967758834271553\n",
            "Epoch 235, loss 0.08991200088555032\n",
            "Epoch 235, loss 0.0898502020477374\n",
            "Epoch 235, loss 0.09010847894730425\n",
            "Epoch 235, loss 0.08986451845276086\n",
            "Epoch 235, loss 0.08990921307332717\n",
            "Epoch 235, loss 0.09036611087966565\n",
            "Epoch 235, loss 0.09013940165371914\n",
            "Epoch 235, loss 0.09012670767136857\n",
            "Epoch 235, loss 0.08967202937966472\n",
            " Epoch:36 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002272560161115\n",
            "Epoch 235, loss 0.08962415687873544\n",
            "Epoch 235, loss 0.09007849955557597\n",
            "Epoch 235, loss 0.08996229004154399\n",
            "Epoch 235, loss 0.08996096782740264\n",
            "Epoch 235, loss 0.0896775882843075\n",
            "Epoch 235, loss 0.08991200077830004\n",
            "Epoch 235, loss 0.08985020175648292\n",
            "Epoch 235, loss 0.09010847893562342\n",
            "Epoch 235, loss 0.08986451828443084\n",
            "Epoch 235, loss 0.08990921264396175\n",
            "Epoch 235, loss 0.09036611035988432\n",
            "Epoch 235, loss 0.0901394017562857\n",
            "Epoch 235, loss 0.0901267069690543\n",
            "Epoch 235, loss 0.0896720293229915\n",
            " Epoch:37 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002272538262364\n",
            "Epoch 235, loss 0.08962415650272387\n",
            "Epoch 235, loss 0.09007849915928696\n",
            "Epoch 235, loss 0.08996228998635794\n",
            "Epoch 235, loss 0.08996096750831362\n",
            "Epoch 235, loss 0.08967758821560495\n",
            "Epoch 235, loss 0.08991200067207955\n",
            "Epoch 235, loss 0.08985020146971895\n",
            "Epoch 235, loss 0.09010847892568657\n",
            "Epoch 235, loss 0.08986451811679157\n",
            "Epoch 235, loss 0.08990921221188516\n",
            "Epoch 235, loss 0.09036610984610473\n",
            "Epoch 235, loss 0.0901394018604403\n",
            "Epoch 235, loss 0.09012670626379925\n",
            "Epoch 235, loss 0.08967202926344718\n",
            " Epoch:38 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.0900227251645598\n",
            "Epoch 235, loss 0.0896241561331658\n",
            "Epoch 235, loss 0.09007849875634166\n",
            "Epoch 235, loss 0.08996228993406621\n",
            "Epoch 235, loss 0.08996096718817947\n",
            "Epoch 235, loss 0.08967758814042961\n",
            "Epoch 235, loss 0.08991200056652301\n",
            "Epoch 235, loss 0.0898502011856991\n",
            "Epoch 235, loss 0.09010847891685164\n",
            "Epoch 235, loss 0.08986451794960286\n",
            "Epoch 235, loss 0.08990921177813124\n",
            "Epoch 235, loss 0.0903661093361733\n",
            "Epoch 235, loss 0.09013940196559149\n",
            "Epoch 235, loss 0.0901267055566671\n",
            "Epoch 235, loss 0.08967202920202663\n",
            " Epoch:39 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002272494712835\n",
            "Epoch 235, loss 0.08962415576767083\n",
            "Epoch 235, loss 0.09007849834918483\n",
            "Epoch 235, loss 0.08996228988356736\n",
            "Epoch 235, loss 0.0899609668674443\n",
            "Epoch 235, loss 0.0896775880611862\n",
            "Epoch 235, loss 0.08991200046139522\n",
            "Epoch 235, loss 0.08985020090335386\n",
            "Epoch 235, loss 0.09010847890871376\n",
            "Epoch 235, loss 0.08986451778270761\n",
            "Epoch 235, loss 0.0899092113433393\n",
            "Epoch 235, loss 0.09036610882871357\n",
            "Epoch 235, loss 0.09013940207136825\n",
            "Epoch 235, loss 0.09012670484833951\n",
            "Epoch 235, loss 0.08967202913938067\n",
            " Epoch:40 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.090022724730128\n",
            "Epoch 235, loss 0.08962415540473342\n",
            "Epoch 235, loss 0.09007849793936457\n",
            "Epoch 235, loss 0.08996228983417812\n",
            "Epoch 235, loss 0.08996096654636766\n",
            "Epoch 235, loss 0.08967758797938728\n",
            "Epoch 235, loss 0.08991200035654474\n",
            "Epoch 235, loss 0.08985020062202938\n",
            "Epoch 235, loss 0.09010847890101739\n",
            "Epoch 235, loss 0.08986451761600334\n",
            "Epoch 235, loss 0.08990921090790525\n",
            "Epoch 235, loss 0.09036610832284457\n",
            "Epoch 235, loss 0.0901394021775376\n",
            "Epoch 235, loss 0.09012670413925306\n",
            "Epoch 235, loss 0.08967202907593481\n",
            " Epoch:41 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.0900227245134205\n",
            "Epoch 235, loss 0.0896241550434059\n",
            "Epoch 235, loss 0.09007849752786105\n",
            "Epoch 235, loss 0.08996228978547491\n",
            "Epoch 235, loss 0.0899609662251003\n",
            "Epoch 235, loss 0.0896775878959839\n",
            "Epoch 235, loss 0.08991200025187401\n",
            "Epoch 235, loss 0.08985020034132654\n",
            "Epoch 235, loss 0.09010847889360103\n",
            "Epoch 235, loss 0.08986451744942338\n",
            "Epoch 235, loss 0.0899092104720747\n",
            "Epoch 235, loss 0.09036610781800167\n",
            "Epoch 235, loss 0.09013940228395319\n",
            "Epoch 235, loss 0.09012670342968723\n",
            "Epoch 235, loss 0.0896720290119671\n",
            " Epoch:42 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002272429691154\n",
            "Epoch 235, loss 0.08962415468309218\n",
            "Epoch 235, loss 0.09007849711529496\n",
            "Epoch 235, loss 0.0899622897371956\n",
            "Epoch 235, loss 0.08996096590372923\n",
            "Epoch 235, loss 0.08967758781157384\n",
            "Epoch 235, loss 0.08991200014732015\n",
            "Epoch 235, loss 0.08985020006100226\n",
            "Epoch 235, loss 0.09010847888636249\n",
            "Epoch 235, loss 0.08986451728292444\n",
            "Epoch 235, loss 0.08990921003600018\n",
            "Epoch 235, loss 0.0903661073138226\n",
            "Epoch 235, loss 0.09013940239052293\n",
            "Epoch 235, loss 0.0901267027198209\n",
            "Epoch 235, loss 0.08967202894765913\n",
            " Epoch:43 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002272408053709\n",
            "Epoch 235, loss 0.0896241543234175\n",
            "Epoch 235, loss 0.09007849670205918\n",
            "Epoch 235, loss 0.08996228968917787\n",
            "Epoch 235, loss 0.08996096558230418\n",
            "Epoch 235, loss 0.08967758772653274\n",
            "Epoch 235, loss 0.08991200004284254\n",
            "Epoch 235, loss 0.08985019978090877\n",
            "Epoch 235, loss 0.09010847887923701\n",
            "Epoch 235, loss 0.08986451711647855\n",
            "Epoch 235, loss 0.08990920959977665\n",
            "Epoch 235, loss 0.09036610681007458\n",
            "Epoch 235, loss 0.09013940249718877\n",
            "Epoch 235, loss 0.09012670200976851\n",
            "Epoch 235, loss 0.08967202888312946\n",
            " Epoch:44 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002272386425386\n",
            "Epoch 235, loss 0.08962415396414644\n",
            "Epoch 235, loss 0.09007849628840256\n",
            "Epoch 235, loss 0.08996228964132147\n",
            "Epoch 235, loss 0.08996096526085332\n",
            "Epoch 235, loss 0.08967758764109653\n",
            "Epoch 235, loss 0.089911999938415\n",
            "Epoch 235, loss 0.08985019950095643\n",
            "Epoch 235, loss 0.09010847887218351\n",
            "Epoch 235, loss 0.08986451695006765\n",
            "Epoch 235, loss 0.08990920916346327\n",
            "Epoch 235, loss 0.0903661063066079\n",
            "Epoch 235, loss 0.09013940260391422\n",
            "Epoch 235, loss 0.09012670129960325\n",
            "Epoch 235, loss 0.08967202881845553\n",
            " Epoch:45 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002272364803268\n",
            "Epoch 235, loss 0.08962415360513115\n",
            "Epoch 235, loss 0.0900784958744826\n",
            "Epoch 235, loss 0.08996228959356449\n",
            "Epoch 235, loss 0.08996096493939247\n",
            "Epoch 235, loss 0.0896775875554134\n",
            "Epoch 235, loss 0.08991199983402057\n",
            "Epoch 235, loss 0.08985019922109101\n",
            "Epoch 235, loss 0.09010847886517592\n",
            "Epoch 235, loss 0.08986451678368007\n",
            "Epoch 235, loss 0.08990920872709701\n",
            "Epoch 235, loss 0.09036610580332616\n",
            "Epoch 235, loss 0.09013940271067619\n",
            "Epoch 235, loss 0.09012670058937192\n",
            "Epoch 235, loss 0.08967202875368778\n",
            " Epoch:46 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002272343185404\n",
            "Epoch 235, loss 0.0896241532462789\n",
            "Epoch 235, loss 0.09007849546039906\n",
            "Epoch 235, loss 0.08996228954586871\n",
            "Epoch 235, loss 0.08996096461793028\n",
            "Epoch 235, loss 0.08967758746957641\n",
            "Epoch 235, loss 0.08991199972964828\n",
            "Epoch 235, loss 0.08985019894127977\n",
            "Epoch 235, loss 0.0901084788581976\n",
            "Epoch 235, loss 0.08986451661730832\n",
            "Epoch 235, loss 0.08990920829070093\n",
            "Epoch 235, loss 0.09036610530016727\n",
            "Epoch 235, loss 0.0901394028174601\n",
            "Epoch 235, loss 0.09012669987910442\n",
            "Epoch 235, loss 0.08967202868885915\n",
            " Epoch:47 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002272321570479\n",
            "Epoch 235, loss 0.08962415288753146\n",
            "Epoch 235, loss 0.09007849504621508\n",
            "Epoch 235, loss 0.0899622894982106\n",
            "Epoch 235, loss 0.08996096429647145\n",
            "Epoch 235, loss 0.08967758738364391\n",
            "Epoch 235, loss 0.08991199962529102\n",
            "Epoch 235, loss 0.08985019866150297\n",
            "Epoch 235, loss 0.090108478851238\n",
            "Epoch 235, loss 0.08986451645094759\n",
            "Epoch 235, loss 0.08990920785428953\n",
            "Epoch 235, loss 0.09036610479709109\n",
            "Epoch 235, loss 0.0901394029242567\n",
            "Epoch 235, loss 0.09012669916881991\n",
            "Epoch 235, loss 0.08967202862399111\n",
            " Epoch:48 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002272299957623\n",
            "Epoch 235, loss 0.08962415252885235\n",
            "Epoch 235, loss 0.09007849463197072\n",
            "Epoch 235, loss 0.08996228945057567\n",
            "Epoch 235, loss 0.08996096397501843\n",
            "Epoch 235, loss 0.0896775872976526\n",
            "Epoch 235, loss 0.0899119995209442\n",
            "Epoch 235, loss 0.08985019838174886\n",
            "Epoch 235, loss 0.09010847884429038\n",
            "Epoch 235, loss 0.0898645162845948\n",
            "Epoch 235, loss 0.08990920741787188\n",
            "Epoch 235, loss 0.09036610429407178\n",
            "Epoch 235, loss 0.09013940303106023\n",
            "Epoch 235, loss 0.09012669845853058\n",
            "Epoch 235, loss 0.08967202855909764\n",
            " Epoch:49 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.0900227227834626\n",
            "Epoch 235, loss 0.08962415217021873\n",
            "Epoch 235, loss 0.09007849421769125\n",
            "Epoch 235, loss 0.08996228940295503\n",
            "Epoch 235, loss 0.08996096365357245\n",
            "Epoch 235, loss 0.08967758721162544\n",
            "Epoch 235, loss 0.08991199941660483\n",
            "Epoch 235, loss 0.08985019810201036\n",
            "Epoch 235, loss 0.09010847883735043\n",
            "Epoch 235, loss 0.08986451611824796\n",
            "Epoch 235, loss 0.08990920698145369\n",
            "Epoch 235, loss 0.09036610379109263\n",
            "Epoch 235, loss 0.09013940313786692\n",
            "Epoch 235, loss 0.09012669774824426\n",
            "Epoch 235, loss 0.08967202849418787\n",
            " Epoch:50 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002272256735996\n",
            "Epoch 235, loss 0.08962415181161625\n",
            "Epoch 235, loss 0.09007849380339276\n",
            "Epoch 235, loss 0.08996228935534319\n",
            "Epoch 235, loss 0.0899609633321341\n",
            "Epoch 235, loss 0.08967758712557683\n",
            "Epoch 235, loss 0.08991199931227103\n",
            "Epoch 235, loss 0.08985019782228328\n",
            "Epoch 235, loss 0.0901084788304154\n",
            "Epoch 235, loss 0.08986451595190584\n",
            "Epoch 235, loss 0.08990920654503856\n",
            "Epoch 235, loss 0.09036610328814276\n",
            "Epoch 235, loss 0.09013940324467444\n",
            "Epoch 235, loss 0.09012669703796597\n",
            "Epoch 235, loss 0.08967202842926773\n",
            " Epoch:51 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002272235126581\n",
            "Epoch 235, loss 0.08962415145303596\n",
            "Epoch 235, loss 0.09007849338908544\n",
            "Epoch 235, loss 0.08996228930773678\n",
            "Epoch 235, loss 0.08996096301070364\n",
            "Epoch 235, loss 0.08967758703951585\n",
            "Epoch 235, loss 0.08991199920794146\n",
            "Epoch 235, loss 0.0898501975425651\n",
            "Epoch 235, loss 0.09010847882348352\n",
            "Epoch 235, loss 0.08986451578556762\n",
            "Epoch 235, loss 0.08990920610862875\n",
            "Epoch 235, loss 0.09036610278521522\n",
            "Epoch 235, loss 0.09013940335148132\n",
            "Epoch 235, loss 0.09012669632769886\n",
            "Epoch 235, loss 0.0896720283643411\n",
            " Epoch:52 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002272213517845\n",
            "Epoch 235, loss 0.08962415109447226\n",
            "Epoch 235, loss 0.09007849297477569\n",
            "Epoch 235, loss 0.0899622892601338\n",
            "Epoch 235, loss 0.08996096268928114\n",
            "Epoch 235, loss 0.08967758695344813\n",
            "Epoch 235, loss 0.08991199910361537\n",
            "Epoch 235, loss 0.0898501972628544\n",
            "Epoch 235, loss 0.09010847881655365\n",
            "Epoch 235, loss 0.08986451561923278\n",
            "Epoch 235, loss 0.08990920567222568\n",
            "Epoch 235, loss 0.09036610228230547\n",
            "Epoch 235, loss 0.0901394034582866\n",
            "Epoch 235, loss 0.09012669561744499\n",
            "Epoch 235, loss 0.0896720282994105\n",
            " Epoch:53 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002272191909676\n",
            "Epoch 235, loss 0.08962415073592164\n",
            "Epoch 235, loss 0.09007849256046759\n",
            "Epoch 235, loss 0.08996228921253295\n",
            "Epoch 235, loss 0.08996096236786659\n",
            "Epoch 235, loss 0.08967758686737726\n",
            "Epoch 235, loss 0.08991199899929223\n",
            "Epoch 235, loss 0.0898501969831503\n",
            "Epoch 235, loss 0.0901084788096251\n",
            "Epoch 235, loss 0.08986451545290106\n",
            "Epoch 235, loss 0.08990920523583028\n",
            "Epoch 235, loss 0.09036610177941055\n",
            "Epoch 235, loss 0.09013940356508963\n",
            "Epoch 235, loss 0.09012669490720567\n",
            "Epoch 235, loss 0.08967202823447756\n",
            " Epoch:54 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002272170302002\n",
            "Epoch 235, loss 0.08962415037738189\n",
            "Epoch 235, loss 0.09007849214616374\n",
            "Epoch 235, loss 0.08996228916493348\n",
            "Epoch 235, loss 0.08996096204645995\n",
            "Epoch 235, loss 0.08967758678130541\n",
            "Epoch 235, loss 0.08991199889497165\n",
            "Epoch 235, loss 0.08985019670345233\n",
            "Epoch 235, loss 0.09010847880269737\n",
            "Epoch 235, loss 0.08986451528657216\n",
            "Epoch 235, loss 0.08990920479944312\n",
            "Epoch 235, loss 0.09036610127652858\n",
            "Epoch 235, loss 0.0901394036718901\n",
            "Epoch 235, loss 0.0901266941969817\n",
            "Epoch 235, loss 0.08967202816954337\n",
            " Epoch:55 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.0900227214869477\n",
            "Epoch 235, loss 0.08962415001885163\n",
            "Epoch 235, loss 0.0900784917318658\n",
            "Epoch 235, loss 0.08996228911733492\n",
            "Epoch 235, loss 0.08996096172506121\n",
            "Epoch 235, loss 0.08967758669523404\n",
            "Epoch 235, loss 0.08991199879065345\n",
            "Epoch 235, loss 0.08985019642376017\n",
            "Epoch 235, loss 0.09010847879577018\n",
            "Epoch 235, loss 0.08986451512024599\n",
            "Epoch 235, loss 0.08990920436306453\n",
            "Epoch 235, loss 0.09036610077365831\n",
            "Epoch 235, loss 0.09013940377868772\n",
            "Epoch 235, loss 0.09012669348677366\n",
            "Epoch 235, loss 0.08967202810460857\n",
            " Epoch:56 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002272127087954\n",
            "Epoch 235, loss 0.08962414966033004\n",
            "Epoch 235, loss 0.09007849131757478\n",
            "Epoch 235, loss 0.089962289069737\n",
            "Epoch 235, loss 0.0899609614036703\n",
            "Epoch 235, loss 0.089677586609164\n",
            "Epoch 235, loss 0.08991199868633745\n",
            "Epoch 235, loss 0.0898501961440737\n",
            "Epoch 235, loss 0.09010847878884334\n",
            "Epoch 235, loss 0.08986451495392248\n",
            "Epoch 235, loss 0.0899092039266948\n",
            "Epoch 235, loss 0.09036610027079894\n",
            "Epoch 235, loss 0.09013940388548233\n",
            "Epoch 235, loss 0.09012669277658186\n",
            "Epoch 235, loss 0.08967202803967367\n",
            " Epoch:57 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.0900227210548153\n",
            "Epoch 235, loss 0.08962414930181654\n",
            "Epoch 235, loss 0.09007849090329136\n",
            "Epoch 235, loss 0.08996228902213951\n",
            "Epoch 235, loss 0.08996096108228721\n",
            "Epoch 235, loss 0.0896775865230958\n",
            "Epoch 235, loss 0.0899119985820236\n",
            "Epoch 235, loss 0.08985019586439279\n",
            "Epoch 235, loss 0.09010847878191672\n",
            "Epoch 235, loss 0.08986451478760156\n",
            "Epoch 235, loss 0.08990920349033397\n",
            "Epoch 235, loss 0.09036609976794995\n",
            "Epoch 235, loss 0.09013940399227387\n",
            "Epoch 235, loss 0.09012669206640654\n",
            "Epoch 235, loss 0.08967202797473894\n",
            " Epoch:58 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002272083875487\n",
            "Epoch 235, loss 0.08962414894331086\n",
            "Epoch 235, loss 0.09007849048901592\n",
            "Epoch 235, loss 0.08996228897454242\n",
            "Epoch 235, loss 0.08996096076091191\n",
            "Epoch 235, loss 0.08967758643702983\n",
            "Epoch 235, loss 0.08991199847771181\n",
            "Epoch 235, loss 0.08985019558471741\n",
            "Epoch 235, loss 0.09010847877499026\n",
            "Epoch 235, loss 0.08986451462128317\n",
            "Epoch 235, loss 0.08990920305398227\n",
            "Epoch 235, loss 0.09036609926511101\n",
            "Epoch 235, loss 0.09013940409906222\n",
            "Epoch 235, loss 0.09012669135624782\n",
            "Epoch 235, loss 0.08967202790980455\n",
            " Epoch:59 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002272062269812\n",
            "Epoch 235, loss 0.08962414858481271\n",
            "Epoch 235, loss 0.09007849007474882\n",
            "Epoch 235, loss 0.08996228892694558\n",
            "Epoch 235, loss 0.08996096043954438\n",
            "Epoch 235, loss 0.0896775863509663\n",
            "Epoch 235, loss 0.089911998373402\n",
            "Epoch 235, loss 0.08985019530504754\n",
            "Epoch 235, loss 0.09010847876806387\n",
            "Epoch 235, loss 0.08986451445496736\n",
            "Epoch 235, loss 0.08990920261763966\n",
            "Epoch 235, loss 0.0903660987622819\n",
            "Epoch 235, loss 0.0901394042058474\n",
            "Epoch 235, loss 0.09012669064610579\n",
            "Epoch 235, loss 0.08967202784487067\n",
            " Epoch:60 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002272040664501\n",
            "Epoch 235, loss 0.08962414822632203\n",
            "Epoch 235, loss 0.09007848966049012\n",
            "Epoch 235, loss 0.08996228887934898\n",
            "Epoch 235, loss 0.08996096011818461\n",
            "Epoch 235, loss 0.08967758626490532\n",
            "Epoch 235, loss 0.08991199826909421\n",
            "Epoch 235, loss 0.08985019502538313\n",
            "Epoch 235, loss 0.09010847876113755\n",
            "Epoch 235, loss 0.08986451428865407\n",
            "Epoch 235, loss 0.08990920218130623\n",
            "Epoch 235, loss 0.09036609825946247\n",
            "Epoch 235, loss 0.09013940431262932\n",
            "Epoch 235, loss 0.09012668993598053\n",
            "Epoch 235, loss 0.08967202777993735\n",
            " Epoch:61 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.0900227201905955\n",
            "Epoch 235, loss 0.0896241478678387\n",
            "Epoch 235, loss 0.09007848924623998\n",
            "Epoch 235, loss 0.08996228883175264\n",
            "Epoch 235, loss 0.08996095979683259\n",
            "Epoch 235, loss 0.08967758617884698\n",
            "Epoch 235, loss 0.08991199816478843\n",
            "Epoch 235, loss 0.08985019474572423\n",
            "Epoch 235, loss 0.09010847875421127\n",
            "Epoch 235, loss 0.08986451412234328\n",
            "Epoch 235, loss 0.08990920174498196\n",
            "Epoch 235, loss 0.09036609775665261\n",
            "Epoch 235, loss 0.090139404419408\n",
            "Epoch 235, loss 0.09012668922587204\n",
            "Epoch 235, loss 0.08967202771500467\n",
            " Epoch:62 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002271997454955\n",
            "Epoch 235, loss 0.08962414750936268\n",
            "Epoch 235, loss 0.09007848883199845\n",
            "Epoch 235, loss 0.0899622887841565\n",
            "Epoch 235, loss 0.0899609594754883\n",
            "Epoch 235, loss 0.08967758609279135\n",
            "Epoch 235, loss 0.08991199806048457\n",
            "Epoch 235, loss 0.08985019446607079\n",
            "Epoch 235, loss 0.090108478747285\n",
            "Epoch 235, loss 0.08986451395603502\n",
            "Epoch 235, loss 0.0899092013086669\n",
            "Epoch 235, loss 0.09036609725385229\n",
            "Epoch 235, loss 0.09013940452618344\n",
            "Epoch 235, loss 0.09012668851578035\n",
            "Epoch 235, loss 0.0896720276500726\n",
            " Epoch:63 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002271975850717\n",
            "Epoch 235, loss 0.08962414715089394\n",
            "Epoch 235, loss 0.09007848841776558\n",
            "Epoch 235, loss 0.08996228873656058\n",
            "Epoch 235, loss 0.08996095915415177\n",
            "Epoch 235, loss 0.08967758600673845\n",
            "Epoch 235, loss 0.08991199795618268\n",
            "Epoch 235, loss 0.08985019418642283\n",
            "Epoch 235, loss 0.09010847874035874\n",
            "Epoch 235, loss 0.08986451378972926\n",
            "Epoch 235, loss 0.08990920087236104\n",
            "Epoch 235, loss 0.09036609675106146\n",
            "Epoch 235, loss 0.09013940463295558\n",
            "Epoch 235, loss 0.09012668780570549\n",
            "Epoch 235, loss 0.08967202758514123\n",
            " Epoch:64 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002271954246835\n",
            "Epoch 235, loss 0.08962414679243247\n",
            "Epoch 235, loss 0.09007848800354142\n",
            "Epoch 235, loss 0.08996228868896483\n",
            "Epoch 235, loss 0.08996095883282294\n",
            "Epoch 235, loss 0.08967758592068828\n",
            "Epoch 235, loss 0.08991199785188275\n",
            "Epoch 235, loss 0.08985019390678033\n",
            "Epoch 235, loss 0.0901084787334325\n",
            "Epoch 235, loss 0.08986451362342601\n",
            "Epoch 235, loss 0.0899092004360644\n",
            "Epoch 235, loss 0.09036609624828008\n",
            "Epoch 235, loss 0.09013940473972447\n",
            "Epoch 235, loss 0.09012668709564749\n",
            "Epoch 235, loss 0.08967202752021056\n",
            " Epoch:65 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002271932643306\n",
            "Epoch 235, loss 0.08962414643397823\n",
            "Epoch 235, loss 0.09007848758932595\n",
            "Epoch 235, loss 0.08996228864136932\n",
            "Epoch 235, loss 0.08996095851150185\n",
            "Epoch 235, loss 0.08967758583464087\n",
            "Epoch 235, loss 0.08991199774758477\n",
            "Epoch 235, loss 0.08985019362714333\n",
            "Epoch 235, loss 0.09010847872650626\n",
            "Epoch 235, loss 0.08986451345712528\n",
            "Epoch 235, loss 0.089909199999777\n",
            "Epoch 235, loss 0.09036609574550816\n",
            "Epoch 235, loss 0.09013940484649009\n",
            "Epoch 235, loss 0.0901266863856063\n",
            "Epoch 235, loss 0.08967202745528058\n",
            " Epoch:66 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002271911040131\n",
            "Epoch 235, loss 0.08962414607553126\n",
            "Epoch 235, loss 0.0900784871751192\n",
            "Epoch 235, loss 0.08996228859377398\n",
            "Epoch 235, loss 0.0899609581901885\n",
            "Epoch 235, loss 0.08967758574859626\n",
            "Epoch 235, loss 0.08991199764328875\n",
            "Epoch 235, loss 0.08985019334751178\n",
            "Epoch 235, loss 0.09010847871958001\n",
            "Epoch 235, loss 0.08986451329082702\n",
            "Epoch 235, loss 0.08990919956349881\n",
            "Epoch 235, loss 0.09036609524274568\n",
            "Epoch 235, loss 0.09013940495325246\n",
            "Epoch 235, loss 0.09012668567558198\n",
            "Epoch 235, loss 0.0896720273903513\n",
            " Epoch:67 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.0900227188943731\n",
            "Epoch 235, loss 0.08962414571709149\n",
            "Epoch 235, loss 0.09007848676092119\n",
            "Epoch 235, loss 0.08996228854617885\n",
            "Epoch 235, loss 0.08996095786888286\n",
            "Epoch 235, loss 0.08967758566255442\n",
            "Epoch 235, loss 0.08991199753899466\n",
            "Epoch 235, loss 0.08985019306788572\n",
            "Epoch 235, loss 0.09010847871265378\n",
            "Epoch 235, loss 0.08986451312453128\n",
            "Epoch 235, loss 0.08990919912722983\n",
            "Epoch 235, loss 0.0903660947399926\n",
            "Epoch 235, loss 0.09013940506001153\n",
            "Epoch 235, loss 0.09012668496557448\n",
            "Epoch 235, loss 0.08967202732542273\n",
            " Epoch:68 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002271867834843\n",
            "Epoch 235, loss 0.08962414535865897\n",
            "Epoch 235, loss 0.09007848634673188\n",
            "Epoch 235, loss 0.08996228849858393\n",
            "Epoch 235, loss 0.08996095754758496\n",
            "Epoch 235, loss 0.08967758557651533\n",
            "Epoch 235, loss 0.08991199743470255\n",
            "Epoch 235, loss 0.08985019278826514\n",
            "Epoch 235, loss 0.09010847870572754\n",
            "Epoch 235, loss 0.08986451295823805\n",
            "Epoch 235, loss 0.08990919869097011\n",
            "Epoch 235, loss 0.09036609423724898\n",
            "Epoch 235, loss 0.0901394051667673\n",
            "Epoch 235, loss 0.09012668425558383\n",
            "Epoch 235, loss 0.08967202726049486\n",
            " Epoch:69 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002271846232728\n",
            "Epoch 235, loss 0.08962414500023368\n",
            "Epoch 235, loss 0.0900784859325513\n",
            "Epoch 235, loss 0.08996228845098918\n",
            "Epoch 235, loss 0.08996095722629478\n",
            "Epoch 235, loss 0.08967758549047902\n",
            "Epoch 235, loss 0.08991199733041236\n",
            "Epoch 235, loss 0.08985019250865005\n",
            "Epoch 235, loss 0.09010847869880129\n",
            "Epoch 235, loss 0.08986451279194732\n",
            "Epoch 235, loss 0.08990919825471959\n",
            "Epoch 235, loss 0.09036609373451476\n",
            "Epoch 235, loss 0.09013940527351985\n",
            "Epoch 235, loss 0.09012668354561004\n",
            "Epoch 235, loss 0.08967202719556773\n",
            " Epoch:70 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002271824630965\n",
            "Epoch 235, loss 0.0896241446418156\n",
            "Epoch 235, loss 0.09007848551837946\n",
            "Epoch 235, loss 0.08996228840339462\n",
            "Epoch 235, loss 0.0899609569050123\n",
            "Epoch 235, loss 0.08967758540444552\n",
            "Epoch 235, loss 0.0899119972261241\n",
            "Epoch 235, loss 0.08985019222904041\n",
            "Epoch 235, loss 0.09010847869187504\n",
            "Epoch 235, loss 0.08986451262565909\n",
            "Epoch 235, loss 0.08990919781847831\n",
            "Epoch 235, loss 0.09036609323178996\n",
            "Epoch 235, loss 0.0901394053802691\n",
            "Epoch 235, loss 0.09012668283565309\n",
            "Epoch 235, loss 0.0896720271306413\n",
            " Epoch:71 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002271803029556\n",
            "Epoch 235, loss 0.08962414428340476\n",
            "Epoch 235, loss 0.09007848510421637\n",
            "Epoch 235, loss 0.0899622883558003\n",
            "Epoch 235, loss 0.08996095658373757\n",
            "Epoch 235, loss 0.0896775853184148\n",
            "Epoch 235, loss 0.08991199712183781\n",
            "Epoch 235, loss 0.08985019194943625\n",
            "Epoch 235, loss 0.09010847868494878\n",
            "Epoch 235, loss 0.08986451245937335\n",
            "Epoch 235, loss 0.08990919738224622\n",
            "Epoch 235, loss 0.09036609272907456\n",
            "Epoch 235, loss 0.09013940548701507\n",
            "Epoch 235, loss 0.09012668212571298\n",
            "Epoch 235, loss 0.0896720270657156\n",
            " Epoch:72 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.090022717814285\n",
            "Epoch 235, loss 0.08962414392500115\n",
            "Epoch 235, loss 0.09007848469006201\n",
            "Epoch 235, loss 0.08996228830820614\n",
            "Epoch 235, loss 0.08996095626247054\n",
            "Epoch 235, loss 0.08967758523238685\n",
            "Epoch 235, loss 0.08991199701755345\n",
            "Epoch 235, loss 0.08985019166983757\n",
            "Epoch 235, loss 0.09010847867802252\n",
            "Epoch 235, loss 0.08986451229309014\n",
            "Epoch 235, loss 0.08990919694602338\n",
            "Epoch 235, loss 0.09036609222636861\n",
            "Epoch 235, loss 0.09013940559375774\n",
            "Epoch 235, loss 0.09012668141578974\n",
            "Epoch 235, loss 0.0896720270007906\n",
            " Epoch:73 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002271759827797\n",
            "Epoch 235, loss 0.08962414356660478\n",
            "Epoch 235, loss 0.09007848427591636\n",
            "Epoch 235, loss 0.08996228826061217\n",
            "Epoch 235, loss 0.08996095594121126\n",
            "Epoch 235, loss 0.0896775851463617\n",
            "Epoch 235, loss 0.08991199691327104\n",
            "Epoch 235, loss 0.08985019139024437\n",
            "Epoch 235, loss 0.09010847867109628\n",
            "Epoch 235, loss 0.08986451212680943\n",
            "Epoch 235, loss 0.08990919650980975\n",
            "Epoch 235, loss 0.09036609172367205\n",
            "Epoch 235, loss 0.0901394057004972\n",
            "Epoch 235, loss 0.09012668070588332\n",
            "Epoch 235, loss 0.08967202693586633\n",
            " Epoch:74 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002271738227446\n",
            "Epoch 235, loss 0.08962414320821563\n",
            "Epoch 235, loss 0.09007848386177945\n",
            "Epoch 235, loss 0.08996228821301842\n",
            "Epoch 235, loss 0.08996095561995969\n",
            "Epoch 235, loss 0.08967758506033932\n",
            "Epoch 235, loss 0.0899119968089906\n",
            "Epoch 235, loss 0.08985019111065665\n",
            "Epoch 235, loss 0.09010847866417002\n",
            "Epoch 235, loss 0.08986451196053122\n",
            "Epoch 235, loss 0.08990919607360537\n",
            "Epoch 235, loss 0.0903660912209849\n",
            "Epoch 235, loss 0.09013940580723333\n",
            "Epoch 235, loss 0.09012667999599376\n",
            "Epoch 235, loss 0.08967202687094275\n",
            " Epoch:75 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.0900227171662745\n",
            "Epoch 235, loss 0.0896241428498337\n",
            "Epoch 235, loss 0.09007848344765128\n",
            "Epoch 235, loss 0.08996228816542487\n",
            "Epoch 235, loss 0.08996095529871584\n",
            "Epoch 235, loss 0.08967758497431971\n",
            "Epoch 235, loss 0.08991199670471209\n",
            "Epoch 235, loss 0.0898501908310744\n",
            "Epoch 235, loss 0.09010847865724374\n",
            "Epoch 235, loss 0.08986451179425552\n",
            "Epoch 235, loss 0.0899091956374102\n",
            "Epoch 235, loss 0.09036609071830717\n",
            "Epoch 235, loss 0.09013940591396621\n",
            "Epoch 235, loss 0.09012667928612106\n",
            "Epoch 235, loss 0.08967202680601992\n",
            " Epoch:76 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002271695027804\n",
            "Epoch 235, loss 0.08962414249145897\n",
            "Epoch 235, loss 0.09007848303353186\n",
            "Epoch 235, loss 0.0899622881178315\n",
            "Epoch 235, loss 0.08996095497747972\n",
            "Epoch 235, loss 0.08967758488830291\n",
            "Epoch 235, loss 0.0899119966004355\n",
            "Epoch 235, loss 0.08985019055149764\n",
            "Epoch 235, loss 0.09010847865031747\n",
            "Epoch 235, loss 0.0898645116279823\n",
            "Epoch 235, loss 0.08990919520122424\n",
            "Epoch 235, loss 0.09036609021563886\n",
            "Epoch 235, loss 0.09013940602069578\n",
            "Epoch 235, loss 0.09012667857626519\n",
            "Epoch 235, loss 0.08967202674109778\n",
            " Epoch:77 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002271673428511\n",
            "Epoch 235, loss 0.08962414213309149\n",
            "Epoch 235, loss 0.09007848261942114\n",
            "Epoch 235, loss 0.08996228807023834\n",
            "Epoch 235, loss 0.08996095465625131\n",
            "Epoch 235, loss 0.08967758480228888\n",
            "Epoch 235, loss 0.08991199649616088\n",
            "Epoch 235, loss 0.08985019027192633\n",
            "Epoch 235, loss 0.09010847864339121\n",
            "Epoch 235, loss 0.08986451146171158\n",
            "Epoch 235, loss 0.08990919476504752\n",
            "Epoch 235, loss 0.09036608971297996\n",
            "Epoch 235, loss 0.0901394061274221\n",
            "Epoch 235, loss 0.09012667786642614\n",
            "Epoch 235, loss 0.08967202667617638\n",
            " Epoch:78 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.0900227165182957\n",
            "Epoch 235, loss 0.08962414177473124\n",
            "Epoch 235, loss 0.09007848220531917\n",
            "Epoch 235, loss 0.08996228802264535\n",
            "Epoch 235, loss 0.08996095433503062\n",
            "Epoch 235, loss 0.08967758471627763\n",
            "Epoch 235, loss 0.08991199639188821\n",
            "Epoch 235, loss 0.08985018999236051\n",
            "Epoch 235, loss 0.09010847863646491\n",
            "Epoch 235, loss 0.0898645112954434\n",
            "Epoch 235, loss 0.08990919432888003\n",
            "Epoch 235, loss 0.09036608921033049\n",
            "Epoch 235, loss 0.09013940623414515\n",
            "Epoch 235, loss 0.09012667715660398\n",
            "Epoch 235, loss 0.08967202661125569\n",
            " Epoch:79 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002271630230982\n",
            "Epoch 235, loss 0.0896241414163782\n",
            "Epoch 235, loss 0.09007848179122593\n",
            "Epoch 235, loss 0.08996228797505257\n",
            "Epoch 235, loss 0.08996095401381765\n",
            "Epoch 235, loss 0.08967758463026917\n",
            "Epoch 235, loss 0.08991199628761748\n",
            "Epoch 235, loss 0.08985018971280016\n",
            "Epoch 235, loss 0.09010847862953865\n",
            "Epoch 235, loss 0.08986451112917768\n",
            "Epoch 235, loss 0.08990919389272176\n",
            "Epoch 235, loss 0.0903660887076904\n",
            "Epoch 235, loss 0.09013940634086491\n",
            "Epoch 235, loss 0.09012667644679864\n",
            "Epoch 235, loss 0.0896720265463357\n",
            " Epoch:80 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002271608632748\n",
            "Epoch 235, loss 0.0896241410580324\n",
            "Epoch 235, loss 0.09007848137714142\n",
            "Epoch 235, loss 0.08996228792746\n",
            "Epoch 235, loss 0.08996095369261241\n",
            "Epoch 235, loss 0.0896775845442635\n",
            "Epoch 235, loss 0.08991199618334869\n",
            "Epoch 235, loss 0.0898501894332453\n",
            "Epoch 235, loss 0.09010847862261237\n",
            "Epoch 235, loss 0.08986451096291449\n",
            "Epoch 235, loss 0.08990919345657271\n",
            "Epoch 235, loss 0.09036608820505973\n",
            "Epoch 235, loss 0.09013940644758142\n",
            "Epoch 235, loss 0.09012667573701015\n",
            "Epoch 235, loss 0.08967202648141644\n",
            " Epoch:81 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002271587034869\n",
            "Epoch 235, loss 0.08962414069969382\n",
            "Epoch 235, loss 0.09007848096306564\n",
            "Epoch 235, loss 0.0899622878798676\n",
            "Epoch 235, loss 0.08996095337141488\n",
            "Epoch 235, loss 0.0896775844582606\n",
            "Epoch 235, loss 0.08991199607908183\n",
            "Epoch 235, loss 0.08985018915369589\n",
            "Epoch 235, loss 0.09010847861568608\n",
            "Epoch 235, loss 0.0898645107966538\n",
            "Epoch 235, loss 0.08990919302043289\n",
            "Epoch 235, loss 0.09036608770243848\n",
            "Epoch 235, loss 0.09013940655429463\n",
            "Epoch 235, loss 0.0901266750272385\n",
            "Epoch 235, loss 0.08967202641649788\n",
            " Epoch:82 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002271565437339\n",
            "Epoch 235, loss 0.08962414034136247\n",
            "Epoch 235, loss 0.09007848054899861\n",
            "Epoch 235, loss 0.08996228783227542\n",
            "Epoch 235, loss 0.08996095305022508\n",
            "Epoch 235, loss 0.08967758437226048\n",
            "Epoch 235, loss 0.08991199597481694\n",
            "Epoch 235, loss 0.08985018887415197\n",
            "Epoch 235, loss 0.09010847860875978\n",
            "Epoch 235, loss 0.0898645106303956\n",
            "Epoch 235, loss 0.08990919258430227\n",
            "Epoch 235, loss 0.09036608719982664\n",
            "Epoch 235, loss 0.09013940666100459\n",
            "Epoch 235, loss 0.09012667431748371\n",
            "Epoch 235, loss 0.08967202635158006\n",
            " Epoch:83 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002271543840162\n",
            "Epoch 235, loss 0.08962413998303834\n",
            "Epoch 235, loss 0.09007848013494028\n",
            "Epoch 235, loss 0.08996228778468343\n",
            "Epoch 235, loss 0.089960952729043\n",
            "Epoch 235, loss 0.08967758428626313\n",
            "Epoch 235, loss 0.089911995870554\n",
            "Epoch 235, loss 0.08985018859461354\n",
            "Epoch 235, loss 0.09010847860183349\n",
            "Epoch 235, loss 0.0898645104641399\n",
            "Epoch 235, loss 0.0899091921481809\n",
            "Epoch 235, loss 0.09036608669722421\n",
            "Epoch 235, loss 0.09013940676771126\n",
            "Epoch 235, loss 0.09012667360774576\n",
            "Epoch 235, loss 0.08967202628666296\n",
            " Epoch:84 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.0900227152224334\n",
            "Epoch 235, loss 0.08962413962472143\n",
            "Epoch 235, loss 0.09007847972089071\n",
            "Epoch 235, loss 0.08996228773709163\n",
            "Epoch 235, loss 0.08996095240786864\n",
            "Epoch 235, loss 0.08967758420026858\n",
            "Epoch 235, loss 0.08991199576629298\n",
            "Epoch 235, loss 0.08985018831508056\n",
            "Epoch 235, loss 0.0901084785949072\n",
            "Epoch 235, loss 0.08986451029788671\n",
            "Epoch 235, loss 0.08990919171206875\n",
            "Epoch 235, loss 0.09036608619463118\n",
            "Epoch 235, loss 0.09013940687441464\n",
            "Epoch 235, loss 0.09012667289802465\n",
            "Epoch 235, loss 0.08967202622174655\n",
            " Epoch:85 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002271500646868\n",
            "Epoch 235, loss 0.08962413926641175\n",
            "Epoch 235, loss 0.09007847930684987\n",
            "Epoch 235, loss 0.08996228768950003\n",
            "Epoch 235, loss 0.089960952086702\n",
            "Epoch 235, loss 0.08967758411427681\n",
            "Epoch 235, loss 0.08991199566203392\n",
            "Epoch 235, loss 0.08985018803555307\n",
            "Epoch 235, loss 0.0901084785879809\n",
            "Epoch 235, loss 0.08986451013163603\n",
            "Epoch 235, loss 0.0899091912759658\n",
            "Epoch 235, loss 0.09036608569204758\n",
            "Epoch 235, loss 0.09013940698111475\n",
            "Epoch 235, loss 0.09012667218832036\n",
            "Epoch 235, loss 0.08967202615683087\n",
            " Epoch:86 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002271479050751\n",
            "Epoch 235, loss 0.0896241389081093\n",
            "Epoch 235, loss 0.09007847889281774\n",
            "Epoch 235, loss 0.08996228764190861\n",
            "Epoch 235, loss 0.08996095176554307\n",
            "Epoch 235, loss 0.08967758402828784\n",
            "Epoch 235, loss 0.08991199555777682\n",
            "Epoch 235, loss 0.08985018775603104\n",
            "Epoch 235, loss 0.0901084785810546\n",
            "Epoch 235, loss 0.08986450996538783\n",
            "Epoch 235, loss 0.08990919083987209\n",
            "Epoch 235, loss 0.09036608518947338\n",
            "Epoch 235, loss 0.0901394070878116\n",
            "Epoch 235, loss 0.09012667147863293\n",
            "Epoch 235, loss 0.08967202609191591\n",
            " Epoch:87 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002271457454984\n",
            "Epoch 235, loss 0.08962413854981405\n",
            "Epoch 235, loss 0.09007847847879437\n",
            "Epoch 235, loss 0.08996228759431739\n",
            "Epoch 235, loss 0.08996095144439187\n",
            "Epoch 235, loss 0.08967758394230163\n",
            "Epoch 235, loss 0.08991199545352163\n",
            "Epoch 235, loss 0.08985018747651449\n",
            "Epoch 235, loss 0.09010847857412829\n",
            "Epoch 235, loss 0.08986450979914215\n",
            "Epoch 235, loss 0.0899091904037876\n",
            "Epoch 235, loss 0.09036608468690861\n",
            "Epoch 235, loss 0.09013940719450517\n",
            "Epoch 235, loss 0.09012667076896234\n",
            "Epoch 235, loss 0.08967202602700167\n",
            " Epoch:88 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002271435859573\n",
            "Epoch 235, loss 0.08962413819152604\n",
            "Epoch 235, loss 0.0900784780647797\n",
            "Epoch 235, loss 0.08996228754672639\n",
            "Epoch 235, loss 0.08996095112324838\n",
            "Epoch 235, loss 0.08967758385631822\n",
            "Epoch 235, loss 0.0899119953492684\n",
            "Epoch 235, loss 0.08985018719700343\n",
            "Epoch 235, loss 0.09010847856720197\n",
            "Epoch 235, loss 0.08986450963289898\n",
            "Epoch 235, loss 0.08990918996771233\n",
            "Epoch 235, loss 0.09036608418435323\n",
            "Epoch 235, loss 0.09013940730119546\n",
            "Epoch 235, loss 0.0901266700593086\n",
            "Epoch 235, loss 0.08967202596208812\n",
            " Epoch:89 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002271414264511\n",
            "Epoch 235, loss 0.08962413783324526\n",
            "Epoch 235, loss 0.09007847765077377\n",
            "Epoch 235, loss 0.08996228749913558\n",
            "Epoch 235, loss 0.08996095080211261\n",
            "Epoch 235, loss 0.08967758377033756\n",
            "Epoch 235, loss 0.08991199524501711\n",
            "Epoch 235, loss 0.08985018691749784\n",
            "Epoch 235, loss 0.09010847856027566\n",
            "Epoch 235, loss 0.0898645094666583\n",
            "Epoch 235, loss 0.08990918953164628\n",
            "Epoch 235, loss 0.09036608368180725\n",
            "Epoch 235, loss 0.09013940740788248\n",
            "Epoch 235, loss 0.09012666934967169\n",
            "Epoch 235, loss 0.08967202589717531\n",
            " Epoch:90 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002271392669806\n",
            "Epoch 235, loss 0.0896241374749717\n",
            "Epoch 235, loss 0.09007847723677657\n",
            "Epoch 235, loss 0.08996228745154496\n",
            "Epoch 235, loss 0.08996095048098456\n",
            "Epoch 235, loss 0.0896775836843597\n",
            "Epoch 235, loss 0.08991199514076778\n",
            "Epoch 235, loss 0.08985018663799771\n",
            "Epoch 235, loss 0.09010847855334933\n",
            "Epoch 235, loss 0.08986450930042014\n",
            "Epoch 235, loss 0.08990918909558945\n",
            "Epoch 235, loss 0.0903660831792707\n",
            "Epoch 235, loss 0.09013940751456624\n",
            "Epoch 235, loss 0.09012666864005162\n",
            "Epoch 235, loss 0.0896720258322632\n",
            " Epoch:91 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002271371075449\n",
            "Epoch 235, loss 0.08962413711670533\n",
            "Epoch 235, loss 0.0900784768227881\n",
            "Epoch 235, loss 0.08996228740395454\n",
            "Epoch 235, loss 0.08996095015986423\n",
            "Epoch 235, loss 0.08967758359838462\n",
            "Epoch 235, loss 0.08991199503652039\n",
            "Epoch 235, loss 0.08985018635850307\n",
            "Epoch 235, loss 0.09010847854642302\n",
            "Epoch 235, loss 0.08986450913418445\n",
            "Epoch 235, loss 0.08990918865954185\n",
            "Epoch 235, loss 0.09036608267674354\n",
            "Epoch 235, loss 0.09013940762124671\n",
            "Epoch 235, loss 0.09012666793044839\n",
            "Epoch 235, loss 0.08967202576735182\n",
            " Epoch:92 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002271349481447\n",
            "Epoch 235, loss 0.08962413675844623\n",
            "Epoch 235, loss 0.09007847640880837\n",
            "Epoch 235, loss 0.08996228735636433\n",
            "Epoch 235, loss 0.08996094983875162\n",
            "Epoch 235, loss 0.08967758351241234\n",
            "Epoch 235, loss 0.08991199493227493\n",
            "Epoch 235, loss 0.08985018607901389\n",
            "Epoch 235, loss 0.09010847853949669\n",
            "Epoch 235, loss 0.0898645089679513\n",
            "Epoch 235, loss 0.08990918822350347\n",
            "Epoch 235, loss 0.0903660821742258\n",
            "Epoch 235, loss 0.09013940772792392\n",
            "Epoch 235, loss 0.090126667220862\n",
            "Epoch 235, loss 0.08967202570244118\n",
            " Epoch:93 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002271327887797\n",
            "Epoch 235, loss 0.08962413640019433\n",
            "Epoch 235, loss 0.09007847599483737\n",
            "Epoch 235, loss 0.08996228730877429\n",
            "Epoch 235, loss 0.08996094951764673\n",
            "Epoch 235, loss 0.08967758342644282\n",
            "Epoch 235, loss 0.08991199482803143\n",
            "Epoch 235, loss 0.08985018579953019\n",
            "Epoch 235, loss 0.09010847853257035\n",
            "Epoch 235, loss 0.08986450880172062\n",
            "Epoch 235, loss 0.0899091877874743\n",
            "Epoch 235, loss 0.09036608167171747\n",
            "Epoch 235, loss 0.09013940783459784\n",
            "Epoch 235, loss 0.09012666651129245\n",
            "Epoch 235, loss 0.08967202563753121\n",
            " Epoch:94 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.090022713062945\n",
            "Epoch 235, loss 0.08962413604194966\n",
            "Epoch 235, loss 0.09007847558087508\n",
            "Epoch 235, loss 0.08996228726118445\n",
            "Epoch 235, loss 0.08996094919654954\n",
            "Epoch 235, loss 0.08967758334047608\n",
            "Epoch 235, loss 0.08991199472378987\n",
            "Epoch 235, loss 0.08985018552005196\n",
            "Epoch 235, loss 0.09010847852564403\n",
            "Epoch 235, loss 0.08986450863549246\n",
            "Epoch 235, loss 0.08990918735145435\n",
            "Epoch 235, loss 0.09036608116921854\n",
            "Epoch 235, loss 0.09013940794126848\n",
            "Epoch 235, loss 0.09012666580173974\n",
            "Epoch 235, loss 0.08967202557262198\n",
            " Epoch:95 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002271284701555\n",
            "Epoch 235, loss 0.08962413568371222\n",
            "Epoch 235, loss 0.09007847516692154\n",
            "Epoch 235, loss 0.08996228721359482\n",
            "Epoch 235, loss 0.08996094887546009\n",
            "Epoch 235, loss 0.08967758325451212\n",
            "Epoch 235, loss 0.08991199461955025\n",
            "Epoch 235, loss 0.08985018524057922\n",
            "Epoch 235, loss 0.0901084785187177\n",
            "Epoch 235, loss 0.08986450846926679\n",
            "Epoch 235, loss 0.08990918691544363\n",
            "Epoch 235, loss 0.09036608066672905\n",
            "Epoch 235, loss 0.09013940804793585\n",
            "Epoch 235, loss 0.09012666509220385\n",
            "Epoch 235, loss 0.08967202550771346\n",
            " Epoch:96 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002271263108963\n",
            "Epoch 235, loss 0.089624135325482\n",
            "Epoch 235, loss 0.09007847475297673\n",
            "Epoch 235, loss 0.08996228716600538\n",
            "Epoch 235, loss 0.08996094855437833\n",
            "Epoch 235, loss 0.08967758316855096\n",
            "Epoch 235, loss 0.08991199451531258\n",
            "Epoch 235, loss 0.08985018496111194\n",
            "Epoch 235, loss 0.09010847851179135\n",
            "Epoch 235, loss 0.08986450830304363\n",
            "Epoch 235, loss 0.08990918647944213\n",
            "Epoch 235, loss 0.09036608016424894\n",
            "Epoch 235, loss 0.09013940815459998\n",
            "Epoch 235, loss 0.09012666438268482\n",
            "Epoch 235, loss 0.08967202544280566\n",
            " Epoch:97 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002271241516724\n",
            "Epoch 235, loss 0.08962413496725898\n",
            "Epoch 235, loss 0.09007847433904062\n",
            "Epoch 235, loss 0.08996228711841614\n",
            "Epoch 235, loss 0.08996094823330432\n",
            "Epoch 235, loss 0.08967758308259258\n",
            "Epoch 235, loss 0.08991199441107686\n",
            "Epoch 235, loss 0.08985018468165012\n",
            "Epoch 235, loss 0.090108478504865\n",
            "Epoch 235, loss 0.08986450813682297\n",
            "Epoch 235, loss 0.08990918604344984\n",
            "Epoch 235, loss 0.09036607966177825\n",
            "Epoch 235, loss 0.0901394082612608\n",
            "Epoch 235, loss 0.09012666367318262\n",
            "Epoch 235, loss 0.08967202537789856\n",
            " Epoch:98 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002271219924837\n",
            "Epoch 235, loss 0.0896241346090432\n",
            "Epoch 235, loss 0.09007847392511326\n",
            "Epoch 235, loss 0.08996228707082708\n",
            "Epoch 235, loss 0.089960947912238\n",
            "Epoch 235, loss 0.08967758299663697\n",
            "Epoch 235, loss 0.08991199430684307\n",
            "Epoch 235, loss 0.0898501844021938\n",
            "Epoch 235, loss 0.09010847849793865\n",
            "Epoch 235, loss 0.0898645079706048\n",
            "Epoch 235, loss 0.08990918560746677\n",
            "Epoch 235, loss 0.09036607915931694\n",
            "Epoch 235, loss 0.09013940836791837\n",
            "Epoch 235, loss 0.09012666296369724\n",
            "Epoch 235, loss 0.0896720253129922\n",
            " Epoch:99 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002271198333303\n",
            "Epoch 235, loss 0.08962413425083464\n",
            "Epoch 235, loss 0.0900784735111946\n",
            "Epoch 235, loss 0.08996228702323823\n",
            "Epoch 235, loss 0.08996094759117942\n",
            "Epoch 235, loss 0.08967758291068414\n",
            "Epoch 235, loss 0.08991199420261123\n",
            "Epoch 235, loss 0.08985018412274293\n",
            "Epoch 235, loss 0.0901084784910123\n",
            "Epoch 235, loss 0.08986450780438915\n",
            "Epoch 235, loss 0.08990918517149295\n",
            "Epoch 235, loss 0.09036607865686505\n",
            "Epoch 235, loss 0.09013940847457265\n",
            "Epoch 235, loss 0.09012666225422873\n",
            "Epoch 235, loss 0.08967202524808655\n",
            " Epoch:100 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.0900227117674212\n",
            "Epoch 235, loss 0.08962413389263331\n",
            "Epoch 235, loss 0.0900784730972847\n",
            "Epoch 235, loss 0.08996228697564959\n",
            "Epoch 235, loss 0.08996094727012853\n",
            "Epoch 235, loss 0.08967758282473408\n",
            "Epoch 235, loss 0.08991199409838135\n",
            "Epoch 235, loss 0.08985018384329754\n",
            "Epoch 235, loss 0.09010847848408596\n",
            "Epoch 235, loss 0.089864507638176\n",
            "Epoch 235, loss 0.08990918473552831\n",
            "Epoch 235, loss 0.09036607815442259\n",
            "Epoch 235, loss 0.09013940858122366\n",
            "Epoch 235, loss 0.09012666154477703\n",
            "Epoch 235, loss 0.08967202518318163\n",
            " Epoch:101 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.0900227115515129\n",
            "Epoch 235, loss 0.08962413353443918\n",
            "Epoch 235, loss 0.09007847268338351\n",
            "Epoch 235, loss 0.08996228692806113\n",
            "Epoch 235, loss 0.08996094694908537\n",
            "Epoch 235, loss 0.08967758273878683\n",
            "Epoch 235, loss 0.08991199399415338\n",
            "Epoch 235, loss 0.08985018356385763\n",
            "Epoch 235, loss 0.0901084784771596\n",
            "Epoch 235, loss 0.08986450747196535\n",
            "Epoch 235, loss 0.08990918429957288\n",
            "Epoch 235, loss 0.09036607765198952\n",
            "Epoch 235, loss 0.09013940868787139\n",
            "Epoch 235, loss 0.09012666083534217\n",
            "Epoch 235, loss 0.0896720251182774\n",
            " Epoch:102 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002271133560813\n",
            "Epoch 235, loss 0.08962413317625231\n",
            "Epoch 235, loss 0.09007847226949105\n",
            "Epoch 235, loss 0.08996228688047286\n",
            "Epoch 235, loss 0.08996094662804992\n",
            "Epoch 235, loss 0.08967758265284234\n",
            "Epoch 235, loss 0.08991199388992738\n",
            "Epoch 235, loss 0.08985018328442321\n",
            "Epoch 235, loss 0.09010847847023323\n",
            "Epoch 235, loss 0.0898645073057572\n",
            "Epoch 235, loss 0.08990918386362672\n",
            "Epoch 235, loss 0.09036607714956588\n",
            "Epoch 235, loss 0.09013940879451585\n",
            "Epoch 235, loss 0.09012666012592414\n",
            "Epoch 235, loss 0.0896720250533739\n",
            " Epoch:103 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002271111970689\n",
            "Epoch 235, loss 0.08962413281807263\n",
            "Epoch 235, loss 0.09007847185560733\n",
            "Epoch 235, loss 0.0899622868328848\n",
            "Epoch 235, loss 0.0899609463070222\n",
            "Epoch 235, loss 0.08967758256690064\n",
            "Epoch 235, loss 0.08991199378570333\n",
            "Epoch 235, loss 0.08985018300499423\n",
            "Epoch 235, loss 0.09010847846330686\n",
            "Epoch 235, loss 0.08986450713955153\n",
            "Epoch 235, loss 0.08990918342768973\n",
            "Epoch 235, loss 0.09036607664715161\n",
            "Epoch 235, loss 0.09013940890115706\n",
            "Epoch 235, loss 0.09012665941652295\n",
            "Epoch 235, loss 0.08967202498847111\n",
            " Epoch:104 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002271090380917\n",
            "Epoch 235, loss 0.08962413245990018\n",
            "Epoch 235, loss 0.09007847144173231\n",
            "Epoch 235, loss 0.08996228678529694\n",
            "Epoch 235, loss 0.08996094598600218\n",
            "Epoch 235, loss 0.08967758248096172\n",
            "Epoch 235, loss 0.0899119936814812\n",
            "Epoch 235, loss 0.08985018272557074\n",
            "Epoch 235, loss 0.0901084784563805\n",
            "Epoch 235, loss 0.08986450697334838\n",
            "Epoch 235, loss 0.089909182991762\n",
            "Epoch 235, loss 0.09036607614474676\n",
            "Epoch 235, loss 0.09013940900779496\n",
            "Epoch 235, loss 0.0901266587071386\n",
            "Epoch 235, loss 0.08967202492356904\n",
            " Epoch:105 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002271068791497\n",
            "Epoch 235, loss 0.08962413210173495\n",
            "Epoch 235, loss 0.09007847102786604\n",
            "Epoch 235, loss 0.08996228673770926\n",
            "Epoch 235, loss 0.08996094566498988\n",
            "Epoch 235, loss 0.08967758239502559\n",
            "Epoch 235, loss 0.08991199357726103\n",
            "Epoch 235, loss 0.0898501824461527\n",
            "Epoch 235, loss 0.0901084784494541\n",
            "Epoch 235, loss 0.08986450680714772\n",
            "Epoch 235, loss 0.08990918255584344\n",
            "Epoch 235, loss 0.09036607564235133\n",
            "Epoch 235, loss 0.09013940911442961\n",
            "Epoch 235, loss 0.09012665799777109\n",
            "Epoch 235, loss 0.08967202485866768\n",
            " Epoch:106 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.0900227104720243\n",
            "Epoch 235, loss 0.08962413174357695\n",
            "Epoch 235, loss 0.09007847061400849\n",
            "Epoch 235, loss 0.08996228669012178\n",
            "Epoch 235, loss 0.08996094534398531\n",
            "Epoch 235, loss 0.08967758230909222\n",
            "Epoch 235, loss 0.08991199347304281\n",
            "Epoch 235, loss 0.08985018216674015\n",
            "Epoch 235, loss 0.09010847844252776\n",
            "Epoch 235, loss 0.08986450664094957\n",
            "Epoch 235, loss 0.08990918211993412\n",
            "Epoch 235, loss 0.09036607513996531\n",
            "Epoch 235, loss 0.09013940922106098\n",
            "Epoch 235, loss 0.09012665728842038\n",
            "Epoch 235, loss 0.08967202479376704\n",
            " Epoch:107 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002271025613715\n",
            "Epoch 235, loss 0.08962413138542616\n",
            "Epoch 235, loss 0.09007847020015966\n",
            "Epoch 235, loss 0.08996228664253451\n",
            "Epoch 235, loss 0.08996094502298843\n",
            "Epoch 235, loss 0.08967758222316165\n",
            "Epoch 235, loss 0.08991199336882652\n",
            "Epoch 235, loss 0.08985018188733308\n",
            "Epoch 235, loss 0.09010847843560137\n",
            "Epoch 235, loss 0.08986450647475394\n",
            "Epoch 235, loss 0.08990918168403403\n",
            "Epoch 235, loss 0.09036607463758865\n",
            "Epoch 235, loss 0.09013940932768909\n",
            "Epoch 235, loss 0.09012665657908653\n",
            "Epoch 235, loss 0.08967202472886712\n",
            " Epoch:108 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002271004025353\n",
            "Epoch 235, loss 0.08962413102728259\n",
            "Epoch 235, loss 0.09007846978631956\n",
            "Epoch 235, loss 0.08996228659494744\n",
            "Epoch 235, loss 0.08996094470199929\n",
            "Epoch 235, loss 0.08967758213723384\n",
            "Epoch 235, loss 0.08991199326461218\n",
            "Epoch 235, loss 0.08985018160793146\n",
            "Epoch 235, loss 0.09010847842867498\n",
            "Epoch 235, loss 0.08986450630856077\n",
            "Epoch 235, loss 0.08990918124814315\n",
            "Epoch 235, loss 0.09036607413522144\n",
            "Epoch 235, loss 0.09013940943431394\n",
            "Epoch 235, loss 0.0901266558697695\n",
            "Epoch 235, loss 0.08967202466396793\n",
            " Epoch:109 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002270982437344\n",
            "Epoch 235, loss 0.08962413066914625\n",
            "Epoch 235, loss 0.09007846937248817\n",
            "Epoch 235, loss 0.08996228654736056\n",
            "Epoch 235, loss 0.08996094438101784\n",
            "Epoch 235, loss 0.08967758205130882\n",
            "Epoch 235, loss 0.08991199316039977\n",
            "Epoch 235, loss 0.08985018132853533\n",
            "Epoch 235, loss 0.09010847842174859\n",
            "Epoch 235, loss 0.08986450614237014\n",
            "Epoch 235, loss 0.08990918081226149\n",
            "Epoch 235, loss 0.09036607363286364\n",
            "Epoch 235, loss 0.0901394095409355\n",
            "Epoch 235, loss 0.09012665516046932\n",
            "Epoch 235, loss 0.08967202459906942\n",
            " Epoch:110 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002270960849687\n",
            "Epoch 235, loss 0.08962413031101713\n",
            "Epoch 235, loss 0.09007846895866553\n",
            "Epoch 235, loss 0.08996228649977386\n",
            "Epoch 235, loss 0.08996094406004411\n",
            "Epoch 235, loss 0.08967758196538658\n",
            "Epoch 235, loss 0.08991199305618933\n",
            "Epoch 235, loss 0.08985018104914466\n",
            "Epoch 235, loss 0.0901084784148222\n",
            "Epoch 235, loss 0.089864505976182\n",
            "Epoch 235, loss 0.08990918037638904\n",
            "Epoch 235, loss 0.09036607313051523\n",
            "Epoch 235, loss 0.09013940964755376\n",
            "Epoch 235, loss 0.09012665445118595\n",
            "Epoch 235, loss 0.08967202453417164\n",
            " Epoch:111 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.0900227093926238\n",
            "Epoch 235, loss 0.08962412995289522\n",
            "Epoch 235, loss 0.0900784685448516\n",
            "Epoch 235, loss 0.08996228645218737\n",
            "Epoch 235, loss 0.0899609437390781\n",
            "Epoch 235, loss 0.0896775818794671\n",
            "Epoch 235, loss 0.08991199295198082\n",
            "Epoch 235, loss 0.08985018076975945\n",
            "Epoch 235, loss 0.09010847840789579\n",
            "Epoch 235, loss 0.08986450580999636\n",
            "Epoch 235, loss 0.0899091799405258\n",
            "Epoch 235, loss 0.09036607262817622\n",
            "Epoch 235, loss 0.09013940975416879\n",
            "Epoch 235, loss 0.09012665374191942\n",
            "Epoch 235, loss 0.08967202446927461\n",
            " Epoch:112 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002270917675428\n",
            "Epoch 235, loss 0.08962412959478053\n",
            "Epoch 235, loss 0.0900784681310464\n",
            "Epoch 235, loss 0.08996228640460109\n",
            "Epoch 235, loss 0.08996094341811979\n",
            "Epoch 235, loss 0.08967758179355043\n",
            "Epoch 235, loss 0.08991199284777426\n",
            "Epoch 235, loss 0.08985018049037974\n",
            "Epoch 235, loss 0.09010847840096939\n",
            "Epoch 235, loss 0.08986450564381322\n",
            "Epoch 235, loss 0.08990917950467178\n",
            "Epoch 235, loss 0.09036607212584662\n",
            "Epoch 235, loss 0.09013940986078053\n",
            "Epoch 235, loss 0.09012665303266972\n",
            "Epoch 235, loss 0.08967202440437824\n",
            " Epoch:113 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002270896088829\n",
            "Epoch 235, loss 0.08962412923667305\n",
            "Epoch 235, loss 0.09007846771724992\n",
            "Epoch 235, loss 0.08996228635701499\n",
            "Epoch 235, loss 0.0899609430971692\n",
            "Epoch 235, loss 0.08967758170763654\n",
            "Epoch 235, loss 0.08991199274356962\n",
            "Epoch 235, loss 0.08985018021100548\n",
            "Epoch 235, loss 0.09010847839404298\n",
            "Epoch 235, loss 0.08986450547763257\n",
            "Epoch 235, loss 0.08990917906882698\n",
            "Epoch 235, loss 0.09036607162352643\n",
            "Epoch 235, loss 0.09013940996738899\n",
            "Epoch 235, loss 0.09012665232343686\n",
            "Epoch 235, loss 0.08967202433948264\n",
            " Epoch:114 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.0900227087450258\n",
            "Epoch 235, loss 0.08962412887857281\n",
            "Epoch 235, loss 0.09007846730346217\n",
            "Epoch 235, loss 0.08996228630942908\n",
            "Epoch 235, loss 0.08996094277622634\n",
            "Epoch 235, loss 0.08967758162172541\n",
            "Epoch 235, loss 0.08991199263936696\n",
            "Epoch 235, loss 0.08985017993163671\n",
            "Epoch 235, loss 0.09010847838711658\n",
            "Epoch 235, loss 0.08986450531145444\n",
            "Epoch 235, loss 0.08990917863299139\n",
            "Epoch 235, loss 0.09036607112121561\n",
            "Epoch 235, loss 0.0901394100739942\n",
            "Epoch 235, loss 0.09012665161422082\n",
            "Epoch 235, loss 0.08967202427458773\n",
            " Epoch:115 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002270852916686\n",
            "Epoch 235, loss 0.08962412852047978\n",
            "Epoch 235, loss 0.09007846688968314\n",
            "Epoch 235, loss 0.0899622862618434\n",
            "Epoch 235, loss 0.08996094245529117\n",
            "Epoch 235, loss 0.08967758153581706\n",
            "Epoch 235, loss 0.08991199253516621\n",
            "Epoch 235, loss 0.0898501796522734\n",
            "Epoch 235, loss 0.09010847838019016\n",
            "Epoch 235, loss 0.0898645051452788\n",
            "Epoch 235, loss 0.08990917819716501\n",
            "Epoch 235, loss 0.09036607061891425\n",
            "Epoch 235, loss 0.09013941018059612\n",
            "Epoch 235, loss 0.09012665090502159\n",
            "Epoch 235, loss 0.08967202420969353\n",
            " Epoch:116 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002270831331143\n",
            "Epoch 235, loss 0.08962412816239398\n",
            "Epoch 235, loss 0.09007846647591282\n",
            "Epoch 235, loss 0.08996228621425788\n",
            "Epoch 235, loss 0.08996094213436374\n",
            "Epoch 235, loss 0.08967758144991152\n",
            "Epoch 235, loss 0.08991199243096742\n",
            "Epoch 235, loss 0.08985017937291555\n",
            "Epoch 235, loss 0.09010847837326375\n",
            "Epoch 235, loss 0.08986450497910567\n",
            "Epoch 235, loss 0.08990917776134787\n",
            "Epoch 235, loss 0.09036607011662226\n",
            "Epoch 235, loss 0.09013941028719477\n",
            "Epoch 235, loss 0.09012665019583921\n",
            "Epoch 235, loss 0.08967202414480005\n",
            " Epoch:117 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002270809745952\n",
            "Epoch 235, loss 0.08962412780431539\n",
            "Epoch 235, loss 0.09007846606215125\n",
            "Epoch 235, loss 0.08996228616667258\n",
            "Epoch 235, loss 0.08996094181344401\n",
            "Epoch 235, loss 0.08967758136400872\n",
            "Epoch 235, loss 0.08991199232677058\n",
            "Epoch 235, loss 0.08985017909356319\n",
            "Epoch 235, loss 0.09010847836633733\n",
            "Epoch 235, loss 0.08986450481293504\n",
            "Epoch 235, loss 0.08990917732553994\n",
            "Epoch 235, loss 0.09036606961433968\n",
            "Epoch 235, loss 0.09013941039379017\n",
            "Epoch 235, loss 0.09012664948667366\n",
            "Epoch 235, loss 0.08967202407990729\n",
            " Epoch:118 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002270788161112\n",
            "Epoch 235, loss 0.08962412744624403\n",
            "Epoch 235, loss 0.09007846564839839\n",
            "Epoch 235, loss 0.08996228611908748\n",
            "Epoch 235, loss 0.08996094149253198\n",
            "Epoch 235, loss 0.08967758127810874\n",
            "Epoch 235, loss 0.08991199222257568\n",
            "Epoch 235, loss 0.08985017881421628\n",
            "Epoch 235, loss 0.0901084783594109\n",
            "Epoch 235, loss 0.0898645046467669\n",
            "Epoch 235, loss 0.0899091768897412\n",
            "Epoch 235, loss 0.09036606911206652\n",
            "Epoch 235, loss 0.09013941050038227\n",
            "Epoch 235, loss 0.09012664877752492\n",
            "Epoch 235, loss 0.08967202401501526\n",
            " Epoch:119 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002270766576628\n",
            "Epoch 235, loss 0.08962412708817988\n",
            "Epoch 235, loss 0.09007846523465425\n",
            "Epoch 235, loss 0.08996228607150256\n",
            "Epoch 235, loss 0.08996094117162767\n",
            "Epoch 235, loss 0.0896775811922115\n",
            "Epoch 235, loss 0.08991199211838272\n",
            "Epoch 235, loss 0.08985017853487487\n",
            "Epoch 235, loss 0.09010847835248446\n",
            "Epoch 235, loss 0.08986450448060125\n",
            "Epoch 235, loss 0.08990917645395169\n",
            "Epoch 235, loss 0.09036606860980274\n",
            "Epoch 235, loss 0.0901394106069711\n",
            "Epoch 235, loss 0.09012664806839302\n",
            "Epoch 235, loss 0.08967202395012391\n",
            " Epoch:120 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002270744992494\n",
            "Epoch 235, loss 0.08962412673012295\n",
            "Epoch 235, loss 0.09007846482091883\n",
            "Epoch 235, loss 0.08996228602391784\n",
            "Epoch 235, loss 0.08996094085073107\n",
            "Epoch 235, loss 0.08967758110631704\n",
            "Epoch 235, loss 0.08991199201419171\n",
            "Epoch 235, loss 0.08985017825553891\n",
            "Epoch 235, loss 0.09010847834555805\n",
            "Epoch 235, loss 0.08986450431443811\n",
            "Epoch 235, loss 0.0899091760181714\n",
            "Epoch 235, loss 0.09036606810754837\n",
            "Epoch 235, loss 0.09013941071355668\n",
            "Epoch 235, loss 0.09012664735927796\n",
            "Epoch 235, loss 0.08967202388523329\n",
            " Epoch:121 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002270723408712\n",
            "Epoch 235, loss 0.08962412637207325\n",
            "Epoch 235, loss 0.09007846440719215\n",
            "Epoch 235, loss 0.08996228597633331\n",
            "Epoch 235, loss 0.08996094052984219\n",
            "Epoch 235, loss 0.0896775810204254\n",
            "Epoch 235, loss 0.08991199191000263\n",
            "Epoch 235, loss 0.08985017797620841\n",
            "Epoch 235, loss 0.0901084783386316\n",
            "Epoch 235, loss 0.08986450414827749\n",
            "Epoch 235, loss 0.08990917558240032\n",
            "Epoch 235, loss 0.0903660676053034\n",
            "Epoch 235, loss 0.09013941082013899\n",
            "Epoch 235, loss 0.0901266466501797\n",
            "Epoch 235, loss 0.08967202382034341\n",
            " Epoch:122 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002270701825284\n",
            "Epoch 235, loss 0.08962412601403075\n",
            "Epoch 235, loss 0.09007846399347416\n",
            "Epoch 235, loss 0.08996228592874898\n",
            "Epoch 235, loss 0.08996094020896102\n",
            "Epoch 235, loss 0.0896775809345365\n",
            "Epoch 235, loss 0.08991199180581551\n",
            "Epoch 235, loss 0.0898501776968834\n",
            "Epoch 235, loss 0.09010847833170517\n",
            "Epoch 235, loss 0.08986450398211934\n",
            "Epoch 235, loss 0.08990917514663846\n",
            "Epoch 235, loss 0.09036606710306784\n",
            "Epoch 235, loss 0.09013941092671802\n",
            "Epoch 235, loss 0.09012664594109829\n",
            "Epoch 235, loss 0.08967202375545423\n",
            " Epoch:123 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002270680242205\n",
            "Epoch 235, loss 0.08962412565599548\n",
            "Epoch 235, loss 0.09007846357976493\n",
            "Epoch 235, loss 0.08996228588116487\n",
            "Epoch 235, loss 0.08996093988808755\n",
            "Epoch 235, loss 0.08967758084865039\n",
            "Epoch 235, loss 0.0899119917016303\n",
            "Epoch 235, loss 0.08985017741756386\n",
            "Epoch 235, loss 0.09010847832477871\n",
            "Epoch 235, loss 0.08986450381596374\n",
            "Epoch 235, loss 0.0899091747108858\n",
            "Epoch 235, loss 0.09036606660084169\n",
            "Epoch 235, loss 0.09013941103329377\n",
            "Epoch 235, loss 0.09012664523203369\n",
            "Epoch 235, loss 0.08967202369056576\n",
            " Epoch:124 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002270658659481\n",
            "Epoch 235, loss 0.08962412529796741\n",
            "Epoch 235, loss 0.0900784631660644\n",
            "Epoch 235, loss 0.08996228583358093\n",
            "Epoch 235, loss 0.0899609395672218\n",
            "Epoch 235, loss 0.08967758076276706\n",
            "Epoch 235, loss 0.08991199159744707\n",
            "Epoch 235, loss 0.08985017713824976\n",
            "Epoch 235, loss 0.09010847831785226\n",
            "Epoch 235, loss 0.08986450364981059\n",
            "Epoch 235, loss 0.08990917427514236\n",
            "Epoch 235, loss 0.09036606609862492\n",
            "Epoch 235, loss 0.09013941113986626\n",
            "Epoch 235, loss 0.09012664452298591\n",
            "Epoch 235, loss 0.08967202362567803\n",
            " Epoch:125 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.0900227063707711\n",
            "Epoch 235, loss 0.08962412493994658\n",
            "Epoch 235, loss 0.09007846275237258\n",
            "Epoch 235, loss 0.08996228578599721\n",
            "Epoch 235, loss 0.08996093924636375\n",
            "Epoch 235, loss 0.08967758067688651\n",
            "Epoch 235, loss 0.08991199149326577\n",
            "Epoch 235, loss 0.08985017685894117\n",
            "Epoch 235, loss 0.0901084783109258\n",
            "Epoch 235, loss 0.08986450348365996\n",
            "Epoch 235, loss 0.08990917383940814\n",
            "Epoch 235, loss 0.09036606559641758\n",
            "Epoch 235, loss 0.09013941124643547\n",
            "Epoch 235, loss 0.09012664381395497\n",
            "Epoch 235, loss 0.08967202356079099\n",
            " Epoch:126 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.0900227061549509\n",
            "Epoch 235, loss 0.08962412458193295\n",
            "Epoch 235, loss 0.0900784623386895\n",
            "Epoch 235, loss 0.08996228573841367\n",
            "Epoch 235, loss 0.08996093892551342\n",
            "Epoch 235, loss 0.08967758059100872\n",
            "Epoch 235, loss 0.08991199138908643\n",
            "Epoch 235, loss 0.08985017657963804\n",
            "Epoch 235, loss 0.09010847830399935\n",
            "Epoch 235, loss 0.08986450331751182\n",
            "Epoch 235, loss 0.0899091734036831\n",
            "Epoch 235, loss 0.09036606509421961\n",
            "Epoch 235, loss 0.09013941135300144\n",
            "Epoch 235, loss 0.09012664310494084\n",
            "Epoch 235, loss 0.08967202349590465\n",
            " Epoch:127 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002270593913422\n",
            "Epoch 235, loss 0.08962412422392656\n",
            "Epoch 235, loss 0.09007846192501515\n",
            "Epoch 235, loss 0.08996228569083034\n",
            "Epoch 235, loss 0.0899609386046708\n",
            "Epoch 235, loss 0.08967758050513375\n",
            "Epoch 235, loss 0.08991199128490901\n",
            "Epoch 235, loss 0.08985017630034035\n",
            "Epoch 235, loss 0.09010847829707289\n",
            "Epoch 235, loss 0.0898645031513662\n",
            "Epoch 235, loss 0.0899091729679673\n",
            "Epoch 235, loss 0.09036606459203106\n",
            "Epoch 235, loss 0.0901394114595641\n",
            "Epoch 235, loss 0.09012664239594355\n",
            "Epoch 235, loss 0.08967202343101906\n",
            " Epoch:128 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002270572332106\n",
            "Epoch 235, loss 0.08962412386592737\n",
            "Epoch 235, loss 0.09007846151134949\n",
            "Epoch 235, loss 0.0899622856432472\n",
            "Epoch 235, loss 0.08996093828383589\n",
            "Epoch 235, loss 0.08967758041926152\n",
            "Epoch 235, loss 0.08991199118073354\n",
            "Epoch 235, loss 0.08985017602104814\n",
            "Epoch 235, loss 0.09010847829014643\n",
            "Epoch 235, loss 0.08986450298522307\n",
            "Epoch 235, loss 0.08990917253226072\n",
            "Epoch 235, loss 0.0903660640898519\n",
            "Epoch 235, loss 0.09013941156612351\n",
            "Epoch 235, loss 0.09012664168696308\n",
            "Epoch 235, loss 0.08967202336613418\n",
            " Epoch:129 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002270550751143\n",
            "Epoch 235, loss 0.08962412350793542\n",
            "Epoch 235, loss 0.09007846109769255\n",
            "Epoch 235, loss 0.08996228559566426\n",
            "Epoch 235, loss 0.08996093796300868\n",
            "Epoch 235, loss 0.0896775803333921\n",
            "Epoch 235, loss 0.08991199107656002\n",
            "Epoch 235, loss 0.08985017574176142\n",
            "Epoch 235, loss 0.09010847828321995\n",
            "Epoch 235, loss 0.08986450281908245\n",
            "Epoch 235, loss 0.08990917209656335\n",
            "Epoch 235, loss 0.09036606358768215\n",
            "Epoch 235, loss 0.09013941167267965\n",
            "Epoch 235, loss 0.09012664097799941\n",
            "Epoch 235, loss 0.08967202330124999\n",
            " Epoch:130 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002270529170532\n",
            "Epoch 235, loss 0.08962412314995065\n",
            "Epoch 235, loss 0.09007846068404435\n",
            "Epoch 235, loss 0.0899622855480815\n",
            "Epoch 235, loss 0.08996093764218921\n",
            "Epoch 235, loss 0.08967758024752544\n",
            "Epoch 235, loss 0.08991199097238844\n",
            "Epoch 235, loss 0.08985017546248016\n",
            "Epoch 235, loss 0.0901084782762935\n",
            "Epoch 235, loss 0.0898645026529443\n",
            "Epoch 235, loss 0.08990917166087517\n",
            "Epoch 235, loss 0.09036606308552181\n",
            "Epoch 235, loss 0.0901394117792325\n",
            "Epoch 235, loss 0.09012664026905258\n",
            "Epoch 235, loss 0.08967202323636654\n",
            " Epoch:131 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002270507590274\n",
            "Epoch 235, loss 0.08962412279197313\n",
            "Epoch 235, loss 0.09007846027040486\n",
            "Epoch 235, loss 0.08996228550049896\n",
            "Epoch 235, loss 0.08996093732137742\n",
            "Epoch 235, loss 0.08967758016166157\n",
            "Epoch 235, loss 0.0899119908682188\n",
            "Epoch 235, loss 0.08985017518320437\n",
            "Epoch 235, loss 0.09010847826936699\n",
            "Epoch 235, loss 0.08986450248680869\n",
            "Epoch 235, loss 0.08990917122519623\n",
            "Epoch 235, loss 0.09036606258337085\n",
            "Epoch 235, loss 0.09013941188578209\n",
            "Epoch 235, loss 0.09012663956012258\n",
            "Epoch 235, loss 0.08967202317148382\n",
            " Epoch:132 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002270486010368\n",
            "Epoch 235, loss 0.08962412243400282\n",
            "Epoch 235, loss 0.09007845985677411\n",
            "Epoch 235, loss 0.08996228545291661\n",
            "Epoch 235, loss 0.08996093700057335\n",
            "Epoch 235, loss 0.08967758007580046\n",
            "Epoch 235, loss 0.08991199076405111\n",
            "Epoch 235, loss 0.08985017490393403\n",
            "Epoch 235, loss 0.0901084782624405\n",
            "Epoch 235, loss 0.08986450232067554\n",
            "Epoch 235, loss 0.08990917078952648\n",
            "Epoch 235, loss 0.09036606208122931\n",
            "Epoch 235, loss 0.09013941199232842\n",
            "Epoch 235, loss 0.09012663885120939\n",
            "Epoch 235, loss 0.0896720231066018\n",
            " Epoch:133 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002270464430813\n",
            "Epoch 235, loss 0.08962412207603972\n",
            "Epoch 235, loss 0.09007845944315206\n",
            "Epoch 235, loss 0.08996228540533445\n",
            "Epoch 235, loss 0.08996093667977698\n",
            "Epoch 235, loss 0.08967757998994212\n",
            "Epoch 235, loss 0.08991199065988535\n",
            "Epoch 235, loss 0.08985017462466918\n",
            "Epoch 235, loss 0.09010847825551402\n",
            "Epoch 235, loss 0.08986450215454492\n",
            "Epoch 235, loss 0.08990917035386595\n",
            "Epoch 235, loss 0.09036606157909717\n",
            "Epoch 235, loss 0.09013941209887148\n",
            "Epoch 235, loss 0.09012663814231303\n",
            "Epoch 235, loss 0.08967202304172048\n",
            " Epoch:134 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002270442851609\n",
            "Epoch 235, loss 0.08962412171808383\n",
            "Epoch 235, loss 0.09007845902953873\n",
            "Epoch 235, loss 0.0899622853577525\n",
            "Epoch 235, loss 0.08996093635898832\n",
            "Epoch 235, loss 0.08967757990408658\n",
            "Epoch 235, loss 0.08991199055572155\n",
            "Epoch 235, loss 0.08985017434540979\n",
            "Epoch 235, loss 0.09010847824858755\n",
            "Epoch 235, loss 0.08986450198841678\n",
            "Epoch 235, loss 0.08990916991821464\n",
            "Epoch 235, loss 0.09036606107697442\n",
            "Epoch 235, loss 0.09013941220541127\n",
            "Epoch 235, loss 0.09012663743343347\n",
            "Epoch 235, loss 0.08967202297683989\n",
            " Epoch:135 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.0900227042127276\n",
            "Epoch 235, loss 0.08962412136013517\n",
            "Epoch 235, loss 0.09007845861593414\n",
            "Epoch 235, loss 0.08996228531017073\n",
            "Epoch 235, loss 0.08996093603820736\n",
            "Epoch 235, loss 0.08967757981823381\n",
            "Epoch 235, loss 0.08991199045155968\n",
            "Epoch 235, loss 0.08985017406615588\n",
            "Epoch 235, loss 0.09010847824166104\n",
            "Epoch 235, loss 0.08986450182229114\n",
            "Epoch 235, loss 0.08990916948257252\n",
            "Epoch 235, loss 0.09036606057486107\n",
            "Epoch 235, loss 0.09013941231194778\n",
            "Epoch 235, loss 0.09012663672457077\n",
            "Epoch 235, loss 0.08967202291196001\n",
            " Epoch:136 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002270399694261\n",
            "Epoch 235, loss 0.08962412100219372\n",
            "Epoch 235, loss 0.09007845820233823\n",
            "Epoch 235, loss 0.08996228526258916\n",
            "Epoch 235, loss 0.08996093571743413\n",
            "Epoch 235, loss 0.08967757973238381\n",
            "Epoch 235, loss 0.08991199034739975\n",
            "Epoch 235, loss 0.0898501737869074\n",
            "Epoch 235, loss 0.09010847823473454\n",
            "Epoch 235, loss 0.08986450165616802\n",
            "Epoch 235, loss 0.08990916904693963\n",
            "Epoch 235, loss 0.09036606007275713\n",
            "Epoch 235, loss 0.09013941241848103\n",
            "Epoch 235, loss 0.09012663601572486\n",
            "Epoch 235, loss 0.08967202284708084\n",
            " Epoch:137 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002270378116116\n",
            "Epoch 235, loss 0.08962412064425948\n",
            "Epoch 235, loss 0.09007845778875107\n",
            "Epoch 235, loss 0.0899622852150078\n",
            "Epoch 235, loss 0.08996093539666862\n",
            "Epoch 235, loss 0.0896775796465366\n",
            "Epoch 235, loss 0.08991199024324179\n",
            "Epoch 235, loss 0.08985017350766443\n",
            "Epoch 235, loss 0.09010847822780806\n",
            "Epoch 235, loss 0.08986450149004739\n",
            "Epoch 235, loss 0.08990916861131595\n",
            "Epoch 235, loss 0.09036605957066257\n",
            "Epoch 235, loss 0.09013941252501101\n",
            "Epoch 235, loss 0.09012663530689576\n",
            "Epoch 235, loss 0.0896720227822024\n",
            " Epoch:138 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002270356538322\n",
            "Epoch 235, loss 0.08962412028633247\n",
            "Epoch 235, loss 0.0900784573751726\n",
            "Epoch 235, loss 0.08996228516742664\n",
            "Epoch 235, loss 0.08996093507591077\n",
            "Epoch 235, loss 0.08967757956069218\n",
            "Epoch 235, loss 0.08991199013908575\n",
            "Epoch 235, loss 0.0898501732284269\n",
            "Epoch 235, loss 0.09010847822088153\n",
            "Epoch 235, loss 0.08986450132392927\n",
            "Epoch 235, loss 0.08990916817570146\n",
            "Epoch 235, loss 0.0903660590685774\n",
            "Epoch 235, loss 0.09013941263153771\n",
            "Epoch 235, loss 0.0901266345980835\n",
            "Epoch 235, loss 0.08967202271732469\n",
            " Epoch:139 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002270334960881\n",
            "Epoch 235, loss 0.08962411992841268\n",
            "Epoch 235, loss 0.09007845696160288\n",
            "Epoch 235, loss 0.08996228511984566\n",
            "Epoch 235, loss 0.08996093475516068\n",
            "Epoch 235, loss 0.08967757947485051\n",
            "Epoch 235, loss 0.08991199003493164\n",
            "Epoch 235, loss 0.08985017294919487\n",
            "Epoch 235, loss 0.09010847821395501\n",
            "Epoch 235, loss 0.08986450115781364\n",
            "Epoch 235, loss 0.0899091677400962\n",
            "Epoch 235, loss 0.09036605856650168\n",
            "Epoch 235, loss 0.09013941273806116\n",
            "Epoch 235, loss 0.09012663388928806\n",
            "Epoch 235, loss 0.08967202265244767\n",
            " Epoch:140 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002270313383791\n",
            "Epoch 235, loss 0.0896241195705001\n",
            "Epoch 235, loss 0.09007845654804185\n",
            "Epoch 235, loss 0.0899622850722649\n",
            "Epoch 235, loss 0.08996093443441826\n",
            "Epoch 235, loss 0.08967757938901164\n",
            "Epoch 235, loss 0.08991198993077949\n",
            "Epoch 235, loss 0.08985017266996828\n",
            "Epoch 235, loss 0.09010847820702851\n",
            "Epoch 235, loss 0.08986450099170049\n",
            "Epoch 235, loss 0.08990916730450013\n",
            "Epoch 235, loss 0.09036605806443532\n",
            "Epoch 235, loss 0.09013941284458131\n",
            "Epoch 235, loss 0.09012663318050942\n",
            "Epoch 235, loss 0.08967202258757137\n",
            " Epoch:141 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002270291807053\n",
            "Epoch 235, loss 0.08962411921259472\n",
            "Epoch 235, loss 0.09007845613448953\n",
            "Epoch 235, loss 0.08996228502468433\n",
            "Epoch 235, loss 0.08996093411368357\n",
            "Epoch 235, loss 0.08967757930317552\n",
            "Epoch 235, loss 0.08991198982662928\n",
            "Epoch 235, loss 0.08985017239074718\n",
            "Epoch 235, loss 0.090108478200102\n",
            "Epoch 235, loss 0.08986450082558986\n",
            "Epoch 235, loss 0.0899091668689133\n",
            "Epoch 235, loss 0.09036605756237837\n",
            "Epoch 235, loss 0.09013941295109822\n",
            "Epoch 235, loss 0.0901266324717476\n",
            "Epoch 235, loss 0.08967202252269578\n",
            " Epoch:142 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.0900227027023067\n",
            "Epoch 235, loss 0.08962411885469657\n",
            "Epoch 235, loss 0.09007845572094594\n",
            "Epoch 235, loss 0.08996228497710396\n",
            "Epoch 235, loss 0.08996093379295658\n",
            "Epoch 235, loss 0.08967757921734221\n",
            "Epoch 235, loss 0.08991198972248102\n",
            "Epoch 235, loss 0.08985017211153153\n",
            "Epoch 235, loss 0.09010847819317548\n",
            "Epoch 235, loss 0.08986450065948173\n",
            "Epoch 235, loss 0.08990916643333566\n",
            "Epoch 235, loss 0.09036605706033082\n",
            "Epoch 235, loss 0.09013941305761186\n",
            "Epoch 235, loss 0.09012663176300262\n",
            "Epoch 235, loss 0.08967202245782094\n",
            " Epoch:143 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002270248654635\n",
            "Epoch 235, loss 0.08962411849680563\n",
            "Epoch 235, loss 0.0900784553074111\n",
            "Epoch 235, loss 0.08996228492952377\n",
            "Epoch 235, loss 0.0899609334722373\n",
            "Epoch 235, loss 0.08967757913151164\n",
            "Epoch 235, loss 0.0899119896183347\n",
            "Epoch 235, loss 0.08985017183232133\n",
            "Epoch 235, loss 0.09010847818624894\n",
            "Epoch 235, loss 0.0898645004933761\n",
            "Epoch 235, loss 0.08990916599776724\n",
            "Epoch 235, loss 0.09036605655829266\n",
            "Epoch 235, loss 0.09013941316412222\n",
            "Epoch 235, loss 0.09012663105427444\n",
            "Epoch 235, loss 0.08967202239294678\n",
            " Epoch:144 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002270227078954\n",
            "Epoch 235, loss 0.0896241181389219\n",
            "Epoch 235, loss 0.09007845489388493\n",
            "Epoch 235, loss 0.08996228488194379\n",
            "Epoch 235, loss 0.0899609331515257\n",
            "Epoch 235, loss 0.08967757904568388\n",
            "Epoch 235, loss 0.08991198951419033\n",
            "Epoch 235, loss 0.08985017155311661\n",
            "Epoch 235, loss 0.0901084781793224\n",
            "Epoch 235, loss 0.08986450032727297\n",
            "Epoch 235, loss 0.089909165562208\n",
            "Epoch 235, loss 0.09036605605626391\n",
            "Epoch 235, loss 0.09013941327062931\n",
            "Epoch 235, loss 0.09012663034556306\n",
            "Epoch 235, loss 0.08967202232807334\n",
            " Epoch:145 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002270205503626\n",
            "Epoch 235, loss 0.0896241177810454\n",
            "Epoch 235, loss 0.0900784544803675\n",
            "Epoch 235, loss 0.089962284834364\n",
            "Epoch 235, loss 0.08996093283082182\n",
            "Epoch 235, loss 0.08967757895985888\n",
            "Epoch 235, loss 0.08991198941004788\n",
            "Epoch 235, loss 0.08985017127391737\n",
            "Epoch 235, loss 0.09010847817239587\n",
            "Epoch 235, loss 0.08986450016117234\n",
            "Epoch 235, loss 0.089909165126658\n",
            "Epoch 235, loss 0.09036605555424454\n",
            "Epoch 235, loss 0.09013941337713313\n",
            "Epoch 235, loss 0.09012662963686853\n",
            "Epoch 235, loss 0.08967202226320062\n",
            " Epoch:146 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002270183928648\n",
            "Epoch 235, loss 0.08962411742317611\n",
            "Epoch 235, loss 0.09007845406685878\n",
            "Epoch 235, loss 0.0899622847867844\n",
            "Epoch 235, loss 0.08996093251012567\n",
            "Epoch 235, loss 0.08967757887403667\n",
            "Epoch 235, loss 0.08991198930590738\n",
            "Epoch 235, loss 0.08985017099472359\n",
            "Epoch 235, loss 0.09010847816546932\n",
            "Epoch 235, loss 0.0898644999950742\n",
            "Epoch 235, loss 0.0899091646911172\n",
            "Epoch 235, loss 0.09036605505223458\n",
            "Epoch 235, loss 0.0901394134836337\n",
            "Epoch 235, loss 0.0901266289281908\n",
            "Epoch 235, loss 0.08967202219832862\n",
            " Epoch:147 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002270162354023\n",
            "Epoch 235, loss 0.08962411706531404\n",
            "Epoch 235, loss 0.09007845365335879\n",
            "Epoch 235, loss 0.08996228473920502\n",
            "Epoch 235, loss 0.08996093218943721\n",
            "Epoch 235, loss 0.08967757878821722\n",
            "Epoch 235, loss 0.08991198920176882\n",
            "Epoch 235, loss 0.08985017071553526\n",
            "Epoch 235, loss 0.0901084781585428\n",
            "Epoch 235, loss 0.08986449982897857\n",
            "Epoch 235, loss 0.08990916425558562\n",
            "Epoch 235, loss 0.09036605455023403\n",
            "Epoch 235, loss 0.090139413590131\n",
            "Epoch 235, loss 0.09012662821952988\n",
            "Epoch 235, loss 0.08967202213345733\n",
            " Epoch:148 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002270140779753\n",
            "Epoch 235, loss 0.08962411670745916\n",
            "Epoch 235, loss 0.09007845323986748\n",
            "Epoch 235, loss 0.08996228469162584\n",
            "Epoch 235, loss 0.08996093186875645\n",
            "Epoch 235, loss 0.08967757870240055\n",
            "Epoch 235, loss 0.0899119890976322\n",
            "Epoch 235, loss 0.08985017043635242\n",
            "Epoch 235, loss 0.09010847815161623\n",
            "Epoch 235, loss 0.08986449966288543\n",
            "Epoch 235, loss 0.08990916382006323\n",
            "Epoch 235, loss 0.09036605404824283\n",
            "Epoch 235, loss 0.09013941369662501\n",
            "Epoch 235, loss 0.09012662751088578\n",
            "Epoch 235, loss 0.08967202206858675\n",
            " Epoch:149 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002270119205831\n",
            "Epoch 235, loss 0.08962411634961152\n",
            "Epoch 235, loss 0.09007845282638491\n",
            "Epoch 235, loss 0.08996228464404685\n",
            "Epoch 235, loss 0.0899609315480834\n",
            "Epoch 235, loss 0.08967757861658666\n",
            "Epoch 235, loss 0.08991198899349755\n",
            "Epoch 235, loss 0.08985017015717503\n",
            "Epoch 235, loss 0.0901084781446897\n",
            "Epoch 235, loss 0.0898644994967948\n",
            "Epoch 235, loss 0.08990916338455004\n",
            "Epoch 235, loss 0.09036605354626108\n",
            "Epoch 235, loss 0.09013941380311577\n",
            "Epoch 235, loss 0.0901266268022585\n",
            "Epoch 235, loss 0.0896720220037169\n",
            " Epoch:150 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002270097632262\n",
            "Epoch 235, loss 0.08962411599177107\n",
            "Epoch 235, loss 0.09007845241291104\n",
            "Epoch 235, loss 0.08996228459646802\n",
            "Epoch 235, loss 0.08996093122741805\n",
            "Epoch 235, loss 0.08967757853077556\n",
            "Epoch 235, loss 0.08991198888936483\n",
            "Epoch 235, loss 0.08985016987800312\n",
            "Epoch 235, loss 0.09010847813776313\n",
            "Epoch 235, loss 0.08986449933070666\n",
            "Epoch 235, loss 0.08990916294904608\n",
            "Epoch 235, loss 0.09036605304428869\n",
            "Epoch 235, loss 0.09013941390960326\n",
            "Epoch 235, loss 0.09012662609364802\n",
            "Epoch 235, loss 0.08967202193884775\n",
            " Epoch:151 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002270076059046\n",
            "Epoch 235, loss 0.08962411563393786\n",
            "Epoch 235, loss 0.0900784519994459\n",
            "Epoch 235, loss 0.08996228454888944\n",
            "Epoch 235, loss 0.08996093090676041\n",
            "Epoch 235, loss 0.0896775784449672\n",
            "Epoch 235, loss 0.08991198878523404\n",
            "Epoch 235, loss 0.08985016959883667\n",
            "Epoch 235, loss 0.09010847813083656\n",
            "Epoch 235, loss 0.08986449916462103\n",
            "Epoch 235, loss 0.0899091625135513\n",
            "Epoch 235, loss 0.09036605254232574\n",
            "Epoch 235, loss 0.09013941401608747\n",
            "Epoch 235, loss 0.09012662538505437\n",
            "Epoch 235, loss 0.08967202187397934\n",
            " Epoch:152 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.0900227005448618\n",
            "Epoch 235, loss 0.08962411527611186\n",
            "Epoch 235, loss 0.09007845158598947\n",
            "Epoch 235, loss 0.08996228450131102\n",
            "Epoch 235, loss 0.08996093058611049\n",
            "Epoch 235, loss 0.08967757835916165\n",
            "Epoch 235, loss 0.0899119886811052\n",
            "Epoch 235, loss 0.0898501693196757\n",
            "Epoch 235, loss 0.09010847812390999\n",
            "Epoch 235, loss 0.08986449899853788\n",
            "Epoch 235, loss 0.08990916207806575\n",
            "Epoch 235, loss 0.09036605204037214\n",
            "Epoch 235, loss 0.0901394141225684\n",
            "Epoch 235, loss 0.09012662467647752\n",
            "Epoch 235, loss 0.08967202180911163\n",
            " Epoch:153 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002270032913669\n",
            "Epoch 235, loss 0.08962411491829307\n",
            "Epoch 235, loss 0.09007845117254176\n",
            "Epoch 235, loss 0.08996228445373283\n",
            "Epoch 235, loss 0.08996093026546825\n",
            "Epoch 235, loss 0.08967757827335886\n",
            "Epoch 235, loss 0.08991198857697831\n",
            "Epoch 235, loss 0.08985016904052016\n",
            "Epoch 235, loss 0.09010847811698341\n",
            "Epoch 235, loss 0.08986449883245724\n",
            "Epoch 235, loss 0.0899091616425894\n",
            "Epoch 235, loss 0.09036605153842796\n",
            "Epoch 235, loss 0.0901394142290461\n",
            "Epoch 235, loss 0.09012662396791749\n",
            "Epoch 235, loss 0.08967202174424463\n",
            " Epoch:154 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002270011341508\n",
            "Epoch 235, loss 0.08962411456048147\n",
            "Epoch 235, loss 0.09007845075910276\n",
            "Epoch 235, loss 0.08996228440615484\n",
            "Epoch 235, loss 0.08996092994483373\n",
            "Epoch 235, loss 0.08967757818755887\n",
            "Epoch 235, loss 0.08991198847285335\n",
            "Epoch 235, loss 0.08985016876137011\n",
            "Epoch 235, loss 0.09010847811005684\n",
            "Epoch 235, loss 0.0898644986663791\n",
            "Epoch 235, loss 0.08990916120712225\n",
            "Epoch 235, loss 0.09036605103649316\n",
            "Epoch 235, loss 0.0901394143355205\n",
            "Epoch 235, loss 0.09012662325937426\n",
            "Epoch 235, loss 0.08967202167937835\n",
            " Epoch:155 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.090022699897697\n",
            "Epoch 235, loss 0.08962411420267713\n",
            "Epoch 235, loss 0.09007845034567248\n",
            "Epoch 235, loss 0.08996228435857702\n",
            "Epoch 235, loss 0.0899609296242069\n",
            "Epoch 235, loss 0.08967757810176163\n",
            "Epoch 235, loss 0.08991198836873034\n",
            "Epoch 235, loss 0.08985016848222553\n",
            "Epoch 235, loss 0.09010847810313025\n",
            "Epoch 235, loss 0.08986449850030345\n",
            "Epoch 235, loss 0.08990916077166432\n",
            "Epoch 235, loss 0.09036605053456778\n",
            "Epoch 235, loss 0.09013941444199167\n",
            "Epoch 235, loss 0.09012662255084784\n",
            "Epoch 235, loss 0.08967202161451279\n",
            " Epoch:156 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002269968198243\n",
            "Epoch 235, loss 0.08962411384487998\n",
            "Epoch 235, loss 0.09007844993225089\n",
            "Epoch 235, loss 0.08996228431099941\n",
            "Epoch 235, loss 0.08996092930358779\n",
            "Epoch 235, loss 0.08967757801596717\n",
            "Epoch 235, loss 0.08991198826460928\n",
            "Epoch 235, loss 0.0898501682030864\n",
            "Epoch 235, loss 0.09010847809620368\n",
            "Epoch 235, loss 0.08986449833423032\n",
            "Epoch 235, loss 0.08990916033621559\n",
            "Epoch 235, loss 0.09036605003265177\n",
            "Epoch 235, loss 0.09013941454845953\n",
            "Epoch 235, loss 0.09012662184233824\n",
            "Epoch 235, loss 0.08967202154964794\n",
            " Epoch:157 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002269946627138\n",
            "Epoch 235, loss 0.08962411348709003\n",
            "Epoch 235, loss 0.09007844951883803\n",
            "Epoch 235, loss 0.08996228426342198\n",
            "Epoch 235, loss 0.08996092898297636\n",
            "Epoch 235, loss 0.0896775779301755\n",
            "Epoch 235, loss 0.08991198816049013\n",
            "Epoch 235, loss 0.08985016792395276\n",
            "Epoch 235, loss 0.09010847808927709\n",
            "Epoch 235, loss 0.08986449816815967\n",
            "Epoch 235, loss 0.08990915990077605\n",
            "Epoch 235, loss 0.09036604953074516\n",
            "Epoch 235, loss 0.09013941465492413\n",
            "Epoch 235, loss 0.09012662113384545\n",
            "Epoch 235, loss 0.0896720214847838\n",
            " Epoch:158 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002269925056386\n",
            "Epoch 235, loss 0.08962411312930732\n",
            "Epoch 235, loss 0.09007844910543387\n",
            "Epoch 235, loss 0.08996228421584478\n",
            "Epoch 235, loss 0.08996092866237267\n",
            "Epoch 235, loss 0.0896775778443866\n",
            "Epoch 235, loss 0.08991198805637295\n",
            "Epoch 235, loss 0.08985016764482456\n",
            "Epoch 235, loss 0.0901084780823505\n",
            "Epoch 235, loss 0.08986449800209154\n",
            "Epoch 235, loss 0.08990915946534575\n",
            "Epoch 235, loss 0.09036604902884796\n",
            "Epoch 235, loss 0.09013941476138548\n",
            "Epoch 235, loss 0.09012662042536948\n",
            "Epoch 235, loss 0.0896720214199204\n",
            " Epoch:159 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002269903485985\n",
            "Epoch 235, loss 0.08962411277153179\n",
            "Epoch 235, loss 0.09007844869203845\n",
            "Epoch 235, loss 0.08996228416826776\n",
            "Epoch 235, loss 0.08996092834177666\n",
            "Epoch 235, loss 0.08967757775860045\n",
            "Epoch 235, loss 0.0899119879522577\n",
            "Epoch 235, loss 0.08985016736570182\n",
            "Epoch 235, loss 0.0901084780754239\n",
            "Epoch 235, loss 0.08986449783602589\n",
            "Epoch 235, loss 0.08990915902992462\n",
            "Epoch 235, loss 0.09036604852696013\n",
            "Epoch 235, loss 0.09013941486784356\n",
            "Epoch 235, loss 0.09012661971691031\n",
            "Epoch 235, loss 0.08967202135505767\n",
            " Epoch:160 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002269881915935\n",
            "Epoch 235, loss 0.0896241124137635\n",
            "Epoch 235, loss 0.09007844827865172\n",
            "Epoch 235, loss 0.08996228412069093\n",
            "Epoch 235, loss 0.08996092802118835\n",
            "Epoch 235, loss 0.0896775776728171\n",
            "Epoch 235, loss 0.0899119878481444\n",
            "Epoch 235, loss 0.08985016708658457\n",
            "Epoch 235, loss 0.0901084780684973\n",
            "Epoch 235, loss 0.08986449766996274\n",
            "Epoch 235, loss 0.08990915859451272\n",
            "Epoch 235, loss 0.09036604802508172\n",
            "Epoch 235, loss 0.09013941497429837\n",
            "Epoch 235, loss 0.09012661900846794\n",
            "Epoch 235, loss 0.0896720212901957\n",
            " Epoch:161 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002269860346238\n",
            "Epoch 235, loss 0.0896241120560024\n",
            "Epoch 235, loss 0.0900784478652737\n",
            "Epoch 235, loss 0.08996228407311431\n",
            "Epoch 235, loss 0.08996092770060775\n",
            "Epoch 235, loss 0.08967757758703651\n",
            "Epoch 235, loss 0.08991198774403304\n",
            "Epoch 235, loss 0.08985016680747276\n",
            "Epoch 235, loss 0.09010847806157068\n",
            "Epoch 235, loss 0.08986449750390209\n",
            "Epoch 235, loss 0.08990915815911002\n",
            "Epoch 235, loss 0.09036604752321269\n",
            "Epoch 235, loss 0.09013941508074992\n",
            "Epoch 235, loss 0.0901266183000424\n",
            "Epoch 235, loss 0.08967202122533442\n",
            " Epoch:162 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002269838776893\n",
            "Epoch 235, loss 0.08962411169824853\n",
            "Epoch 235, loss 0.09007844745190441\n",
            "Epoch 235, loss 0.0899622840255379\n",
            "Epoch 235, loss 0.08996092738003486\n",
            "Epoch 235, loss 0.08967757750125872\n",
            "Epoch 235, loss 0.08991198763992363\n",
            "Epoch 235, loss 0.08985016652836643\n",
            "Epoch 235, loss 0.09010847805464409\n",
            "Epoch 235, loss 0.08986449733784393\n",
            "Epoch 235, loss 0.08990915772371652\n",
            "Epoch 235, loss 0.09036604702135306\n",
            "Epoch 235, loss 0.09013941518719819\n",
            "Epoch 235, loss 0.09012661759163365\n",
            "Epoch 235, loss 0.08967202116047387\n",
            " Epoch:163 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.090022698172079\n",
            "Epoch 235, loss 0.08962411134050187\n",
            "Epoch 235, loss 0.09007844703854384\n",
            "Epoch 235, loss 0.08996228397796166\n",
            "Epoch 235, loss 0.08996092705946965\n",
            "Epoch 235, loss 0.08967757741548368\n",
            "Epoch 235, loss 0.08991198753581615\n",
            "Epoch 235, loss 0.08985016624926556\n",
            "Epoch 235, loss 0.09010847804771746\n",
            "Epoch 235, loss 0.08986449717178828\n",
            "Epoch 235, loss 0.08990915728833224\n",
            "Epoch 235, loss 0.09036604651950282\n",
            "Epoch 235, loss 0.0901394152936432\n",
            "Epoch 235, loss 0.09012661688324172\n",
            "Epoch 235, loss 0.08967202109561405\n",
            " Epoch:164 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002269795639259\n",
            "Epoch 235, loss 0.08962411098276243\n",
            "Epoch 235, loss 0.09007844662519195\n",
            "Epoch 235, loss 0.08996228393038563\n",
            "Epoch 235, loss 0.08996092673891216\n",
            "Epoch 235, loss 0.08967757732971145\n",
            "Epoch 235, loss 0.08991198743171061\n",
            "Epoch 235, loss 0.08985016597017016\n",
            "Epoch 235, loss 0.09010847804079083\n",
            "Epoch 235, loss 0.08986449700573514\n",
            "Epoch 235, loss 0.08990915685295714\n",
            "Epoch 235, loss 0.09036604601766197\n",
            "Epoch 235, loss 0.09013941540008495\n",
            "Epoch 235, loss 0.09012661617486659\n",
            "Epoch 235, loss 0.08967202103075492\n",
            " Epoch:165 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002269774070969\n",
            "Epoch 235, loss 0.0896241106250302\n",
            "Epoch 235, loss 0.09007844621184877\n",
            "Epoch 235, loss 0.08996228388280982\n",
            "Epoch 235, loss 0.08996092641836237\n",
            "Epoch 235, loss 0.08967757724394196\n",
            "Epoch 235, loss 0.08991198732760702\n",
            "Epoch 235, loss 0.08985016569108022\n",
            "Epoch 235, loss 0.09010847803386421\n",
            "Epoch 235, loss 0.08986449683968448\n",
            "Epoch 235, loss 0.08990915641759127\n",
            "Epoch 235, loss 0.09036604551583052\n",
            "Epoch 235, loss 0.09013941550652342\n",
            "Epoch 235, loss 0.09012661546650827\n",
            "Epoch 235, loss 0.08967202096589649\n",
            " Epoch:166 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002269752503031\n",
            "Epoch 235, loss 0.08962411026730517\n",
            "Epoch 235, loss 0.09007844579851434\n",
            "Epoch 235, loss 0.08996228383523416\n",
            "Epoch 235, loss 0.08996092609782029\n",
            "Epoch 235, loss 0.08967757715817526\n",
            "Epoch 235, loss 0.08991198722350538\n",
            "Epoch 235, loss 0.08985016541199574\n",
            "Epoch 235, loss 0.0901084780269376\n",
            "Epoch 235, loss 0.08986449667363634\n",
            "Epoch 235, loss 0.08990915598223456\n",
            "Epoch 235, loss 0.09036604501400847\n",
            "Epoch 235, loss 0.09013941561295863\n",
            "Epoch 235, loss 0.09012661475816676\n",
            "Epoch 235, loss 0.0896720209010388\n",
            " Epoch:167 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002269730935446\n",
            "Epoch 235, loss 0.08962410990958736\n",
            "Epoch 235, loss 0.09007844538518858\n",
            "Epoch 235, loss 0.08996228378765873\n",
            "Epoch 235, loss 0.0899609257772859\n",
            "Epoch 235, loss 0.08967757707241134\n",
            "Epoch 235, loss 0.08991198711940566\n",
            "Epoch 235, loss 0.08985016513291673\n",
            "Epoch 235, loss 0.09010847802001096\n",
            "Epoch 235, loss 0.08986449650759068\n",
            "Epoch 235, loss 0.0899091555468871\n",
            "Epoch 235, loss 0.0903660445121958\n",
            "Epoch 235, loss 0.09013941571939058\n",
            "Epoch 235, loss 0.09012661404984204\n",
            "Epoch 235, loss 0.08967202083618182\n",
            " Epoch:168 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002269709368213\n",
            "Epoch 235, loss 0.08962410955187675\n",
            "Epoch 235, loss 0.09007844497187155\n",
            "Epoch 235, loss 0.0899622837400835\n",
            "Epoch 235, loss 0.08996092545675921\n",
            "Epoch 235, loss 0.08967757698665017\n",
            "Epoch 235, loss 0.08991198701530788\n",
            "Epoch 235, loss 0.08985016485384319\n",
            "Epoch 235, loss 0.09010847801308432\n",
            "Epoch 235, loss 0.0898644963415475\n",
            "Epoch 235, loss 0.08990915511154882\n",
            "Epoch 235, loss 0.09036604401039253\n",
            "Epoch 235, loss 0.09013941582581925\n",
            "Epoch 235, loss 0.09012661334153414\n",
            "Epoch 235, loss 0.08967202077132555\n",
            " Epoch:169 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.0900226968780133\n",
            "Epoch 235, loss 0.08962410919417335\n",
            "Epoch 235, loss 0.09007844455856323\n",
            "Epoch 235, loss 0.08996228369250847\n",
            "Epoch 235, loss 0.08996092513624024\n",
            "Epoch 235, loss 0.0896775769008918\n",
            "Epoch 235, loss 0.08991198691121205\n",
            "Epoch 235, loss 0.0898501645747751\n",
            "Epoch 235, loss 0.09010847800615769\n",
            "Epoch 235, loss 0.08986449617550685\n",
            "Epoch 235, loss 0.08990915467621977\n",
            "Epoch 235, loss 0.09036604350859864\n",
            "Epoch 235, loss 0.09013941593224466\n",
            "Epoch 235, loss 0.09012661263324305\n",
            "Epoch 235, loss 0.08967202070647003\n",
            " Epoch:170 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.090022696662348\n",
            "Epoch 235, loss 0.08962410883647717\n",
            "Epoch 235, loss 0.09007844414526363\n",
            "Epoch 235, loss 0.08996228364493361\n",
            "Epoch 235, loss 0.08996092481572895\n",
            "Epoch 235, loss 0.08967757681513619\n",
            "Epoch 235, loss 0.08991198680711819\n",
            "Epoch 235, loss 0.08985016429571246\n",
            "Epoch 235, loss 0.09010847799923102\n",
            "Epoch 235, loss 0.08986449600946869\n",
            "Epoch 235, loss 0.08990915424089989\n",
            "Epoch 235, loss 0.09036604300681417\n",
            "Epoch 235, loss 0.09013941603866679\n",
            "Epoch 235, loss 0.09012661192496876\n",
            "Epoch 235, loss 0.08967202064161518\n",
            " Epoch:171 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002269644668622\n",
            "Epoch 235, loss 0.0896241084787882\n",
            "Epoch 235, loss 0.09007844373197271\n",
            "Epoch 235, loss 0.08996228359735897\n",
            "Epoch 235, loss 0.08996092449522536\n",
            "Epoch 235, loss 0.08967757672938337\n",
            "Epoch 235, loss 0.08991198670302625\n",
            "Epoch 235, loss 0.08985016401665531\n",
            "Epoch 235, loss 0.0901084779923044\n",
            "Epoch 235, loss 0.08986449584343302\n",
            "Epoch 235, loss 0.08990915380558921\n",
            "Epoch 235, loss 0.09036604250503906\n",
            "Epoch 235, loss 0.0901394161450857\n",
            "Epoch 235, loss 0.09012661121671128\n",
            "Epoch 235, loss 0.08967202057676107\n",
            " Epoch:172 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002269623102795\n",
            "Epoch 235, loss 0.08962410812110644\n",
            "Epoch 235, loss 0.09007844331869053\n",
            "Epoch 235, loss 0.08996228354978454\n",
            "Epoch 235, loss 0.08996092417472948\n",
            "Epoch 235, loss 0.08967757664363332\n",
            "Epoch 235, loss 0.08991198659893625\n",
            "Epoch 235, loss 0.0898501637376036\n",
            "Epoch 235, loss 0.09010847798537772\n",
            "Epoch 235, loss 0.08986449567739985\n",
            "Epoch 235, loss 0.08990915337028776\n",
            "Epoch 235, loss 0.09036604200327336\n",
            "Epoch 235, loss 0.0901394162515013\n",
            "Epoch 235, loss 0.09012661050847058\n",
            "Epoch 235, loss 0.08967202051190766\n",
            " Epoch:173 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.0900226960153732\n",
            "Epoch 235, loss 0.0896241077634319\n",
            "Epoch 235, loss 0.09007844290541704\n",
            "Epoch 235, loss 0.08996228350221029\n",
            "Epoch 235, loss 0.08996092385424129\n",
            "Epoch 235, loss 0.08967757655788604\n",
            "Epoch 235, loss 0.08991198649484818\n",
            "Epoch 235, loss 0.08985016345855737\n",
            "Epoch 235, loss 0.09010847797845108\n",
            "Epoch 235, loss 0.08986449551136919\n",
            "Epoch 235, loss 0.0899091529349955\n",
            "Epoch 235, loss 0.09036604150151704\n",
            "Epoch 235, loss 0.09013941635791364\n",
            "Epoch 235, loss 0.09012660980024671\n",
            "Epoch 235, loss 0.08967202044705495\n",
            " Epoch:174 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002269579972197\n",
            "Epoch 235, loss 0.08962410740576457\n",
            "Epoch 235, loss 0.09007844249215227\n",
            "Epoch 235, loss 0.08996228345463624\n",
            "Epoch 235, loss 0.0899609235337608\n",
            "Epoch 235, loss 0.08967757647214152\n",
            "Epoch 235, loss 0.08991198639076206\n",
            "Epoch 235, loss 0.08985016317951659\n",
            "Epoch 235, loss 0.0901084779715244\n",
            "Epoch 235, loss 0.08986449534534101\n",
            "Epoch 235, loss 0.08990915249971246\n",
            "Epoch 235, loss 0.09036604099977014\n",
            "Epoch 235, loss 0.09013941646432273\n",
            "Epoch 235, loss 0.09012660909203965\n",
            "Epoch 235, loss 0.08967202038220301\n",
            " Epoch:175 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002269558407427\n",
            "Epoch 235, loss 0.08962410704810443\n",
            "Epoch 235, loss 0.09007844207889619\n",
            "Epoch 235, loss 0.08996228340706239\n",
            "Epoch 235, loss 0.08996092321328801\n",
            "Epoch 235, loss 0.08967757638639981\n",
            "Epoch 235, loss 0.08991198628667789\n",
            "Epoch 235, loss 0.08985016290048128\n",
            "Epoch 235, loss 0.09010847796459773\n",
            "Epoch 235, loss 0.08986449517931536\n",
            "Epoch 235, loss 0.08990915206443859\n",
            "Epoch 235, loss 0.09036604049803261\n",
            "Epoch 235, loss 0.09013941657072855\n",
            "Epoch 235, loss 0.09012660838384937\n",
            "Epoch 235, loss 0.08967202031735173\n",
            " Epoch:176 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002269536843006\n",
            "Epoch 235, loss 0.08962410669045151\n",
            "Epoch 235, loss 0.09007844166564884\n",
            "Epoch 235, loss 0.08996228335948875\n",
            "Epoch 235, loss 0.08996092289282294\n",
            "Epoch 235, loss 0.08967757630066084\n",
            "Epoch 235, loss 0.08991198618259565\n",
            "Epoch 235, loss 0.08985016262145144\n",
            "Epoch 235, loss 0.09010847795767105\n",
            "Epoch 235, loss 0.08986449501329216\n",
            "Epoch 235, loss 0.08990915162917393\n",
            "Epoch 235, loss 0.09036603999630446\n",
            "Epoch 235, loss 0.09013941667713107\n",
            "Epoch 235, loss 0.0901266076756759\n",
            "Epoch 235, loss 0.0896720202525012\n",
            " Epoch:177 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002269515278939\n",
            "Epoch 235, loss 0.0896241063328058\n",
            "Epoch 235, loss 0.09007844125241019\n",
            "Epoch 235, loss 0.08996228331191528\n",
            "Epoch 235, loss 0.08996092257236554\n",
            "Epoch 235, loss 0.08967757621492466\n",
            "Epoch 235, loss 0.08991198607851536\n",
            "Epoch 235, loss 0.08985016234242707\n",
            "Epoch 235, loss 0.09010847795074436\n",
            "Epoch 235, loss 0.0898644948472715\n",
            "Epoch 235, loss 0.08990915119391849\n",
            "Epoch 235, loss 0.0903660394945857\n",
            "Epoch 235, loss 0.09013941678353038\n",
            "Epoch 235, loss 0.09012660696751923\n",
            "Epoch 235, loss 0.08967202018765137\n",
            " Epoch:178 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002269493715223\n",
            "Epoch 235, loss 0.0896241059751673\n",
            "Epoch 235, loss 0.09007844083918025\n",
            "Epoch 235, loss 0.08996228326434201\n",
            "Epoch 235, loss 0.08996092225191585\n",
            "Epoch 235, loss 0.08967757612919124\n",
            "Epoch 235, loss 0.08991198597443702\n",
            "Epoch 235, loss 0.08985016206340814\n",
            "Epoch 235, loss 0.09010847794381768\n",
            "Epoch 235, loss 0.08986449468125332\n",
            "Epoch 235, loss 0.08990915075867222\n",
            "Epoch 235, loss 0.09036603899287636\n",
            "Epoch 235, loss 0.09013941688992641\n",
            "Epoch 235, loss 0.09012660625937936\n",
            "Epoch 235, loss 0.08967202012280226\n",
            " Epoch:179 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002269472151858\n",
            "Epoch 235, loss 0.08962410561753602\n",
            "Epoch 235, loss 0.090078440425959\n",
            "Epoch 235, loss 0.08996228321676898\n",
            "Epoch 235, loss 0.08996092193147388\n",
            "Epoch 235, loss 0.08967757604346063\n",
            "Epoch 235, loss 0.08991198587036062\n",
            "Epoch 235, loss 0.08985016178439467\n",
            "Epoch 235, loss 0.09010847793689099\n",
            "Epoch 235, loss 0.08986449451523763\n",
            "Epoch 235, loss 0.08990915032343516\n",
            "Epoch 235, loss 0.09036603849117639\n",
            "Epoch 235, loss 0.09013941699631915\n",
            "Epoch 235, loss 0.09012660555125629\n",
            "Epoch 235, loss 0.08967202005795387\n",
            " Epoch:180 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002269450588847\n",
            "Epoch 235, loss 0.08962410525991195\n",
            "Epoch 235, loss 0.09007844001274648\n",
            "Epoch 235, loss 0.0899622831691961\n",
            "Epoch 235, loss 0.08996092161103957\n",
            "Epoch 235, loss 0.08967757595773275\n",
            "Epoch 235, loss 0.08991198576628615\n",
            "Epoch 235, loss 0.08985016150538669\n",
            "Epoch 235, loss 0.0901084779299643\n",
            "Epoch 235, loss 0.08986449434922446\n",
            "Epoch 235, loss 0.08990914988820731\n",
            "Epoch 235, loss 0.09036603798948581\n",
            "Epoch 235, loss 0.09013941710270865\n",
            "Epoch 235, loss 0.09012660484315003\n",
            "Epoch 235, loss 0.08967201999310617\n",
            " Epoch:181 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002269429026186\n",
            "Epoch 235, loss 0.08962410490229507\n",
            "Epoch 235, loss 0.09007843959954268\n",
            "Epoch 235, loss 0.08996228312162344\n",
            "Epoch 235, loss 0.08996092129061299\n",
            "Epoch 235, loss 0.08967757587200767\n",
            "Epoch 235, loss 0.08991198566221362\n",
            "Epoch 235, loss 0.08985016122638415\n",
            "Epoch 235, loss 0.09010847792303761\n",
            "Epoch 235, loss 0.08986449418321377\n",
            "Epoch 235, loss 0.08990914945298867\n",
            "Epoch 235, loss 0.09036603748780461\n",
            "Epoch 235, loss 0.09013941720909488\n",
            "Epoch 235, loss 0.09012660413506057\n",
            "Epoch 235, loss 0.08967201992825921\n",
            " Epoch:182 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002269407463878\n",
            "Epoch 235, loss 0.08962410454468542\n",
            "Epoch 235, loss 0.09007843918634754\n",
            "Epoch 235, loss 0.08996228307405099\n",
            "Epoch 235, loss 0.0899609209701941\n",
            "Epoch 235, loss 0.08967757578628535\n",
            "Epoch 235, loss 0.08991198555814303\n",
            "Epoch 235, loss 0.08985016094738708\n",
            "Epoch 235, loss 0.0901084779161109\n",
            "Epoch 235, loss 0.08986449401720559\n",
            "Epoch 235, loss 0.08990914901777922\n",
            "Epoch 235, loss 0.09036603698613281\n",
            "Epoch 235, loss 0.09013941731547784\n",
            "Epoch 235, loss 0.0901266034269879\n",
            "Epoch 235, loss 0.08967201986341296\n",
            " Epoch:183 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002269385901919\n",
            "Epoch 235, loss 0.08962410418708297\n",
            "Epoch 235, loss 0.09007843877316114\n",
            "Epoch 235, loss 0.08996228302647871\n",
            "Epoch 235, loss 0.08996092064978292\n",
            "Epoch 235, loss 0.08967757570056581\n",
            "Epoch 235, loss 0.08991198545407438\n",
            "Epoch 235, loss 0.08985016066839546\n",
            "Epoch 235, loss 0.09010847790918419\n",
            "Epoch 235, loss 0.0898644938511999\n",
            "Epoch 235, loss 0.08990914858257895\n",
            "Epoch 235, loss 0.09036603648447042\n",
            "Epoch 235, loss 0.09013941742185753\n",
            "Epoch 235, loss 0.09012660271893205\n",
            "Epoch 235, loss 0.08967201979856743\n",
            " Epoch:184 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002269364340314\n",
            "Epoch 235, loss 0.08962410382948774\n",
            "Epoch 235, loss 0.09007843835998344\n",
            "Epoch 235, loss 0.08996228297890665\n",
            "Epoch 235, loss 0.08996092032937941\n",
            "Epoch 235, loss 0.08967757561484904\n",
            "Epoch 235, loss 0.08991198535000769\n",
            "Epoch 235, loss 0.08985016038940932\n",
            "Epoch 235, loss 0.09010847790225748\n",
            "Epoch 235, loss 0.0898644936851967\n",
            "Epoch 235, loss 0.08990914814738792\n",
            "Epoch 235, loss 0.09036603598281738\n",
            "Epoch 235, loss 0.09013941752823396\n",
            "Epoch 235, loss 0.09012660201089298\n",
            "Epoch 235, loss 0.0896720197337226\n",
            " Epoch:185 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.0900226934277906\n",
            "Epoch 235, loss 0.08962410347189971\n",
            "Epoch 235, loss 0.09007843794681444\n",
            "Epoch 235, loss 0.08996228293133478\n",
            "Epoch 235, loss 0.08996092000898362\n",
            "Epoch 235, loss 0.08967757552913505\n",
            "Epoch 235, loss 0.08991198524594292\n",
            "Epoch 235, loss 0.08985016011042864\n",
            "Epoch 235, loss 0.09010847789533076\n",
            "Epoch 235, loss 0.08986449351919601\n",
            "Epoch 235, loss 0.08990914771220607\n",
            "Epoch 235, loss 0.09036603548117378\n",
            "Epoch 235, loss 0.09013941763460712\n",
            "Epoch 235, loss 0.09012660130287072\n",
            "Epoch 235, loss 0.08967201966887849\n",
            " Epoch:186 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002269321218156\n",
            "Epoch 235, loss 0.08962410311431888\n",
            "Epoch 235, loss 0.09007843753365416\n",
            "Epoch 235, loss 0.08996228288376311\n",
            "Epoch 235, loss 0.0899609196885955\n",
            "Epoch 235, loss 0.08967757544342383\n",
            "Epoch 235, loss 0.0899119851418801\n",
            "Epoch 235, loss 0.0898501598314534\n",
            "Epoch 235, loss 0.09010847788840404\n",
            "Epoch 235, loss 0.08986449335319781\n",
            "Epoch 235, loss 0.0899091472770334\n",
            "Epoch 235, loss 0.09036603497953952\n",
            "Epoch 235, loss 0.09013941774097703\n",
            "Epoch 235, loss 0.09012660059486524\n",
            "Epoch 235, loss 0.0896720196040351\n",
            " Epoch:187 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002269299657606\n",
            "Epoch 235, loss 0.08962410275674526\n",
            "Epoch 235, loss 0.09007843712050258\n",
            "Epoch 235, loss 0.08996228283619165\n",
            "Epoch 235, loss 0.08996091936821511\n",
            "Epoch 235, loss 0.0896775753577154\n",
            "Epoch 235, loss 0.0899119850378192\n",
            "Epoch 235, loss 0.08985015955248363\n",
            "Epoch 235, loss 0.09010847788147733\n",
            "Epoch 235, loss 0.0898644931872021\n",
            "Epoch 235, loss 0.08990914684186997\n",
            "Epoch 235, loss 0.09036603447791466\n",
            "Epoch 235, loss 0.09013941784734367\n",
            "Epoch 235, loss 0.09012659988687657\n",
            "Epoch 235, loss 0.08967201953919243\n",
            " Epoch:188 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002269278097408\n",
            "Epoch 235, loss 0.08962410239917887\n",
            "Epoch 235, loss 0.09007843670735971\n",
            "Epoch 235, loss 0.08996228278862037\n",
            "Epoch 235, loss 0.0899609190478424\n",
            "Epoch 235, loss 0.0896775752720097\n",
            "Epoch 235, loss 0.08991198493376026\n",
            "Epoch 235, loss 0.08985015927351933\n",
            "Epoch 235, loss 0.09010847787455059\n",
            "Epoch 235, loss 0.08986449302120891\n",
            "Epoch 235, loss 0.08990914640671571\n",
            "Epoch 235, loss 0.09036603397629922\n",
            "Epoch 235, loss 0.09013941795370704\n",
            "Epoch 235, loss 0.09012659917890468\n",
            "Epoch 235, loss 0.08967201947435047\n",
            " Epoch:189 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002269256537561\n",
            "Epoch 235, loss 0.08962410204161966\n",
            "Epoch 235, loss 0.09007843629422554\n",
            "Epoch 235, loss 0.0899622827410493\n",
            "Epoch 235, loss 0.08996091872747738\n",
            "Epoch 235, loss 0.08967757518630678\n",
            "Epoch 235, loss 0.08991198482970328\n",
            "Epoch 235, loss 0.08985015899456048\n",
            "Epoch 235, loss 0.09010847786762385\n",
            "Epoch 235, loss 0.0898644928552182\n",
            "Epoch 235, loss 0.08990914597157065\n",
            "Epoch 235, loss 0.09036603347469314\n",
            "Epoch 235, loss 0.09013941806006714\n",
            "Epoch 235, loss 0.09012659847094961\n",
            "Epoch 235, loss 0.08967201940950922\n",
            " Epoch:190 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002269234978065\n",
            "Epoch 235, loss 0.08962410168406768\n",
            "Epoch 235, loss 0.09007843588110007\n",
            "Epoch 235, loss 0.08996228269347842\n",
            "Epoch 235, loss 0.08996091840712009\n",
            "Epoch 235, loss 0.08967757510060667\n",
            "Epoch 235, loss 0.08991198472564822\n",
            "Epoch 235, loss 0.08985015871560709\n",
            "Epoch 235, loss 0.09010847786069712\n",
            "Epoch 235, loss 0.08986449268923\n",
            "Epoch 235, loss 0.0899091455364348\n",
            "Epoch 235, loss 0.09036603297309645\n",
            "Epoch 235, loss 0.09013941816642398\n",
            "Epoch 235, loss 0.09012659776301132\n",
            "Epoch 235, loss 0.0896720193446687\n",
            " Epoch:191 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.0900226921341892\n",
            "Epoch 235, loss 0.08962410132652289\n",
            "Epoch 235, loss 0.0900784354679833\n",
            "Epoch 235, loss 0.08996228264590773\n",
            "Epoch 235, loss 0.08996091808677045\n",
            "Epoch 235, loss 0.08967757501490932\n",
            "Epoch 235, loss 0.0899119846215951\n",
            "Epoch 235, loss 0.08985015843665918\n",
            "Epoch 235, loss 0.09010847785377037\n",
            "Epoch 235, loss 0.08986449252324427\n",
            "Epoch 235, loss 0.08990914510130814\n",
            "Epoch 235, loss 0.09036603247150915\n",
            "Epoch 235, loss 0.09013941827277758\n",
            "Epoch 235, loss 0.09012659705508985\n",
            "Epoch 235, loss 0.08967201927982889\n",
            " Epoch:192 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002269191860128\n",
            "Epoch 235, loss 0.08962410096898532\n",
            "Epoch 235, loss 0.09007843505487526\n",
            "Epoch 235, loss 0.08996228259833725\n",
            "Epoch 235, loss 0.08996091776642853\n",
            "Epoch 235, loss 0.08967757492921473\n",
            "Epoch 235, loss 0.08991198451754392\n",
            "Epoch 235, loss 0.0898501581577167\n",
            "Epoch 235, loss 0.09010847784684362\n",
            "Epoch 235, loss 0.08986449235726106\n",
            "Epoch 235, loss 0.08990914466619068\n",
            "Epoch 235, loss 0.09036603196993125\n",
            "Epoch 235, loss 0.0901394183791279\n",
            "Epoch 235, loss 0.09012659634718515\n",
            "Epoch 235, loss 0.08967201921498977\n",
            " Epoch:193 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002269170301687\n",
            "Epoch 235, loss 0.08962410061145495\n",
            "Epoch 235, loss 0.0900784346417759\n",
            "Epoch 235, loss 0.08996228255076699\n",
            "Epoch 235, loss 0.08996091744609429\n",
            "Epoch 235, loss 0.08967757484352293\n",
            "Epoch 235, loss 0.0899119844134947\n",
            "Epoch 235, loss 0.08985015787877972\n",
            "Epoch 235, loss 0.09010847783991686\n",
            "Epoch 235, loss 0.08986449219128034\n",
            "Epoch 235, loss 0.0899091442310824\n",
            "Epoch 235, loss 0.09036603146836271\n",
            "Epoch 235, loss 0.09013941848547494\n",
            "Epoch 235, loss 0.09012659563929723\n",
            "Epoch 235, loss 0.08967201915015138\n",
            " Epoch:194 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002269148743598\n",
            "Epoch 235, loss 0.0896241002539318\n",
            "Epoch 235, loss 0.09007843422868525\n",
            "Epoch 235, loss 0.08996228250319689\n",
            "Epoch 235, loss 0.08996091712576779\n",
            "Epoch 235, loss 0.08967757475783387\n",
            "Epoch 235, loss 0.0899119843094474\n",
            "Epoch 235, loss 0.08985015759984817\n",
            "Epoch 235, loss 0.0901084778329901\n",
            "Epoch 235, loss 0.08986449202530214\n",
            "Epoch 235, loss 0.08990914379598333\n",
            "Epoch 235, loss 0.09036603096680358\n",
            "Epoch 235, loss 0.09013941859181875\n",
            "Epoch 235, loss 0.09012659493142613\n",
            "Epoch 235, loss 0.08967201908531372\n",
            " Epoch:195 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002269127185861\n",
            "Epoch 235, loss 0.08962409989641586\n",
            "Epoch 235, loss 0.09007843381560332\n",
            "Epoch 235, loss 0.08996228245562701\n",
            "Epoch 235, loss 0.08996091680544896\n",
            "Epoch 235, loss 0.08967757467214761\n",
            "Epoch 235, loss 0.08991198420540204\n",
            "Epoch 235, loss 0.08985015732092208\n",
            "Epoch 235, loss 0.09010847782606332\n",
            "Epoch 235, loss 0.0898644918593264\n",
            "Epoch 235, loss 0.08990914336089348\n",
            "Epoch 235, loss 0.09036603046525382\n",
            "Epoch 235, loss 0.09013941869815927\n",
            "Epoch 235, loss 0.09012659422357185\n",
            "Epoch 235, loss 0.08967201902047675\n",
            " Epoch:196 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002269105628473\n",
            "Epoch 235, loss 0.08962409953890711\n",
            "Epoch 235, loss 0.09007843340253005\n",
            "Epoch 235, loss 0.08996228240805731\n",
            "Epoch 235, loss 0.0899609164851378\n",
            "Epoch 235, loss 0.08967757458646411\n",
            "Epoch 235, loss 0.08991198410135864\n",
            "Epoch 235, loss 0.08985015704200146\n",
            "Epoch 235, loss 0.09010847781913657\n",
            "Epoch 235, loss 0.0898644916933532\n",
            "Epoch 235, loss 0.08990914292581281\n",
            "Epoch 235, loss 0.09036602996371346\n",
            "Epoch 235, loss 0.09013941880449652\n",
            "Epoch 235, loss 0.09012659351573434\n",
            "Epoch 235, loss 0.08967201895564052\n",
            " Epoch:197 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002269084071439\n",
            "Epoch 235, loss 0.0896240991814056\n",
            "Epoch 235, loss 0.09007843298946552\n",
            "Epoch 235, loss 0.08996228236048784\n",
            "Epoch 235, loss 0.08996091616483434\n",
            "Epoch 235, loss 0.0896775745007834\n",
            "Epoch 235, loss 0.08991198399731717\n",
            "Epoch 235, loss 0.0898501567630863\n",
            "Epoch 235, loss 0.09010847781220979\n",
            "Epoch 235, loss 0.08986449152738245\n",
            "Epoch 235, loss 0.08990914249074133\n",
            "Epoch 235, loss 0.09036602946218249\n",
            "Epoch 235, loss 0.09013941891083052\n",
            "Epoch 235, loss 0.09012659280791362\n",
            "Epoch 235, loss 0.08967201889080498\n",
            " Epoch:198 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002269062514758\n",
            "Epoch 235, loss 0.08962409882391124\n",
            "Epoch 235, loss 0.09007843257640971\n",
            "Epoch 235, loss 0.08996228231291854\n",
            "Epoch 235, loss 0.08996091584453861\n",
            "Epoch 235, loss 0.08967757441510545\n",
            "Epoch 235, loss 0.08991198389327763\n",
            "Epoch 235, loss 0.0898501564841766\n",
            "Epoch 235, loss 0.09010847780528301\n",
            "Epoch 235, loss 0.08986449136141422\n",
            "Epoch 235, loss 0.08990914205567904\n",
            "Epoch 235, loss 0.0903660289606609\n",
            "Epoch 235, loss 0.09013941901716127\n",
            "Epoch 235, loss 0.09012659210010968\n",
            "Epoch 235, loss 0.08967201882597016\n",
            " Epoch:199 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002269040958424\n",
            "Epoch 235, loss 0.08962409846642413\n",
            "Epoch 235, loss 0.09007843216336257\n",
            "Epoch 235, loss 0.08996228226534944\n",
            "Epoch 235, loss 0.08996091552425056\n",
            "Epoch 235, loss 0.08967757432943027\n",
            "Epoch 235, loss 0.08991198378924005\n",
            "Epoch 235, loss 0.08985015620527234\n",
            "Epoch 235, loss 0.09010847779835622\n",
            "Epoch 235, loss 0.0898644911954485\n",
            "Epoch 235, loss 0.08990914162062598\n",
            "Epoch 235, loss 0.09036602845914868\n",
            "Epoch 235, loss 0.09013941912348875\n",
            "Epoch 235, loss 0.09012659139232256\n",
            "Epoch 235, loss 0.08967201876113609\n",
            " Epoch:200 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002269019402445\n",
            "Epoch 235, loss 0.0896240981089442\n",
            "Epoch 235, loss 0.09007843175032412\n",
            "Epoch 235, loss 0.08996228221778055\n",
            "Epoch 235, loss 0.08996091520397019\n",
            "Epoch 235, loss 0.08967757424375786\n",
            "Epoch 235, loss 0.08991198368520441\n",
            "Epoch 235, loss 0.08985015592637355\n",
            "Epoch 235, loss 0.09010847779142944\n",
            "Epoch 235, loss 0.08986449102948524\n",
            "Epoch 235, loss 0.0899091411855821\n",
            "Epoch 235, loss 0.09036602795764587\n",
            "Epoch 235, loss 0.09013941922981297\n",
            "Epoch 235, loss 0.0901265906845522\n",
            "Epoch 235, loss 0.08967201869630269\n",
            " Epoch:201 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002268997846816\n",
            "Epoch 235, loss 0.0896240977514715\n",
            "Epoch 235, loss 0.0900784313372944\n",
            "Epoch 235, loss 0.08996228217021188\n",
            "Epoch 235, loss 0.08996091488369753\n",
            "Epoch 235, loss 0.08967757415808822\n",
            "Epoch 235, loss 0.0899119835811707\n",
            "Epoch 235, loss 0.08985015564748025\n",
            "Epoch 235, loss 0.09010847778450264\n",
            "Epoch 235, loss 0.08986449086352451\n",
            "Epoch 235, loss 0.08990914075054739\n",
            "Epoch 235, loss 0.09036602745615244\n",
            "Epoch 235, loss 0.0901394193361339\n",
            "Epoch 235, loss 0.09012658997679865\n",
            "Epoch 235, loss 0.08967201863147002\n",
            " Epoch:202 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002268976291539\n",
            "Epoch 235, loss 0.08962409739400601\n",
            "Epoch 235, loss 0.0900784309242734\n",
            "Epoch 235, loss 0.08996228212264337\n",
            "Epoch 235, loss 0.08996091456343255\n",
            "Epoch 235, loss 0.08967757407242136\n",
            "Epoch 235, loss 0.08991198347713893\n",
            "Epoch 235, loss 0.08985015536859237\n",
            "Epoch 235, loss 0.09010847777757584\n",
            "Epoch 235, loss 0.08986449069756627\n",
            "Epoch 235, loss 0.08990914031552191\n",
            "Epoch 235, loss 0.09036602695466837\n",
            "Epoch 235, loss 0.09013941944245159\n",
            "Epoch 235, loss 0.09012658926906188\n",
            "Epoch 235, loss 0.08967201856663808\n",
            " Epoch:203 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002268954736614\n",
            "Epoch 235, loss 0.0896240970365477\n",
            "Epoch 235, loss 0.09007843051126105\n",
            "Epoch 235, loss 0.08996228207507509\n",
            "Epoch 235, loss 0.08996091424317527\n",
            "Epoch 235, loss 0.08967757398675727\n",
            "Epoch 235, loss 0.0899119833731091\n",
            "Epoch 235, loss 0.08985015508970998\n",
            "Epoch 235, loss 0.09010847777064905\n",
            "Epoch 235, loss 0.08986449053161052\n",
            "Epoch 235, loss 0.08990913988050561\n",
            "Epoch 235, loss 0.0903660264531937\n",
            "Epoch 235, loss 0.090139419548766\n",
            "Epoch 235, loss 0.0901265885613419\n",
            "Epoch 235, loss 0.08967201850180684\n",
            " Epoch:204 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002268933182041\n",
            "Epoch 235, loss 0.08962409667909661\n",
            "Epoch 235, loss 0.09007843009825742\n",
            "Epoch 235, loss 0.08996228202750697\n",
            "Epoch 235, loss 0.08996091392292568\n",
            "Epoch 235, loss 0.08967757390109594\n",
            "Epoch 235, loss 0.0899119832690812\n",
            "Epoch 235, loss 0.089850154810833\n",
            "Epoch 235, loss 0.09010847776372223\n",
            "Epoch 235, loss 0.08986449036565727\n",
            "Epoch 235, loss 0.0899091394454985\n",
            "Epoch 235, loss 0.09036602595172843\n",
            "Epoch 235, loss 0.09013941965507717\n",
            "Epoch 235, loss 0.09012658785363872\n",
            "Epoch 235, loss 0.08967201843697631\n",
            " Epoch:205 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002268911627817\n",
            "Epoch 235, loss 0.08962409632165272\n",
            "Epoch 235, loss 0.0900784296852625\n",
            "Epoch 235, loss 0.08996228197993908\n",
            "Epoch 235, loss 0.0899609136026838\n",
            "Epoch 235, loss 0.0896775738154374\n",
            "Epoch 235, loss 0.08991198316505526\n",
            "Epoch 235, loss 0.0898501545319615\n",
            "Epoch 235, loss 0.09010847775679541\n",
            "Epoch 235, loss 0.08986449019970652\n",
            "Epoch 235, loss 0.0899091390105006\n",
            "Epoch 235, loss 0.09036602545027253\n",
            "Epoch 235, loss 0.09013941976138506\n",
            "Epoch 235, loss 0.09012658714595233\n",
            "Epoch 235, loss 0.08967201837214651\n",
            " Epoch:206 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002268890073947\n",
            "Epoch 235, loss 0.08962409596421606\n",
            "Epoch 235, loss 0.09007842927227629\n",
            "Epoch 235, loss 0.0899622819323714\n",
            "Epoch 235, loss 0.0899609132824496\n",
            "Epoch 235, loss 0.08967757372978162\n",
            "Epoch 235, loss 0.08991198306103126\n",
            "Epoch 235, loss 0.08985015425309548\n",
            "Epoch 235, loss 0.0901084777498686\n",
            "Epoch 235, loss 0.08986449003375827\n",
            "Epoch 235, loss 0.08990913857551189\n",
            "Epoch 235, loss 0.09036602494882603\n",
            "Epoch 235, loss 0.0901394198676897\n",
            "Epoch 235, loss 0.09012658643828274\n",
            "Epoch 235, loss 0.08967201830731739\n",
            " Epoch:207 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002268868520429\n",
            "Epoch 235, loss 0.08962409560678657\n",
            "Epoch 235, loss 0.09007842885929876\n",
            "Epoch 235, loss 0.08996228188480389\n",
            "Epoch 235, loss 0.08996091296222308\n",
            "Epoch 235, loss 0.08967757364412862\n",
            "Epoch 235, loss 0.08991198295700918\n",
            "Epoch 235, loss 0.0898501539742349\n",
            "Epoch 235, loss 0.09010847774294178\n",
            "Epoch 235, loss 0.08986448986781251\n",
            "Epoch 235, loss 0.08990913814053236\n",
            "Epoch 235, loss 0.0903660244473889\n",
            "Epoch 235, loss 0.09013941997399107\n",
            "Epoch 235, loss 0.09012658573062993\n",
            "Epoch 235, loss 0.08967201824248902\n",
            " Epoch:208 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002268846967261\n",
            "Epoch 235, loss 0.08962409524936431\n",
            "Epoch 235, loss 0.09007842844632993\n",
            "Epoch 235, loss 0.08996228183723659\n",
            "Epoch 235, loss 0.08996091264200427\n",
            "Epoch 235, loss 0.08967757355847839\n",
            "Epoch 235, loss 0.08991198285298907\n",
            "Epoch 235, loss 0.0898501536953798\n",
            "Epoch 235, loss 0.09010847773601495\n",
            "Epoch 235, loss 0.08986448970186925\n",
            "Epoch 235, loss 0.08990913770556204\n",
            "Epoch 235, loss 0.09036602394596116\n",
            "Epoch 235, loss 0.09013942008028919\n",
            "Epoch 235, loss 0.09012658502299391\n",
            "Epoch 235, loss 0.08967201817766135\n",
            " Epoch:209 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002268825414443\n",
            "Epoch 235, loss 0.08962409489194925\n",
            "Epoch 235, loss 0.09007842803336982\n",
            "Epoch 235, loss 0.08996228178966947\n",
            "Epoch 235, loss 0.08996091232179315\n",
            "Epoch 235, loss 0.08967757347283092\n",
            "Epoch 235, loss 0.08991198274897087\n",
            "Epoch 235, loss 0.08985015341653013\n",
            "Epoch 235, loss 0.09010847772908812\n",
            "Epoch 235, loss 0.08986448953592847\n",
            "Epoch 235, loss 0.08990913727060092\n",
            "Epoch 235, loss 0.09036602344454281\n",
            "Epoch 235, loss 0.09013942018658402\n",
            "Epoch 235, loss 0.09012658431537467\n",
            "Epoch 235, loss 0.08967201811283443\n",
            " Epoch:210 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002268803861978\n",
            "Epoch 235, loss 0.08962409453454138\n",
            "Epoch 235, loss 0.09007842762041843\n",
            "Epoch 235, loss 0.08996228174210259\n",
            "Epoch 235, loss 0.08996091200158972\n",
            "Epoch 235, loss 0.08967757338718622\n",
            "Epoch 235, loss 0.08991198264495463\n",
            "Epoch 235, loss 0.08985015313768593\n",
            "Epoch 235, loss 0.09010847772216127\n",
            "Epoch 235, loss 0.08986448936999018\n",
            "Epoch 235, loss 0.08990913683564897\n",
            "Epoch 235, loss 0.09036602294313383\n",
            "Epoch 235, loss 0.09013942029287561\n",
            "Epoch 235, loss 0.09012658360777222\n",
            "Epoch 235, loss 0.08967201804800817\n",
            " Epoch:211 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002268782309863\n",
            "Epoch 235, loss 0.08962409417714072\n",
            "Epoch 235, loss 0.09007842720747569\n",
            "Epoch 235, loss 0.08996228169453588\n",
            "Epoch 235, loss 0.08996091168139399\n",
            "Epoch 235, loss 0.0896775733015443\n",
            "Epoch 235, loss 0.08991198254094032\n",
            "Epoch 235, loss 0.0898501528588472\n",
            "Epoch 235, loss 0.09010847771523442\n",
            "Epoch 235, loss 0.0898644892040544\n",
            "Epoch 235, loss 0.08990913640070623\n",
            "Epoch 235, loss 0.09036602244173426\n",
            "Epoch 235, loss 0.09013942039916395\n",
            "Epoch 235, loss 0.09012658290018656\n",
            "Epoch 235, loss 0.08967201798318265\n",
            " Epoch:212 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002268760758102\n",
            "Epoch 235, loss 0.0896240938197473\n",
            "Epoch 235, loss 0.09007842679454167\n",
            "Epoch 235, loss 0.08996228164696937\n",
            "Epoch 235, loss 0.08996091136120594\n",
            "Epoch 235, loss 0.08967757321590515\n",
            "Epoch 235, loss 0.08991198243692797\n",
            "Epoch 235, loss 0.08985015258001391\n",
            "Epoch 235, loss 0.09010847770830759\n",
            "Epoch 235, loss 0.08986448903812114\n",
            "Epoch 235, loss 0.08990913596577269\n",
            "Epoch 235, loss 0.09036602194034404\n",
            "Epoch 235, loss 0.09013942050544901\n",
            "Epoch 235, loss 0.09012658219261768\n",
            "Epoch 235, loss 0.08967201791835784\n",
            " Epoch:213 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002268739206691\n",
            "Epoch 235, loss 0.08962409346236104\n",
            "Epoch 235, loss 0.09007842638161637\n",
            "Epoch 235, loss 0.08996228159940305\n",
            "Epoch 235, loss 0.08996091104102558\n",
            "Epoch 235, loss 0.08967757313026878\n",
            "Epoch 235, loss 0.08991198233291754\n",
            "Epoch 235, loss 0.08985015230118609\n",
            "Epoch 235, loss 0.09010847770138072\n",
            "Epoch 235, loss 0.08986448887219037\n",
            "Epoch 235, loss 0.08990913553084832\n",
            "Epoch 235, loss 0.09036602143896322\n",
            "Epoch 235, loss 0.09013942061173082\n",
            "Epoch 235, loss 0.0901265814850656\n",
            "Epoch 235, loss 0.08967201785353376\n",
            " Epoch:214 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002268717655633\n",
            "Epoch 235, loss 0.08962409310498201\n",
            "Epoch 235, loss 0.09007842596869974\n",
            "Epoch 235, loss 0.08996228155183697\n",
            "Epoch 235, loss 0.08996091072085291\n",
            "Epoch 235, loss 0.08967757304463517\n",
            "Epoch 235, loss 0.08991198222890903\n",
            "Epoch 235, loss 0.08985015202236371\n",
            "Epoch 235, loss 0.09010847769445388\n",
            "Epoch 235, loss 0.08986448870626207\n",
            "Epoch 235, loss 0.08990913509593315\n",
            "Epoch 235, loss 0.09036602093759177\n",
            "Epoch 235, loss 0.09013942071800936\n",
            "Epoch 235, loss 0.09012658077753029\n",
            "Epoch 235, loss 0.0896720177887104\n",
            " Epoch:215 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002268696104923\n",
            "Epoch 235, loss 0.08962409274761016\n",
            "Epoch 235, loss 0.09007842555579179\n",
            "Epoch 235, loss 0.08996228150427105\n",
            "Epoch 235, loss 0.08996091040068795\n",
            "Epoch 235, loss 0.08967757295900433\n",
            "Epoch 235, loss 0.08991198212490252\n",
            "Epoch 235, loss 0.0898501517435468\n",
            "Epoch 235, loss 0.09010847768752701\n",
            "Epoch 235, loss 0.08986448854033627\n",
            "Epoch 235, loss 0.08990913466102719\n",
            "Epoch 235, loss 0.09036602043622971\n",
            "Epoch 235, loss 0.09013942082428464\n",
            "Epoch 235, loss 0.09012658007001176\n",
            "Epoch 235, loss 0.0896720177238877\n",
            " Epoch:216 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002268674554569\n",
            "Epoch 235, loss 0.08962409239024553\n",
            "Epoch 235, loss 0.09007842514289259\n",
            "Epoch 235, loss 0.08996228145670533\n",
            "Epoch 235, loss 0.08996091008053067\n",
            "Epoch 235, loss 0.08967757287337627\n",
            "Epoch 235, loss 0.0899119820208979\n",
            "Epoch 235, loss 0.08985015146473535\n",
            "Epoch 235, loss 0.09010847768060014\n",
            "Epoch 235, loss 0.08986448837441299\n",
            "Epoch 235, loss 0.08990913422613041\n",
            "Epoch 235, loss 0.09036601993487704\n",
            "Epoch 235, loss 0.09013942093055664\n",
            "Epoch 235, loss 0.09012657936251003\n",
            "Epoch 235, loss 0.08967201765906577\n",
            " Epoch:217 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002268653004561\n",
            "Epoch 235, loss 0.08962409203288811\n",
            "Epoch 235, loss 0.09007842473000205\n",
            "Epoch 235, loss 0.08996228140913981\n",
            "Epoch 235, loss 0.08996090976038107\n",
            "Epoch 235, loss 0.08967757278775096\n",
            "Epoch 235, loss 0.08991198191689524\n",
            "Epoch 235, loss 0.08985015118592934\n",
            "Epoch 235, loss 0.09010847767367328\n",
            "Epoch 235, loss 0.08986448820849219\n",
            "Epoch 235, loss 0.08990913379124284\n",
            "Epoch 235, loss 0.09036601943353374\n",
            "Epoch 235, loss 0.0901394210368254\n",
            "Epoch 235, loss 0.09012657865502507\n",
            "Epoch 235, loss 0.08967201759424452\n",
            " Epoch:218 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.09002268631454909\n",
            "Epoch 235, loss 0.08962409167553789\n",
            "Epoch 235, loss 0.09007842431712024\n",
            "Epoch 235, loss 0.08996228136157451\n",
            "Epoch 235, loss 0.08996090944023916\n",
            "Epoch 235, loss 0.08967757270212844\n",
            "Epoch 235, loss 0.08991198181289452\n",
            "Epoch 235, loss 0.0898501509071288\n",
            "Epoch 235, loss 0.09010847766674639\n",
            "Epoch 235, loss 0.08986448804257388\n",
            "Epoch 235, loss 0.08990913335636444\n",
            "Epoch 235, loss 0.09036601893219982\n",
            "Epoch 235, loss 0.09013942114309088\n",
            "Epoch 235, loss 0.09012657794755692\n",
            "Epoch 235, loss 0.08967201752942403\n",
            " Epoch:219 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.09002268609905606\n",
            "Epoch 235, loss 0.08962409131819489\n",
            "Epoch 235, loss 0.09007842390424711\n",
            "Epoch 235, loss 0.08996228131400939\n",
            "Epoch 235, loss 0.08996090912010496\n",
            "Epoch 235, loss 0.08967757261650869\n",
            "Epoch 235, loss 0.08991198170889574\n",
            "Epoch 235, loss 0.08985015062833372\n",
            "Epoch 235, loss 0.09010847765981951\n",
            "Epoch 235, loss 0.08986448787665807\n",
            "Epoch 235, loss 0.08990913292149523\n",
            "Epoch 235, loss 0.0903660184308753\n",
            "Epoch 235, loss 0.09013942124935312\n",
            "Epoch 235, loss 0.09012657724010556\n",
            "Epoch 235, loss 0.08967201746460421\n",
            " Epoch:220 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002268588356654\n",
            "Epoch 235, loss 0.08962409096085906\n",
            "Epoch 235, loss 0.09007842349138266\n",
            "Epoch 235, loss 0.08996228126644448\n",
            "Epoch 235, loss 0.08996090879997845\n",
            "Epoch 235, loss 0.08967757253089169\n",
            "Epoch 235, loss 0.08991198160489891\n",
            "Epoch 235, loss 0.0898501503495441\n",
            "Epoch 235, loss 0.09010847765289262\n",
            "Epoch 235, loss 0.08986448771074476\n",
            "Epoch 235, loss 0.08990913248663523\n",
            "Epoch 235, loss 0.09036601792956014\n",
            "Epoch 235, loss 0.09013942135561208\n",
            "Epoch 235, loss 0.09012657653267095\n",
            "Epoch 235, loss 0.08967201739978511\n",
            " Epoch:221 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002268566808055\n",
            "Epoch 235, loss 0.08962409060353045\n",
            "Epoch 235, loss 0.09007842307852694\n",
            "Epoch 235, loss 0.08996228121887975\n",
            "Epoch 235, loss 0.0899609084798596\n",
            "Epoch 235, loss 0.08967757244527748\n",
            "Epoch 235, loss 0.08991198150090399\n",
            "Epoch 235, loss 0.08985015007075993\n",
            "Epoch 235, loss 0.09010847764596572\n",
            "Epoch 235, loss 0.08986448754483395\n",
            "Epoch 235, loss 0.08990913205178439\n",
            "Epoch 235, loss 0.09036601742825437\n",
            "Epoch 235, loss 0.09013942146186779\n",
            "Epoch 235, loss 0.09012657582525312\n",
            "Epoch 235, loss 0.08967201733496674\n",
            " Epoch:222 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.09002268545259806\n",
            "Epoch 235, loss 0.08962409024620903\n",
            "Epoch 235, loss 0.09007842266567989\n",
            "Epoch 235, loss 0.08996228117131524\n",
            "Epoch 235, loss 0.08996090815974847\n",
            "Epoch 235, loss 0.08967757235966603\n",
            "Epoch 235, loss 0.08991198139691102\n",
            "Epoch 235, loss 0.08985014979198121\n",
            "Epoch 235, loss 0.09010847763903881\n",
            "Epoch 235, loss 0.08986448737892563\n",
            "Epoch 235, loss 0.08990913161694278\n",
            "Epoch 235, loss 0.09036601692695799\n",
            "Epoch 235, loss 0.09013942156812026\n",
            "Epoch 235, loss 0.09012657511785209\n",
            "Epoch 235, loss 0.08967201727014908\n",
            " Epoch:223 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.0900226852371191\n",
            "Epoch 235, loss 0.08962408988889484\n",
            "Epoch 235, loss 0.09007842225284154\n",
            "Epoch 235, loss 0.08996228112375092\n",
            "Epoch 235, loss 0.08996090783964501\n",
            "Epoch 235, loss 0.08967757227405736\n",
            "Epoch 235, loss 0.08991198129292\n",
            "Epoch 235, loss 0.08985014951320795\n",
            "Epoch 235, loss 0.09010847763211191\n",
            "Epoch 235, loss 0.0898644872130198\n",
            "Epoch 235, loss 0.08990913118211033\n",
            "Epoch 235, loss 0.09036601642567098\n",
            "Epoch 235, loss 0.09013942167436945\n",
            "Epoch 235, loss 0.09012657441046786\n",
            "Epoch 235, loss 0.08967201720533216\n",
            " Epoch:224 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:7.571 -> Test-Accuracy:0.479\n",
            "Epoch 235, loss 0.09002268502164362\n",
            "Epoch 235, loss 0.08962408953158782\n",
            "Epoch 235, loss 0.09007842184001191\n",
            "Epoch 235, loss 0.0899622810761868\n",
            "Epoch 235, loss 0.08996090751954924\n",
            "Epoch 235, loss 0.08967757218845145\n",
            "Epoch 235, loss 0.08991198118893091\n",
            "Epoch 235, loss 0.08985014923444015\n",
            "Epoch 235, loss 0.09010847762518501\n",
            "Epoch 235, loss 0.08986448704711648\n",
            "Epoch 235, loss 0.08990913074728708\n",
            "Epoch 235, loss 0.09036601592439335\n",
            "Epoch 235, loss 0.09013942178061538\n",
            "Epoch 235, loss 0.09012657370310037\n",
            "Epoch 235, loss 0.08967201714051591\n",
            " Epoch:225 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:9.085 -> Test-Accuracy:0.5748\n",
            "Epoch 235, loss 0.09002268480617168\n",
            "Epoch 235, loss 0.08962408917428802\n",
            "Epoch 235, loss 0.09007842142719096\n",
            "Epoch 235, loss 0.08996228102862289\n",
            "Epoch 235, loss 0.08996090719946118\n",
            "Epoch 235, loss 0.0896775721028483\n",
            "Epoch 235, loss 0.08991198108494378\n",
            "Epoch 235, loss 0.0898501489556778\n",
            "Epoch 235, loss 0.09010847761825809\n",
            "Epoch 235, loss 0.08986448688121565\n",
            "Epoch 235, loss 0.08990913031247302\n",
            "Epoch 235, loss 0.09036601542312513\n",
            "Epoch 235, loss 0.09013942188685804\n",
            "Epoch 235, loss 0.09012657299574969\n",
            "Epoch 235, loss 0.0896720170757004\n",
            " Epoch:226 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:10.60 -> Test-Accuracy:0.6706\n",
            "Epoch 235, loss 0.09002268459070324\n",
            "Epoch 235, loss 0.08962408881699543\n",
            "Epoch 235, loss 0.09007842101437871\n",
            "Epoch 235, loss 0.08996228098105916\n",
            "Epoch 235, loss 0.08996090687938077\n",
            "Epoch 235, loss 0.08967757201724794\n",
            "Epoch 235, loss 0.08991198098095855\n",
            "Epoch 235, loss 0.0898501486769209\n",
            "Epoch 235, loss 0.09010847761133119\n",
            "Epoch 235, loss 0.0898644867153173\n",
            "Epoch 235, loss 0.08990912987766816\n",
            "Epoch 235, loss 0.09036601492186623\n",
            "Epoch 235, loss 0.09013942199309746\n",
            "Epoch 235, loss 0.09012657228841578\n",
            "Epoch 235, loss 0.08967201701088559\n",
            " Epoch:227 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:12.11 -> Test-Accuracy:0.7664\n",
            "Epoch 235, loss 0.09002268437523833\n",
            "Epoch 235, loss 0.08962408845971005\n",
            "Epoch 235, loss 0.09007842060157516\n",
            "Epoch 235, loss 0.08996228093349563\n",
            "Epoch 235, loss 0.08996090655930808\n",
            "Epoch 235, loss 0.08967757193165034\n",
            "Epoch 235, loss 0.0899119808769753\n",
            "Epoch 235, loss 0.08985014839816947\n",
            "Epoch 235, loss 0.09010847760440426\n",
            "Epoch 235, loss 0.08986448654942147\n",
            "Epoch 235, loss 0.0899091294428725\n",
            "Epoch 235, loss 0.09036601442061676\n",
            "Epoch 235, loss 0.09013942209933361\n",
            "Epoch 235, loss 0.09012657158109866\n",
            "Epoch 235, loss 0.08967201694607149\n",
            " Epoch:228 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:13.62 -> Test-Accuracy:0.8622\n",
            "Epoch 235, loss 0.0900226841597769\n",
            "Epoch 235, loss 0.08962408810243186\n",
            "Epoch 235, loss 0.09007842018878029\n",
            "Epoch 235, loss 0.08996228088593232\n",
            "Epoch 235, loss 0.08996090623924306\n",
            "Epoch 235, loss 0.08967757184605551\n",
            "Epoch 235, loss 0.08991198077299396\n",
            "Epoch 235, loss 0.0898501481194235\n",
            "Epoch 235, loss 0.09010847759747732\n",
            "Epoch 235, loss 0.0898644863835281\n",
            "Epoch 235, loss 0.08990912900808601\n",
            "Epoch 235, loss 0.09036601391937665\n",
            "Epoch 235, loss 0.0901394222055665\n",
            "Epoch 235, loss 0.0901265708737983\n",
            "Epoch 235, loss 0.08967201688125812\n",
            " Epoch:229 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:15.14 -> Test-Accuracy:0.958\n",
            "Epoch 235, loss 0.090022683944319\n",
            "Epoch 235, loss 0.08962408774516087\n",
            "Epoch 235, loss 0.09007841977599414\n",
            "Epoch 235, loss 0.08996228083836919\n",
            "Epoch 235, loss 0.08996090591918575\n",
            "Epoch 235, loss 0.08967757176046345\n",
            "Epoch 235, loss 0.08991198066901458\n",
            "Epoch 235, loss 0.08985014784068297\n",
            "Epoch 235, loss 0.09010847759055038\n",
            "Epoch 235, loss 0.08986448621763728\n",
            "Epoch 235, loss 0.08990912857330871\n",
            "Epoch 235, loss 0.09036601341814593\n",
            "Epoch 235, loss 0.09013942231179611\n",
            "Epoch 235, loss 0.09012657016651474\n",
            "Epoch 235, loss 0.08967201681644546\n",
            " Epoch:230 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n",
            "Epoch 235, loss 0.09002268372886464\n",
            "Epoch 235, loss 0.08962408738789707\n",
            "Epoch 235, loss 0.09007841936321667\n",
            "Epoch 235, loss 0.08996228079080627\n",
            "Epoch 235, loss 0.08996090559913612\n",
            "Epoch 235, loss 0.08967757167487417\n",
            "Epoch 235, loss 0.08991198056503713\n",
            "Epoch 235, loss 0.0898501475619479\n",
            "Epoch 235, loss 0.09010847758362343\n",
            "Epoch 235, loss 0.0898644860517489\n",
            "Epoch 235, loss 0.0899091281385406\n",
            "Epoch 235, loss 0.09036601291692459\n",
            "Epoch 235, loss 0.0901394224180225\n",
            "Epoch 235, loss 0.09012656945924793\n",
            "Epoch 235, loss 0.08967201675163351\n",
            " Epoch:231 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:3.028 -> Test-Accuracy:0.1916\n",
            "Epoch 235, loss 0.09002268351341378\n",
            "Epoch 235, loss 0.08962408703064048\n",
            "Epoch 235, loss 0.0900784189504479\n",
            "Epoch 235, loss 0.08996228074324356\n",
            "Epoch 235, loss 0.08996090527909416\n",
            "Epoch 235, loss 0.08967757158928766\n",
            "Epoch 235, loss 0.08991198046106161\n",
            "Epoch 235, loss 0.08985014728321827\n",
            "Epoch 235, loss 0.09010847757669649\n",
            "Epoch 235, loss 0.08986448588586304\n",
            "Epoch 235, loss 0.08990912770378168\n",
            "Epoch 235, loss 0.0903660124157126\n",
            "Epoch 235, loss 0.09013942252424559\n",
            "Epoch 235, loss 0.09012656875199794\n",
            "Epoch 235, loss 0.08967201668682227\n",
            " Epoch:232 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:4.542 -> Test-Accuracy:0.2874\n",
            "Epoch 235, loss 0.0900226832979664\n",
            "Epoch 235, loss 0.0896240866733911\n",
            "Epoch 235, loss 0.0900784185376878\n",
            "Epoch 235, loss 0.08996228069568103\n",
            "Epoch 235, loss 0.08996090495905991\n",
            "Epoch 235, loss 0.0896775715037039\n",
            "Epoch 235, loss 0.08991198035708806\n",
            "Epoch 235, loss 0.08985014700449412\n",
            "Epoch 235, loss 0.09010847756976954\n",
            "Epoch 235, loss 0.0898644857199797\n",
            "Epoch 235, loss 0.08990912726903195\n",
            "Epoch 235, loss 0.09036601191451002\n",
            "Epoch 235, loss 0.09013942263046544\n",
            "Epoch 235, loss 0.09012656804476471\n",
            "Epoch 235, loss 0.08967201662201177\n",
            " Epoch:233 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:6.057 -> Test-Accuracy:0.3832\n",
            "Epoch 235, loss 0.09002268308252255\n",
            "Epoch 235, loss 0.08962408631614892\n",
            "Epoch 235, loss 0.09007841812493642\n",
            "Epoch 235, loss 0.0899622806481187\n",
            "Epoch 235, loss 0.08996090463903335\n",
            "Epoch 235, loss 0.08967757141812291\n",
            "Epoch 235, loss 0.08991198025311643\n",
            "Epoch 235, loss 0.08985014672577542\n",
            "Epoch 235, loss 0.0901084775628426\n",
            "Epoch 235, loss 0.08986448555409883\n",
            "Epoch 235, loss 0.08990912683429142\n",
            "Epoch 235, loss 0.09036601141331682\n",
            "Epoch 235, loss 0.09013942273668203\n",
            "Epoch 235, loss 0.09012656733754823\n",
            "Epoch 235, loss 0.08967201655720197\n",
            " Epoch:234 Training-Error:0.863-> Training-Accuracy:0.114, Test-Error:1.514 -> Test-Accuracy:0.0958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "9DAoiI72r_YH",
        "outputId": "17e896e1-9dab-4e93-d4c7-5960b1abce78"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model(test_digits)\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(test_labels,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moSFmeTvUFpU"
      },
      "source": [
        "# **Part 2. MNIST Keras Classifier**\n",
        "\n",
        "Accuracy without Data Augmentation :\n",
        "\n",
        "440/440 - 256s - loss: 0.2352 - accuracy: 0.9246 - val_loss: 0.0932 - val_accuracy: 0.9719\n",
        "\n",
        "Accuracy with Data Augmentation :\n",
        "\n",
        "439/439 - 255s - loss: 0.1737 - accuracy: 0.9475 - val_loss: 0.0776 - val_accuracy: 0.9802"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWssaT6ZUEUd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "# convert to one-hot-encoding\n",
        "from keras.utils.np_utils import to_categorical \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "sns.set(style='white', context='notebook', palette='deep')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5eRNnCCUJ4w"
      },
      "source": [
        "# Load the data\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/cmpe-258-Deep Learning/mnist/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/cmpe-258-Deep Learning/mnist/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWKcWdX3e4Gj"
      },
      "source": [
        "Y_train = train['label']\n",
        "\n",
        "# Drop the \"label\" column\n",
        "X_train = train.drop(labels = ['label'],axis = 1)\n",
        "\n",
        "# Free memory space\n",
        "del train "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLAZKnj3fGKi"
      },
      "source": [
        "# Normalize the dataset\n",
        "X_train = X_train / 255.0\n",
        "test = test / 255.0\n",
        "\n",
        "#Reshape image size into 3Dimension (h=28px, w=28px, canal = 1)\n",
        "X_train = X_train.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)\n",
        "\n",
        "# Hot encoding the labels (ex: 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
        "Y_train = to_categorical(Y_train, num_classes=10)\n",
        "\n",
        "# Set the random seed\n",
        "random_seed = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mykSHQzifjKb"
      },
      "source": [
        "# Split the train and the validation set for the fitting of model\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6CZvnjwfo5x"
      },
      "source": [
        "# Set the Keras CNN model -> [[Conv2D->relu] * 2 -> MaxPool2D -> Dropout] * 2 -> Flatten -> Dense -> Dropout -> Out\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation = 'relu', input_shape = (28,28,1)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size = (2,2), strides = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ldgh8kYf7js"
      },
      "source": [
        "# Define the optimizer\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbDob2r6gAUB"
      },
      "source": [
        "# Compile the mode\n",
        "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw1FTcyWgDb8"
      },
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V29NRzDUgKwT"
      },
      "source": [
        "# Turn epochs to 30 to get 0.9967 accuracy\n",
        "epochs = 1 \n",
        "batch_size = 86"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLPt6cMUqLjn"
      },
      "source": [
        "### **Without Data Augmentation **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy7_gBgLgQh6",
        "outputId": "f30e1422-9d21-46dc-9196-5a70fa84bcf0"
      },
      "source": [
        "# Without data augmentation i obtained an accuracy of 0.98114\n",
        "NN = model.fit(X_train, Y_train, batch_size = batch_size, epochs=epochs, validation_data = (X_val, Y_val), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "440/440 - 256s - loss: 0.2352 - accuracy: 0.9246 - val_loss: 0.0932 - val_accuracy: 0.9719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMuygcGXgvCi"
      },
      "source": [
        "# This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`.\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='MNIST Confusion Matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment='center',color='white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True MNIST Label')\n",
        "    plt.xlabel('MNIST Predicted Label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPEo-Ls9ylXs"
      },
      "source": [
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(X_val)\n",
        "\n",
        "# Convert predictions classes to one hot vectors encoded\n",
        "Y_pred_classes = np.argmax(Y_pred, axis = 1)\n",
        "\n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(Y_val,axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "wARmm34AzVb2",
        "outputId": "68e33773-4793-40cf-b763-127061b7790e"
      },
      "source": [
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "\n",
        "# plot the confusion matrix, applying normalization the value in confusion matrix is converted to float.\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jir1vahyqSrY"
      },
      "source": [
        "### **With Data Augmentation ** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-lNprEKil-T"
      },
      "source": [
        "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
        "datagen = ImageDataGenerator( featurewise_center = False, # set input mean to 0 over the dataset\n",
        "        samplewise_center = False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization = False, # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization = False, # divide input by its std\n",
        "        zca_whitening = False, # apply ZCA whitening\n",
        "        rotation_range = 10, # randomly rotate images in the range (degress, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image\n",
        "        width_shift_range = 0.1, # randomly shift images horizontally (fraction of total width) \n",
        "        height_shift_range = 0.1, # randomly shift images vertically (fraction of total height\n",
        "        horizontal_flip = False, # randomly flip images\n",
        "        vertical_flip = False) # randomly flip images\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI6aAr2BgbNa",
        "outputId": "b8a457d3-cc73-488a-b749-da4c69940cd3"
      },
      "source": [
        "# Fit the model\n",
        "nn = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size), epochs=epochs, validation_data = (X_val,Y_val),\n",
        "                        verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size, callbacks=[learning_rate_reduction])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "439/439 - 255s - loss: 0.1737 - accuracy: 0.9475 - val_loss: 0.0776 - val_accuracy: 0.9802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ldEwt6U25mO"
      },
      "source": [
        "# This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`.\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='MNIST Confusion Matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment='center',color='white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True MNIST Label')\n",
        "    plt.xlabel('MNIST Predicted Label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7-MbTey3CLr"
      },
      "source": [
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(X_val)\n",
        "\n",
        "# Convert predictions classes to one hot vectors encoded\n",
        "Y_pred_classes = np.argmax(Y_pred, axis = 1)\n",
        "\n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(Y_val,axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "XKJNMGXF3Fsj",
        "outputId": "28f735fc-a339-40ab-d267-c076b8d6a3b2"
      },
      "source": [
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "\n",
        "# plot the confusion matrix, applying normalization the value in confusion matrix is converted to float.\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAElCAYAAACLYAvwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxMVxvHvzMjCRFkkU2IqL21i10pUdSShBYpoooqSnWhtLbY91prb7Vv7dS+NJairWoFsa+1BBGJJIJE1pl5/0gzRJJZMnMnM3G+/dxP3TnnPueZOzNPzrnnnOcnU6vVagQCgUCgN/KCdkAgEAisDRE4BQKBwEBE4BQIBAIDEYFTIBAIDEQEToFAIDAQETgFAoHAQETgFJiMdevW0bRpU+rWrcujR4/ybadu3brcvXvXhJ6Zn507d9KvX7+CdkMgFWqBSWjVqpX6jTfeUMfFxWV7PSAgQF2lShX13bt31Wq1Wj1q1Ch1lSpV1GfPntXUuX37trpKlSqa8969e6s3bdqkOV+6dKm6VatW6jp16qjffPNN9fDhw9VqtVrdoUMHdZ06ddR16tRRV6tWTV2jRg3N+dKlS3P18+bNm+phw4apGzZsqK5Xr566U6dO6h9++EGdkZFh1PtPS0tT16xZU3358mWj7EiJvp+RNu7evauuUqWKOj09XSo3BVaA6HGaEC8vL/bs2aM5v3r1KsnJyTnqOTo6Mn/+fL1sbtu2jR07dvDjjz8SHh7OL7/8QpMmTQDYs2cP4eHhhIeH4+vry/jx4zXngwYNymHrzp07dO/eHU9PT3bt2sWpU6dYsGABFy5cICkpKZ/vOpO4uDhSU1OpVKmSUXakRt/PyBgyMjJMak9geYjAaUICAgLYvn275nz79u0EBgbmqBcYGMjVq1c5ceKETpvnz5+nefPmeHt7A+Dq6kqPHj3y5d/ChQupW7cuX3/9NW5ubgC89tprzJ07l5IlSwJw6NAhOnbsiK+vL8HBwdy4cUNzfevWrfn+++/p3Lkz9evX57PPPiM1NZVbt27Rvn17ABo0aECfPn24d+8eVatWzRZEgoOD2bx5MwARERH07t2b+vXr06hRIz777DNNvapVqxIREQHA06dP+eqrr2jcuDGtWrViyZIlqFQqALZu3cr777/PzJkzadCgAa1bt+bo0aNa74E+n9GRI0cIDAykXr16tGzZkkWLFmnKevfurXmfdevWJTw8nK1btxIUFMS0adNo1KgRixYt0vgGcPr0aRo1akRUVBQAV65coUGDBtnurcC6EIHThNSpU4fExERu3LiBUqlkz549+Pv756hXtGhRPv74Y+bNm6fTZu3atdmxYwerVq3i/PnzKJXKfPt3/Phx2rVrl2f5rVu3+PLLL/nmm284fvw4LVq0YNCgQaSlpWnq7Nu3j1WrVnHo0CGuXr3K1q1bqVChArt37wYgLCyM//3vfzp9WbBgAc2aNSMsLIzff/9dE5BeZvLkyTx9+pSDBw/y888/s2PHDn755RdN+blz56hQoQJ///03AwYMYMyYMai17CLW5zMqVqwYM2fO5OTJkyxfvpz169dz8OBBANasWaN5n+Hh4dStW1fjR7ly5Th27BiDBw/OZq9evXoEBQUxatQoUlJSGDlyJMOHD6dixYo675PAMhGB08Rk9WiOHTtGxYoVcXd3z7VeUFAQUVFRevWQxo4dy59//klwcDBNmzZlxYoV+fItISEBV1fXPMv37t1Ly5YtadasGTY2NvTv35+UlBTCw8M1dYKDg3F3d8fR0ZFWrVpx+fLlfPlSpEgR7t+/T0xMDHZ2dvj6+uaoo1Qq2bt3L19++SUODg6ULVuWDz/8kJ07d2rqlClThu7du6NQKOjSpQsPHz4kNjZWa9u6PqNGjRpRtWpV5HI51apVo2PHjjpHB25ubgQHB1OkSBGKFi2ao3zo0KEkJibSrVs33Nzc6NWrl1Z7AstGBE4TExAQwO7du9m2bRsBAQF51rO1tWXIkCEsWLBAp01/f39+/PFHwsLCCAkJYeHChfzxxx8G++bo6MjDhw/zLI+JiaFMmTKac7lcjqenJ9HR0ZrXXgy8xYoV49mzZwb7ATBy5EjUajXvvfceHTt2ZMuWLTnqPHr0iPT09Gw+lSlTJps/pUuXzuYPoNMnXZ/R2bNnCQ4OpnHjxtSvX58NGzboXCXg4eGhtdzGxoYuXbpw7do1+vXrh0wm01pfYNmIwGlivLy8KFu2LEePHqVt27Za63bt2pWnT5+yf/9+vWzb2NjwzjvvUKVKFa5fv26wb02aNNHalpubG/fv39ecq9VqoqKi8uw1a8Pe3h6AlJQUzWsvBm1XV1emTJnCn3/+ycSJE5k4caLmuWYWTk5O2NjYZPMpv/68iK7P6Msvv8TPz4+jR49y6tQpgoKCNMP/vAKerkAYHR3N4sWL6dq1KzNmzMj2+ENgfYjAKQFTp07lp59+0gSPvChSpAjDhg1j1apVedbZunUrR44cITExEZVKxdGjR/n333+pVauWwX59+umnhIeHM3PmTE0Qi4iIYMSIETx58oR33nmHo0ePcvz4cdLT0/nhhx+wtbXVPMczBGdnZ9zd3dmxYwdKpZItW7ZkW5u5b98+Hjx4AECpUqWQyWTI5dm/jgqFgvbt2zNv3jwSExOJjIxk9erVuT43NhRtn1FSUhKlSpXCzs6Oc+fOaZ7fZr0vuVxu0DpTtVrN6NGjee+995g2bRpubm56r6oQWCZFCtqBwkjWDLg+dOrUiRUrVpCQkJBruYODA8uWLdNMZnh5eRESEpLrM0F9/NqwYQPz58+nU6dOZGRk4OXlRdeuXSlevDglS5Zk9uzZTJ48mejoaKpXr86yZcuwtbU1uC3InNiZOHEi8+bN47333ssWgM+fP8+0adNITEzExcWFMWPGUK5cuRw2xo0bx+TJk2nTpg12dnZ069aNd999N1/+vIi2z2jChAnMnDmTSZMm0bBhQ9555x2ePHkCZD4OGDRoEO+//z4ZGRla/+hl8b///Y+4uDiGDx+OTCZj2rRpBAQE0Lp163x9joKCR6bWNgUpEAgEghyIobpAIBAYiAicAoFAYCAicAoEAoGBiMApEAgEBmLxs+opKSlcuHABV1dXFApFQbsjELxSKJVKHj58SI0aNXLdEZVfEhISSExM1Kuug4MDjo6OJmvbFFh84Lxw4YLYniYQFDBr16412dKphIQEfBs1Q4F+WaRKlSrF/v37LSp4WnzgzNri97BiL5S2JU1q+/SC90xqT2B+pFpNJ7ZEZhL94AEf9umlNceBoSQmJqIgg+iiDcmQae/FFlGnwOMTJCYmisBpCFnDc6VtSZS2jlT0KME/cwLZ/s9tBizK3K/drVkFJvasj0sJO347H8WQJX/yKClzS5u3qwPz+jemYRVX0jJUbP/7Nl/9eAKlSo2XV1md7cfHxzNoYH8OHdiPS+nSTJoynaD3e5rkvUll+1XyWZ/A2e+DYA4fPsSzpCTc3T34fMRIPuw3QOs1+gTOV+k+S/GYLENeFKVc++46VCZv1iRYfOB8mW/7N+b0jefZb6qXdWThwKa8N+MgZ27Gsejjpswb0IS+CzKzDs3r35iHT1Ko9PEmStnbsmtcWwa2q8bSffpl9fns00+wtbUlIjKas2fO0DWgI7Vq1eb1N94w+r1IZVv4nJ0RX41m6YpV2NnZcfXKFdq93YradepSr159i/XZGu+zwcjkmYeuOhaIZXqVB+81rcDjZ2kcuRClea37m6+x79Rdjl2OJik1g8kbw/Fv5I1D0cy/CT5uDmw9fovUdCUxj5M5cCaS6mX16/InJSWxfesvTAiZjIODA82aN6djJ3/Wrf3Z6PcilW3hc05ef+MN7OzsgMyepEwm45aRSYTFfTYBMpl+hwViNYGzRDFbxnSvw+ifwrK9Xr2sI+cj4jXnt6KfkpahopJnKQC+23uJ95pWoJitAk8ne9rW8eLAmUi92rx+7RpFihShcpUqmtdq1q7N5UsXjX4/UtkWPufO8GFDcClVnDo1q+Ph4Um7dzoYZU/cZxMgU4BcxyGzzJU0VhM4x/Rswv8OX+d+fPZciw5Fi/DkWXq21548S6NEMRsAjl2Opno5R6J+6sX15d05fTOOXWF39GozMSlRIymRRamSpXj69KkR70Ra28Ln3FmwaAkx8U84ePh3AgK7aHqg+UXcZxMgkz0frud5vOI9zlu3btGjRw/atWtHjx49uH37tt7XVqtWjbdqe7N496UcZYkpGZogmUWJYrY8TU5HJoNt37zNzn/u4Ba8Bu9+63EsbsvkXvo923Io7qDJipPFk6dPKFGihN6+m9u28DlvFAoFTZs1JzLyHiuXLzXKlrjPJkAM1XUzYcIEevbsSWhoKD179mT8+PF6X9uoUSO83UpyZWk3bqzowaed3yCgUXn+nNGZy/cSqFneSVPXx80BOxs5/0Y9xtnBDm9XB5b/epm0DBXxiamsOfIv7erqnk0HqFylChkZGfz7QtLg82fPUv114x+kS2Vb+KybjIwMbt407hmnuM8mQGdvU4/JowLCLF7FxcVx6dIlOnXqBGTmoLx06RLx8fE6rsxk48aN1Bm0miYjd9Jk5E6+P3CV0NP3CJy6n01/3OSd+uVoWs0Ne7sijO1Rl53/3CExJYO4p6ncin7KgLbVUMhllLK3pVfLily4o10GIYvixYsT0KUrkyaOJykpib+OHWP3rh307BWc73shtW3hc3ZiYmLYvHEDiYmJKJVKDuwPZfPGDbzVys9ifbbG+5wvRI9TO1lyB1lrwRQKBW5ubhq5VF2kpKQQk/CMmMfJxDxOJiklg5R0JbFPU7l8L4HhK4/z/actuLWyBw5Fbfh81XHNtT3nHObtOl7cXhXEuYVdSVeqGP2TblneLBYsWkJycjLeZdz4IPh9FixearKlG1LZFj4/RyaTsXLFMipXKEcZN2e+GTWSWXPn0amz8VnkxX02EivucZolkfGFCxcYNWoUe/bs0bzWoUMHZs+ezRs6PrR79+7h5+fHg+qDUdqadudA7Lq+JrUnMD9i55C0REbeo0NbPw4dOkTZsvo94tJF1m860qUTSkVxrXUVyiS84nabtH1TYJYF8FlKiUqlEoVCgVKpJCYmBk9PT3M0LxAILBGZAuQ6QpDqFV6O5OLiQvXq1TWiV7t376Z69eo4Ozubo3mBQGCJyGX6HRaI2bZchoSEMHr0aJYsWULJkiWZOXOmuZoWCASWiBVvuTRb4KxYsSKbN282V3MCgcDS0WfW3EKfNVtdkg+BQFBIyNo5pKuOBSICp0AgKBhEj1MgEAgMRDzjFAgEAkPRZ2eQ6HEKBALBc+TyzNRxuupYIFYTOE8veE8vqQtDcGow1KT2XiT+xCJJ7Eq5o0XswjEP4j7/hxiqCwQCgYGIySGBQCAwENHjFAgEAgOx4sBpmV7lg/j4eLq/1wWXUsWpUrE8G9avM9hGRW9XHv09jx+m9AFgZL+2PDw2V3PEH/+WpFMLcXHMzOiyYmJvHp+Yn62O3IC9tf0+CKaCdxncXUpR6/WqrP5hlcE+54Yp7kVupKamMmhgf6pW8sHNuSSNfOsS+us+k9gWPmfH2r4b+UKGHvk4C849bRSaHqcpZE/nj+7OqYsRmvPZP+xn9g/7NedjPu5A83oViUtI0rz27Y8Hmbhkd758tjbZ2oyMDMqWLcf+g0co5+3Nr/v2EtyzB2Gnz1Hex0f4/IpLGhuOPvk2LbNvZ5leGYgpZE+7tavP46fJHD5xLc86vTo1ZM1u/ZMg68LaZGuLFy/O2PEhlPfxQS6X06FjJ3x8KhB++pTw+RWXNM4XuhQusw4LpFAETmNlT0sUL8q4wR0ZNXdrnnWa1auIq3MJth8Mz/b6wO5vEnlkJsfWfkWgXx2Dfbcm2dqXiY6O5vr1a0Zr1gifc8eavxt6IaQzChZjZU8nDOnIT9v/IjImIc86vTs3YtvBcJKS0zSvLVl/hJoBk/D2+5pJS3ezYmJvmtR+zSDfrUm29kXS09Pp90FvegX3oWq1akbZEj7njrV+N/Qlqyet67BEzBI4Z86cSevWralatSrXruU9FM4vxsie1qriRatG1Vi45nCedYoVtaFrm7qs2fVPttfPXLlH/OMklEoVoX9eYsO+kwT41TbYf2uRrc1CpVLRv28fbGxtmbdgsdH2hM95Y23fDUPI7FDqCpwF4ppOzBI4/fz8WLt2LV5eXpLYN0b2tIVvZcqXcebavsncOjCNz/r4EehXh7/WjdLUCWhVm0dPnvH7yetaLGXuCDHmL6Sly9ZC5nscNHAAMTHRrN+4BRsbG90X6UD4rBtr+G4YjEzPwwIxS+D09fWVVF/IGNnT77ce443OITQOmk7joOms2vInv/55Ef9PvtPU6dW5EWtzmRTq0qYOxYvZIpPJ8Gtcjfc7NGD3kfN6+WyNsrUAnw4dzNUrl9mybSfFihUziU3hc3as9bthKFIO1RcvXpxthHvmzBn8/f1p164d/fr1Iy4uTlNXW1leFIpnnJB/2dPklHSi455qjsRnqaSkphP7KBGAMq6leKtBFdbu/ifHtZ+8/xY3Qqfy4PdZTPs8kE8mr+ePU9p7pVlYo2ztnYgIvl+5gnNnz1ChnCeuTiVwdSrBhnVrhc9C0thgZOgROPPR5bx48SJnzpzRjHBVKhUjR45k/PjxhIaG4uvry5w5c3SWaaPQrON0dnZm8y/bjbYzdfnebOf3Hz6mRIPhudZt039+vttxdXVl/6Ej+b5eG6a6Fy/jXb48z9JUJrcLwucXscbvRn6Qy+WodWQ/kv9X/uDBgxxlJUuWzDHZlZaWxqRJk5g7dy59+mRuZLlw4QJ2dnb4+voCEBQUhJ+fH9OnT9dapo1CEzgFAoGVoc8zzP/Ke/XqlaNo6NChDBs2LNtrCxYswN/fP5sGe1RUFGXKlNGcOzs7o1KpSEhI0Frm6OiYp1sicAoEgoJBn2eY/5WvXbsWDw+PbEUv9zbDw8O5cOECI0aMMKmbuWGWwDllyhT2799PbGwsH374IY6OjuzZs8ccTQsEAgtFn8mfrHIPD49svcjcCAsL48aNG/j5ZU6iPXjwgP79+xMcHMz9+/c19eLj45HL5Tg6OuLp6ZlnmTbMEjjHjh3L2LFjzdGUQCCwEgwJnPowcOBABg4cqDlv3bo1y5Yto1KlSmzatImTJ0/i6+vLhg0baN++PQA1atQgJSUl1zJtiKG6QCAoELIWwOuqYyxyuZxZs2YxYcIEUlNT8fLyYvbs2TrLtCECp0AgKDgkXOD+22+/af5dr149du3alWs9bWV5IQKnQCAoEORyuU4xNrkQaxMIBILnmPoZpzkRgVMgEBQMBqzjtDRe6cD5KMz4LDl54fmh8Vv6ciNqdc6FwKbCUv+6a8MafVZJow6MwspuhehxCgQCgaEYsADe0hCBUyAQFAgyPTK8W2qP0zKnrPKBVOp9xthdPqgplxd1JWJFd8JmdSa4ZUVNWXDLipya48/dld3ZPLIVHo7P052N6lKTmNXvc3dld81R3tXBLD4XlG2p7C79bjHNGvlSqrgdH/XraxKb5rANsHnTBurVeh03JwdqVqvEsT//MNqmJalcSpUdyRwUmh6nVOp9xtidt+siw1b9TVqGisqeJdn1TRvORTzCoWgRxnWvg/+0g9x48JQZwfVZ9UkzOk09qLl22z8RfLzsL7P7XFC2pbLrWaYMo74Zy8H9oSQnJxtly5y2fzt4gPFjRvPTmg34NmjIg6gok9i1JJVLmRzQIadtobLqhaPHKZV6n7F2r0Q+Ji0jM6WZWq1GDVRwc6BdXS92nLjDlcjHpCtVzN5+gWbV3PFx079XKZXPBWFbSp8Du3TFPyAQZxcXo22Z0/bUySGM/mYcDRs1Ri6XU8bLizJGKihYmsql0BwqYKRS7zOF3TkfNCByVQ/CZvsTnZDMgbOZCQVe/DpkfTeql32eWKB9XS9uLn2Pv6Z3pJ9fZbP6bG7bFqe+WMAolUpOnzpJbOxDalWvTJXXyvHF8KFG92ot7T6LwFnASKXeZwq7I34Ko9xHm3hn8n52nbxLaoaSQ+eiCGzkzRvlHClqo+CrwJqoVGrsbTM1pLf/E0GjUbupNOQXPvvhH0YG1uTdxuXN5rO5bVua+mJBExMdTXp6Otu3/sL+337nrxPhnDt7hpnTpxhl1+Lus9Ac0s6jR4/46KOPaNeuHZ07d2bo0KHEx8ebzL5U6n2msqtSq/n72kO8nOzp51eFoxcfMGPreX769E3OzgvgTmwSiSnp3I9/BsDV+094kJCMSq3mxPVYlodewb+ht1l9NqdtS1NfLGiK/qeLNGjIUDw8PSldujRDh3/O/l/3GWXX0u6z6HHqQCaTMWDAAEJDQ9m1axflypXTS9dDX6RS7zO1XYVCRoX/nmOuOngN35G7qDp0KzvD7qBQyLl073Gu16nV+v/hlVLJ0Frus7Xj5OSEV9my2YKGKQKIpd1nETh14OjoSKNGjTTnderUyZY81FikUu8zxm7pknZ0bVye4nZFkMtktK7pybtNfPj94gPsbORUL1sKgLIu9szv14jloVd4/CwNgHfqlaWUvS0A9V5zYWDbquw9fU9ynwvKtpQ+Z2RkkJKSglKpRKlUkpKSQkZGhtF2pbbdu09fli1ZTExMDI8ePWLxwvm079DRKJuWpnKJHsuRLHWsbvblSCqVivXr19O6dWuT2l2waAkff9QP7zJuOLu4mEy9L7921Wro51eZb/s2RCaXcS82iW/WnGRfeCQl7W1YObgZPu4lSExOZ90fN5m65Zzm2ncbl2fxgMbY2si5H/+MBXsuseHPW5L7XJC2pbI7Y9oUpk6eqDlfv24NY8ZNYOz4EIu2PfqbccTFxlK3RlXsihal67vd+Gr0GKPtSvndMBSZXKZzOZLO8gJCplarJdo5mzsTJ04kOjqaxYsX65Uy6t69e/j5+bF3/yG8vLSnzrckrHGvusA8KCXarK6QIMhERt6jQ1s/Dh06pFO6Ql+yftPprcaBvbP2ys/isTk82aTtmwKz9jhnzpxJREQEy5Yts9g8ewKBwDxkjsR17VU3iysGY7bA+e2333LhwgVWrFiBra2tuZoVCAQWil6PMF/lwHn9+nWWL1+Oj48PQUFBAJQtW5bvvvvOHM0LBAILRJ8kH690dqTKlStz9epVczQlEAisBNHjFAgEAgORoUeP00IjZ56B8/jx43oZaNKkicmcEQgErw5yhQyZjrT1aoUMlZn8MYQ8A+eYMbrXjMlkMg4dOmRShwQCwauBPo84LbTDmXfgfFGTWCAQCEyNXlsqLXRySO/FlOnp6Zw8eZK9e/cC8OzZM549eyaZYwKBoHCT1ePUdVgiek0OXb16lcGDB2Nra0t0dDQdOnQgLCyMbdu2MX/+fKl9tEqk2uHj0XeNJHYBHvzYWxK7Uu2UAWl2y0iNNe0ckpJC3+MMCQnh008/5ddff6VIkcxY26BBA06dOiWpcwKBoDBTyJN8/PvvvwQEBADP01vZ29uTmpoqnWcCgaBQY8Xr3/XrcXp5eXHhwoVsr507dw5vb/2S6woEAsHLFPp8nMOHD+fjjz9m4cKFpKens3z5coYPH85nn30mtX96IaVMq6XK1i4f3Iwri9/lzsrunJztT/BblTRlwW9V4vTcAO6t6sGWr1pnkx7ePLIV91b10BwxP77Psen653mUUl5WCjlcsHxJ4xVLv6Nls4a4lirG4I8+1Lx+5fIlWjZriLenC96eLvh3aMuVy5cswmdTIJeDXC7TcRSYe1rRa6jeqlUrVq1axaZNm2jQoAGRkZEsWrSIGjVqSO2fXkgp02qpsrXzdl5g2MrjGunh3WPe5tzteEoUs2F8tzp0nnbgP+lhX77/pDkdpx4AoNvsw9ns7B7zNr9ffKB3u1LdD6nkcMHyJY09PD0ZOeobDh3cT8oL3wUPzzL8b90mvL3Lo1KpWLlsCf369OSvsDMF7rMpsOahut5bLl9//XVCQkIkdCX/BHbpCsDpUyeJvKdfpnR9yJJTPXXmQg451SnTZhhl21ifr0Q+l9lQ/3dUcHeg/mul2X4iQlM+e/t5rix+Fx83B27HJGaz4V26OE2qujJkuX767VLejxflcAGjpXCzkMpnU9r1D8z8LoSfPsX9yOffBUdHRxwdM5VP1Wo1CoWCmzf+tQifTYE+Q3GrHqqnpaWxYMEC2rZtS506dWjbti3z588v9JNDlian+jJz+jbg/vdBnMySHj7zn/TwC9+1rH+//oL0cBZBzV/j+NWH3IlN0qs9qe6HVHK4UDgkjb09nHFztGfkF5/y5Vdf59uOpX2frXkdp97Lkf7++2/GjBnDli1bGDNmDCdOnLDYHqipsDg51ZcY8WMYZQdspP2kUHaF3SE1Q8nBc/fp0qj8c+nhLrVQqdQUs8s5uAh68zXW/X5D7/akuh9SyeFC4ZA0vvMgnrvRj5g9bxG1atfJtx3L+z4X8uVIhw4d4sCBA5qbXqlSJWrXrk3btm31bmjIkCHcu3cPuVyOvb0948aNo3r16vnz2kxYmpxqbmRJD3dvVoH+flVYvv8q0385x/+Gt6BEMRuW/nqFpynp3I/P3qtsXMUVt1JF2XHijt5tSXU/XpbDBRg6/HNmTZ9KyKSpRtkuLJLGxYsXp/9HH/NaOXfCwi/i6uZmsA1L+z5b8zNOvXqcpUuXzjFsSk1NxdXVVe+GZs6cyc6dO9m+fTv9+vXjm2++MczTAsDS5FS1UUQhp4J75g9g1cFr1B+xkyqf/MLOsDsUkcu5dDe79PD7b77G7rC7JKXqr8oo1f2QSg4XCpeksUqlIvnZM+7fj8zX9Zb2fS6Uy5GOHz+uOQICAhgwYACbNm3i6NGjbNy4kY8++kizKF4fXvyrlpiYaNIbIpVMq6XK1uYqPdzYh6O5SA8v6N+YZfufSw8DFLVRENioPOv+0H+YDtLeDynkcKX02ZR28/ou/HboAGfPhKNUKnny5AnffPUljo5OVK2Wv5GapckD616KlHlYIgallVu2bFm2840bNzJw4EC9GxszZgzHjh1DrVazatUqA9zUjpQyrZYoW6tWQ3+/Ksz7sBEyOdyNTeLrNSfZd/oepb10zaMAACAASURBVOxtWDWkOT5uJUhMSWft7zeYuvlstus7+pbjybM0fr8UbbDfUt0PqeRwwfIljWfPmMqMqZM05xvXr2X0mPFUq/46X30xnPuR9yharBj1fRvwy869FC1atMB9NgXWPFQ3uzwwwPbt29mzZw8rV67UWdda5YGlQiT5yI61JbYASMuQJjWvbRHTrxaXUh7Y5f2ZKEqU1lpX+TSWuPWj9G4/r7mUW7duMXr0aBISEnB0dGTmzJn4+PgAaC3LiwJZlx8YGMg///zDo0ePCqJ5gUBgAUjxjDOvuZQJEybQs2dPQkND6dmzJ+PHj9dco60sL/SaVU9MTGTRokWEhYXx6NEjXuykHjlyROf1SUlJPHnyBM//Zkx/++03SpUqpVncKxAIXk30jYsPHuTc3VayZMkcy6tym0uJi4vj0qVLrF69GoBOnToxefJk4uPjUavVeZY5Ozvn6Y9egTMkJITo6GiGDBnCyJEjmT17Nt9//z3t2rXT53KSk5MZPnw4ycnJyOVySpUqxbJlyyx2xkwgEEiPITuHevXKmd926NChDBs2LMfrL8+lREVF4e7ujkKhAEChUODm5kZUVBRqtTrPMqMD57Fjx9i7dy9OTk4oFAratGlDzZo1GTRoEH379tV5fenSpdm0aZM+TQkEglcEQyaH1q5di4eHR7ayl3ubWUydmrn2d/v27cyaNYvhw4cb7evL6BU4VSqVpgtsb2/P06dPcXV1JSIiwuQOCQSCV4Os7Ei66gB4eHgYPDkVGBjI+PHj8fDwIDo6GqVSiUKhQKlUEhMTg6enJ2q1Os8yrX7p40C1atUICwsDwNfXl5CQEEJCQnTOPAkEAkFeyGUyvQ59SUpKIuqFrFpZcykuLi5Ur16d3bt3A7B7926qV6+Os7Oz1jJt6NXjnDJlimZCaMyYMXz77bc8efKE2bNn6/2mBAKB4EVMvY5T21xKSEgIo0ePZsmSJZQsWZKZM2dqrtNWlhd6Bc5y5cpp/u3i4sLUqVNRqVRs3bqVihUr6v/OBAKBIAsTi7Vpm0upWLEimzdvNrgsL/K9jjMjI4Nx48bl93KBQPCKIwfkMh1HQTuZB3onMs6NAth09Moj1e4eAKeWptni+DKPjhqX4aiwYaOQZhmeFL9HKX/j1pzI2KjAaalvSiAQWD7WvFdda+C8e/dunmVpaWl5lgkEAoEuFDIZCh2RUWWhkVPrI4S3336btm3b8vbbb+c4OnY0PuWXKbF0JUNz2jaF3YplXXj0Wwg/jO8GwJt1K5D0x2QeHhivOXq9UzfbNd38ahK+djixBydwcdMXNKtd3qw+54Y1KqCmpqYyaGB/qlbywc25JI186xL66z6LtZtv9NmnbqGBU2uP88qVK+byw2gsXcnQ2nye/2VnTl3JnjA3KvYplbrMyrV+6wYVmTKkHcHjNxJ26R6eLoZlFbdUNVFtSOVzRkYGZcuWY//BI5Tz9ubXfXsJ7tmDsNPnKG/E2mmp7OYXax6qW+qklUFkqfdNCJmcQ73PEu1aus/d/Gry+GkKh0/qn+h4XH8/pq0+zImLd1Gr1dyPfcL92Ce6LzSRz3kR2KUr/gGBOLu4GG3rRaT0uXjx4owdH0J5Hx/kcjkdOnbCx6cC4adPWaTd/GLqBfDmpFAETmtUMrRUn0vY2zFuQBtGLdqbo8zVqTi3d33N5c1fMuvTDtgXtQEyt83Vq+aFq2NxLmz8gn+3fcW8LzpT1Fa/uUdLU1/UB3P6HB0dzfXr10wucSGVXX0p9CqXlo41Khlaqs8TPmrDT7tPEvkwe2/xWsRDGvVdTAX/GbT/9AfqVi3DzGEdAHB3dsDWpgiBrWrQZshKGvVdTO3Knozu28osPhcE5vI5PT2dfh/0pldwH6pWq2bxdg1BpofKpcxCVS7NHjgXL15M1apVuXbtmslsWqOSoSX6XKuyJ60aVGThxr9ylEXHJ3Ll9kPUajURUY8YsySUwLcyeyrJqekALN1ynAdxT4l7/IyFG4/RrkmVHHZM7XNBYQ6fVSoV/fv2wcbWlnkLFlu8XUMptD3OevXqmbSxixcvcubMGby8vExq1xqVDC3R5xZ1K1Dew4lrW0dya+doPnu/OYFvvcFfP3ySo65ardZktkl4msK96IRsi6UNWThtaeqL+iC1z2q1mkEDBxATE836jVuwsbGxaLv5QS57viQpr8NSlVG0Bk5T7hpIS0tj0qRJhISEmMxmFtagZGgNPn+/I4w3us+lcd/FNO67mFXbT/DrX1fx/2I1LepVwNs9M2N/WbdSTB7cjt1/XNZc+7+9pxnyXhNcHYvjWKIow3o0Y99fVyX3WRfWqIAK8OnQwVy9cpkt23ZS7D/deUu2mx8KpTwwmHZn0IIFC/D39zeZ4FMO+4uWkJycjHcZNz4Ift+kSoZS2JXSdn7tJqemEx2fqDkSk9NIScsgNuEZdSqX4fDyj4k7NIHDywZy8cYDvpy/W3Pt9NWHOXk5knMbPid87WecvXafmT8dkdxnXcyYNgWnEsWYM2sG69etwalEMWZMm2K0XZDO5zsREXy/cgXnzp6hQjlPXJ1K4OpUgg3r1lqk3fyic5/6f4clolXlsnr16ri7u2s1oI/mUHh4OPPnz+fHH39EJpPRunVrli1bRpUqup+BCZVL8yH2qpsHa8rxEBl5j47t2kiicllr2GLsHN201k1NiOHcoqEmbd8UaF0vYmtry6xZuS94NoSwsDBu3LiBn58fkCm81L9/f6ZPn07z5s2Nti8QCKwPa14ArzVwKhQKGjZsaHQjAwcOZODAgZpzQ3qcAoGgcFJosyNZ05BCIBBYFzJ0P8O0zLCpI3BOmjRJkkZ/++03SewKBALrQZ8tlVa55bJUqVKcPn1acx4REUFQUBD169enf//+xMTESO6gQCAonBTaveoLFizI9oxh7NixlChRgrlz52Jvb6+XqJFAIBDkhjXvHNKZyLhmzZoAxMXFcerUKQ4fPoy7uzu1atXC39/fLE4KBILCR6GdHHrR6fDwcMqWLatZ1+nk5MSzZ8+k9U4gEBRe9OlRWmbc1D5Ur1GjBj///DOJiYls2bKFFi1aaMru3r2Lk5OT5A4KBILCiTU/49Ta4/z6668ZNGgQs2bNwtvbm4kTJ2rKduzYQYMGDSR3UGA+pNrhU/XLXZLYBbg4SxoJlyIK68u4KMWwVsqhcqFdAF+pUiUOHjzIo0ePcvQuP/jggwLNrCIQCKwbBegUa1OYxxWD0StFd25D8peTuAoEAoEhFNrJoZYtW+p0XJ8kHwKBQPAyMj2yH1lo3NQ+OTR79mxmzZql9bAULFlq19y2LdXn+cF1CZv0NhdmtufwmFYENfbWlBW1UTClW03Cp7bj/Iz2bBrWVFPWpJILG4Y24fyM9vw53s9gnyNu3+bdgI6U83ChYvkyfPnZMJPk5JTyPvf7IJgK3mVwdylFrdersvqHVSaxK6XPhmLNaeW09jhNkeDDXFiy1K7wOZPvDlznq3VnSVOqqOjmwIZhTbhw7zEX7j1mRlAtFHIZftMOk/Asjde9Smmue5amZOPfdylqE8knb1c22Ocvhn9CaVc3rt+O5HFCAv4d27Fy+VIGfzLMYFsvIuV9HvHVaJauWIWdnR1Xr1yh3dutqF2nLvXq1bdYnw2l0A7VFy/Wrkcik8n45JOcsgrmJkuq9dSZCzmkWqdMm2Fxdl9Vn68/SNT8W40a1FC+tD3JaUra1HCn8fiDJKZm9gQv3HusqXv2TgJn7yTQrErpfPl9+/ZtBg7+hKJFi1LUw4M2bdsZrUYp5X0GsgWyrABz68YNowKn1D4bij49SkvtcWodqkdEROR5/PzzzzoDq7mwVKndgrBt6T5P6VaTK7M7cHhMa2KepHL4Ugy1yzsSGZ/M5x2qEj61HaGjWvJObU+j/c3ik6Gf8sumjTx79oz7kZEcCP2VNm3bGWXTHPLAw4cNwaVUcerUrI6Hhyft3ulglD1Lk2EutFsuZ8+eneO1w4cPs2DBApydnSXRD8oPliq1WxC2Ld3nsZvPM37LeepVcKZJJRfSMlR4OhalWpmS7DsbRcPx+6nn48zqjxty/cFT/o1O1G1UB03fbMHqH1ZRxtURpVJJz9596OwfaJRNc8gDL1i0hG/nL+Kfv4/z+9Ej2NnZGWXP0mSYZXoscLfUobreq3yPHz9OUFAQU6dOpW/fvuzZs4d33nlH74Zat25N+/btCQgIICAggD/++CNfDueGJUrtFpRta/BZpYaTN+PxcCxK7+Y+pKSrSMtQsWj/ddKVav65Ecfx67G8Wc3VaJ9VKhVdO3fAP6AL0fFPuR0ZQ0LCI8aNGW2UXXNJGisUCpo2a05k5D1WLl9qlC1Lk2HOXMep4ygQz3SjM3CeOXOGPn36MGrUKPz9/dm3bx+BgYHI5YbvrFi4cCE7duxgx44dvPnmm/lyODcsUWq3oGxbk89F5DLKl7bnyv0nOcpMlUM7Pj6eu3fvMHDwJ9jZ2eHi4kLvPn3Z/+s+o+yaW9I4IyODmzdvGGXD0mSYrXnLpdbo9/HHHzNo0CBatGjBr7/+SlBQEAqFApVKpTksAUuU2hU+Z8fFwZbOdctgb6tALoMW1Vzxr+fFsWux/PNvHPcfJfNJm0oo5DJ8KzjRpHJpfr/8EMh8zmVXRI6NQv7Cv/X7QZUuXRofnwqsWrGMjIwMEhISWLfmf9SoUbPA7oUuYmJi2LxxA4mJiSiVSg7sD2Xzxg281crwpVjm8jk/FNpnnEePHgVgzpw5zJ07N1uZWq1GJpNx+fLl3C7NlREjRqBWq6lfvz5ffPGFSXcfLVi0hI8/6od3GTecXVxMKrUrhV0pbVuiz2o19G7uw9TutZDLITI+mYnbLnLwQjQAA1adYFZQbQa3qUTko2S+WBvOjZjM55uNKrqw8YV1ndfmduT49ViCFh/Xy+e1G7cwasQXzJ87C7lCQcu3WjFj9rf5ePfZkeo+y2QyVq5YxqdDB6NSqfD2Ls+sufPo1Nn4NI5SfjcMxZoXwGuVB46MjNRpwMvLS6+GoqKi8PT0JC0tjalTp5KUlMScOXN0Xifkga0fkeQjO1JpeUkxkRIZeY8Obf0kkQcOmPgDDi7a5ccT46LZMaGfdckD6xsU9cHTM3N5ia2tLT179mTw4MEmsy0QCKyPQpsd6euvv9ZpYPr06TrrPHv2DKVSSYkSJVCr1ezdu5fq1avr76VAICh0mHoB/KNHj/jqq6+4c+cOtra2lC9fnkmTJuHs7MyZM2cYP348qampeHl5MXv2bFxcXAC0luXpl7bCbdu2cebMGZydnXF3d8/10Ie4uDiCg4Pp3LkznTp14tatW0yYMEHP2yEQCAojcpkMhY7DkFl1mUzGgAEDCA0NZdeuXZQrV445c+agUqkYOXIk48ePJzQ0FF9fX81jQm1l2tC55TJr+ZCfnx+BgYHUrVtX7zeSRbly5di+fbvB1wkEgsKLHD16nAbYc3R0pFGjRprzOnXqsH79ei5cuICdnR2+vr4ABAUF4efnx/Tp07WWaUNr4GzTpg1t2rTh8ePH7NmzhxkzZpCQkEBAQAC9e/cWOTkFAkG+MSTJx4MHD3KUlSxZMs8YpFKpWL9+Pa1btyYqKooyZcpoypydnVGpVCQkJGgtc3R0zNMvvRIZlypVip49e+Lv78+SJUtYvHgx9erVo3HjxvpcLhAIBDkw5Blnr169cpQNHTqUYcNyz3A1efJk7O3t6d27NwcOHDDW1RzoDJwqlYo//viD7du3ExYWRsuWLfnxxx+tKuWcQCCwPAyZVV+7di0eHh7ZyvLqbc6cOZOIiAiWLVuGXC7H09OT+/fva8rj4+ORy+U4OjpqLdOG1sA5Y8YM9u3bR5UqVQgMDGTGjBlGJxoQCAQCyFoAr2uonvl/Dw8PvdZxfvvtt1y4cIEVK1Zga2sLZKr1pqSkcPLkSXx9fdmwYQPt27fXWaYNrYHzxx9/xNvbm6SkJNatW8e6dTmzRa9du1ZnIwKBQPAypl6OdP36dZYvX46Pjw9BQUEAlC1blu+++45Zs2YxYcKEbEuOAORyeZ5l2tAaOPVZoykQ6OLq3M6S2Xbq8b0kdh9t7C+JXbDcVGnmJmvJka46+lK5cmWuXr2aa1m9evXYtSv3HWzayvJCa+Ds0qWLQcYEAoFAXwrtziGBQCCQChl6JPkwiyeGI10mAzPzqilGFoRdKW2bwm5Fz5I8Wv8BP3zaEgAPx2JsHt2GmyuDSP6lP96uDtnqT+/TkPOL3yNmTTBnFr5Lz5aVzO5zbiz9bjHNGvlSqrgdH/XraxKbWViWyqX15uMsND3OV00xUvick/kDmnLq31jNuUqt5kB4JHO2nuPI9JzPWZNS03l3+gGu33+MbyVXdoxtx80HT/j7aozZfM4NzzJlGPXNWA7uDyU5OdkoWy9jWSqX1jtULxQ9ziz1vgkhk3Oo91miXeGz6e12a/Yaj5+lcvj88zV5MY9TWBF6mZP/Psz1mikbw7kW+Ri1GsKuP+TY5Qc0quJmNp/zIrBLV/wDAnHWkWjCUKT0OT9Yc49Tr8CZlpbGvHnz8PPzo379THnSP//8kzVr1kjqnL68qoqR5rQrpW1j7ZYoZsO4oHqMWv1Pvn0oaqugfiVXLt19pFd9S1OM1AdL89maM8DrFTinTZvGtWvXmDNnjmYpReXKlVm/fr2kzunLq6oYaU67Uto21u6E9+vz06FrRMY/y7cPiwY24/zteA6c0Z28GyxPMVIfLM1nU2dHMid6PeM8ePAg+/fvx97eXiPS5u7uTnR0tN4NpaamMm3aNI4fP46dnR116tRh8uTJ+fP6JV5lxUhz2ZXStjF2a/k406pWGRqPyH/2rWl9GvC6txPtJ+zV+xpLU4zUB0vzWYbuWXPLDJt6Bk4bGxuUSmW21+Lj43Xu53yR2bNnY2dnR2hoKDKZjNjYWN0X6cmL6n2VKlcGTK8YaUq7wmfT2W3xhiflXR24tqwHAA5FbVDIZVQr50jTkTt0Xj+2R13a1i1H23F7eJqcbhafCwpL81mfZ5iW2uPUa6jevn17Ro0axd27d4FMFb5JkybRsaN+ei9JSUls376d4cOHa4b6pUuXzqfLOXnVFCOFz8/5/sAV3vhkM41HbKfxiO2s2n+FX0/fxX9yKAB2NgrsbBQ5/g0woksterxZkY4T9xGfmGo2n3WRkZFBSkoKSqUSpVJJSkoKGRkZRtu1OJVLPQ9LRK/A+fnnn1O2bFn8/f158uQJ7dq1w83NjU8++USvRu7evYujoyOLFy+ma9euBAcHc/LkSaMcf5kFi5aQnJyMdxk3Pgh+36SKkVLYldL2q+RzcpqS6IRkzZGYkk5KmpLYJykAJGzoS9y6DwA4t+g9Ejb01Vw7uXcDypV24MLibjxc04eHa/owsmttyX3WxYxpU3AqUYw5s2awft0anEoUY8a0KUbbBWm/G4ZizZNDWlUucyM+Ph4nJyeD9ttevHiRrl27MmfOHDp37szZs2cZNGgQBw4cwMHBQeu1QuVSoA1r3KtuTUipcjl84Tqc3Dy01n0U84AFn/a0LpXLLLKG6FkkJSVp/l2uXDmd13t6elKkSBE6deoEQO3atXFycuLWrVvUrFnTEH8FAkEhQY7uIa+lLjTXK3C+/fbbyGSybHrQWT3Oy5cv67ze2dmZRo0acezYMZo3b86tW7eIi4ujfPny+XRbIBBYO9Y8OaRX4Lxy5Uq284cPH7J48WKNwJE+TJw4kW+++YaZM2dSpEgRZs2aJTSLBIJXmMxnmPolMrY08rVX3dXVlTFjxtCuXTs6d9Yv12K5cuX4+eeC2dolEAgsj0I/VM+NmzdvmjwBgUAgeIXQQ+XSUrucegXOnj17ZnuDycnJ/Pvvv3ovRxIIBIKXKfQ7h7p165btvFixYlSrVg0fHx8pfBIIBK8A1pxWTmfgVCqV/P3330yePFmjGicQCATGIkeGXEefUld5QaEzcCoUCo4dOyYEpgQCgUkp9MuRPvjgAxYtWsSwYcOwsbGR2qdCgYEbsvRG/AHLjlQ7fJzaz5TELkD8vq8ksWtt341CO1TfvXs3nTp1Ys2aNcTGxrJ69WqcnZ2zfUBHjhyR2keBQFAIkekxVJdZ41B9/PjxdOrUSS+BdoFAIDCEQtvjzBpuNmzY0CzOCASCVwcZegROs3hiOFoX5qtUKv7++2+OHz+e52EJWKOcampqKoMG9qdqJR/cnEvSyLcuob/uM4ntV1UeWCrbFb2ceLT3S34YnZmkpkVtb8JW9iNq+3Dubf2UjSFdKOPyPMtXGRcHNk3qSuTWT/l3/RAGdKpjsM/9PgimgncZ3F1KUev1qqz+YZXBNnJDyt+Kocj0/M8S0drjTEtLY8yYMXlOdMhkMg4dOiSJY4ZgjXKqGRkZlC1bjv0Hj1DO25tf9+0luGcPwk6fo7yR62NfVXlgqWzPH/Y2p65Gac6vRMTiP3oTUXGJ2NoomND3TRYMb0u38VsB+OHrTpy/8ZCeE7dTvbwLv855n2t34/n97B29fR7x1WiWrliFnZ0dV69cod3brahdpy716tU37M2/hJS/FUORyzIPXXUsEa2Bs1ixYhYRGHUR2KUrAKdPnSTy3j2T2c2SUz115kIOOdUp02YYZbt48eKMHR+iOe/QsRM+PhUIP33KqMAppc9S2bZkn7u9VZ3HSan8fSmSimWcAIhJyC4Kp1SpqOiVWVa8qA0t65Sn9+QdZChVnL/5kG1/XOWD9jUNCpwvBnXZf1sTb924YXTglOq3kh9keixHstSVApa6h94iMKecanR0NNevXzNa/+VVlAeWynYJe1vG9W3OqKW/5Sgr51aCqO3DebTnSz7r1pBvN2ZKE2f90F/8wctkMl6v4Gqw78OHDcGlVHHq1KyOh4cn7d7pYLANS8aah+paA6dUaxGtBXPJqaanp9Pvg970Cu5D1WrVjLL1KsoDS2V7Qt83+WnfOSJjc9a9G/MUz8AFlH13IRNX/8G1u/GZ7SWn8deFe3zduyl2NgrqVHInsHkV7O0Mz6ezYNESYuKfcPDw7wQEdsHOzs5gG5ZM1lBd12GJaA2c4eHhJmnk3r17BAQEaI7WrVtbxUy9OeRUVSoV/fv2wcbWlnkLFhtt71WTB5bKdq2KbrSq58PCX8K01nv0NIU1+y+waVJXFP/9yj+ctovyHqW4vn4IC4e3ZcOhi0Q+zN8fAYVCQdNmzYmMvMfK5UvzZcNSyUzyYY39TSPSyhlC2bJl2bHjuVTr1KlTc8gNWyJSy6mq1WoGDRxATEw023buMcmurFdNHlgq2y1qe1PevSTX1g0GwKGYbabscPkPaDr4p2x1iyjkuDsVp2RxOx49TeFOzBPeHfuLpvzHbzpz8oXJpfyQkZHBzZs3jLJhaVjzOk6zP+NMS0tj165dvPvuuyazaa1yqp8OHczVK5fZsm0nxYoVM4nNV00eWCrb3+85wxt9VtD44x9p/PGPrNp1hl//uYn/6E0ENK9C5bLOyGRQulQxZg5uTfj1Bzx6mqmsWdXbBYdittgUkRPk9zp+9X1YuEV7z/VFYmJi2LxxA4mJiSiVSg7sD2Xzxg281crPqHsB0v1W8kOhlwc2Jb/99hvu7u68YUJJUmuUU70TEcH3K1dw7uwZKpTzxNWpBK5OJdiwbq3F+iylbUvzOTk1g+hHSZojMSWNlLQMYh8nU6a0Azund+Phzs8JW9kPlUpN0IRtmmvf9q3ApZ8/JmrbcD7qXJeArzcT+1j/pT8ymYyVK5ZRuUI5yrg5882okcyaO49Onf3zfQ+ykPK3YihZs+raDkudVTdYHthYPvroI95880369OmjV31rlQcWST6sG5HkIxMp5YHn/LANV/cyWus+jL7PiH5dLE4e2Kw9zujoaMLCwvTWKRIIBIWXrPWpug5LxCyTQ1ls27aNli1b4uTkZM5mBQKBBSImh/Rk27ZtJp0UEggE1ouYHNKT0NBQWrRoYc4mBQKBJWPCqDlz5kxat25N1apVuXbtmub1W7du0aNHD9q1a0ePHj24ffu2XmXaEFsuBQJBgWDqLZd+fn6sXbsWLy+vbK9PmDCBnj17EhoaSs+ePRk/frxeZdoQgVMgEBQIWc84dR364uvri6enZ7bX4uLiuHTpEp06ZaYE7NSpE5cuXSI+Pl5rmS7MOjkkEAgEWRiiq/7gwYMcZSVLlsyRh+BloqKicHd3R6FQAJlbWN3c3IiKikKtVudZ5uzsrNWuCJwCgaBg0Ge50X/lvXr1ylE0dOhQhg0bJoVnOhGBUyAQFAiGLEdau3YtHh4e2cp09TYBPD09iY6ORqlUolAoUCqVxMTE4OnpiVqtzrNMFyJwSoSlLtwtbEi1Q+vRr6MksQvgM3iLJHZvL31PErtSYchQ3cPDI187h1xcXKhevTq7d+8mICCA3bt3U716dc1QXFuZNkTgFAgEBYMhkVMPpkyZwv79+4mNjeXDDz/E0dGRPXv2EBISwujRo1myZAklS5Zk5szn22m1lWlDBE6BQFAg6LPcyJDlSGPHjmXs2LE5Xq9YsSKbN2/O9RptZdooNMuRXkX1RXPbFWqi2THG58X9G3B2dkeuLwzg2JR29GzuA0DXRuW4sShQc9xcHMiDle9Ry9sRgJLFbFj4oS8X5nbiwtxOjOj8utl8NjWmXo5kTgpNj/NVVF80t12hJmo6nxftu8oXP50iLUNFJY8SbB3Rkgt3Etj6z122/nNXU69H0/J83rE65+4kADCpR22K2Rahwdf7KF3Cjs1ftOBeXBIb/oqQ3GdTY+KRulkpFD3OLCXDCSGTcygZWqJda/U5sEtX/AMCcXZxMdrWi0jpc5aaaHkfH+RyeTY10YL0+er9J6RlqIDMCS61Wo2Pm0OOet2blGfz38+D4tu1PPku9CrJaUruxj1j3bHbBDWvYBafTY01Z0cqFIHzVVNfLAi7UvKqqonO6FmXm4sDYd0wLQAAGctJREFUOTalPdGPUzh4Pru8RllnexpXcWXz8ey9SdlL/65WRveyHFP5bEqseaheKALnq6a+WBB2peRVVRMdvS6cSsO24z/zMHvDIzU90Cy6NSnPP9djuRP7XMf98MUHDH2nGsXtiuDjWpz3m/lQzFZhNp9NjTVmRgIzBs7Dhw8TGBhIQEAA/v7+7N+/32S2XyX1xYKyKyWvspqoSg0n/o3D06kYH7SsmK2sWxNvNv11O9trY9efISVdyfGp7flpaFO2hd0l6pF+z5st8rthpZHTLIFTrVbz1VdfMWvWLHbs2MGsWbMYNWoUKpVK98V68KKSYRamVl80pV0pbUvps1RI7fOLaqLrN24xuZpoFsb4XEQux8e1uOa8QUUXPByLsetUZLZ6Cc/S+WTVCWqN2E3LCQeQy2SE39adlEIKn43F1NmRzInZepxyuVwzJHj69Clubm7I5aZp/lVSXyxIn4Wa6HOM8bl0CTsCGpTF3k6BXAZvveFOl4bl+ONKjKZO96bl2XM6kqTU7Pe3vGtxnIrbIpdB6xoe9H6zAvP3XJHcZymw5mecZlmOJJPJmD9/PkOGDMHe3p6kpCRWrFhh0jYWLFrCxx/1w7uMG84uLiZVX5TCrpS2pbI7Y9oUpk6eqDlfv24NY8ZNYOz4EKNtS+VzlpqonZ0dFco934O86LtlBPXMmTjCEPLrs1qtpm/LiszqXQ+5TMa9uGeM23iW/WczJ4fsisjx9y1L/6V/57i2dnknJvWoTcliNtyMSeST709w9f6THPVM7bMUWPNyJLOoXGZkZDBgwACGDRtG/fr1OXXqFF9++SV79uyhePHiWq+1VpVLgXmwRjVRa9qrLqXK5fcb9+Du6aW1bnRUJP17dHw1VS4vX75MTEwM9evXB6B+/foUK1aMGzdumKN5gUBggVjzUN0sgdPDw4MHDx5w8+ZNAG7cuEFcXBze3t7maF4gEFgg1izWZpZnnK6uroSEhDB8+HDNEGjatGk4Ojqao3mBQGCJWPFDTrPtVff398ff399czQkEAgvH1NmRzEmhSfIhEAisDH2eYVpm3BSBUyAQFAxWPFIXgVMgEBQM+mQ/stTsSCJwCgSCAsEQsTZLQwROgUBQIIihuqBQoFRJswtHIZfu6y/VUE7KDXU3v3tXErueH641uU15agKlTW41Exl69DglattYROAUCAQFhPX2OUXgFAgEBYJ4xikQCAQGYr39zUIinWGNsrVS2pbKrrtziWxHyWJF+PKzYSaxbW33WUrZ4Sz+vX4d55LF6NfXsHyZywc15fKirkSs6E7YrM4Ev5BZPrhlRU7N8efuyu5sHtkKD8fn+UlHdalJzOr3ubuyu+Yo76afnlF+kMlkyHUcYjmShFijbK2UtqWyGx3/XJsmMTGRit6edHm3m1E2s7C2+yyl7HAWnw8fSn3fBgZfN2/XRYat+pu0DBWVPUuy65s2nIt4hEPRIozrXgf/aQe58eApM4Lrs+qTZnSaelBz7bZ/Ivh42V+ac3nqE8kmh6y5y1koepzWKFtrjfLAL7Jj2y+4urrRrPmbRtuyxvsslexwFps3bcDR0ZG3WrU2+NorkY+zSw8DFdwcaFfXix0n7nAl8jHpShWzt1+gWTX3XGWJzYE1Z0cqFIFTKoQ8cN6sXfM/3u8dbJKhlDXe55cxlewwwJMnT5gycQIzZs3Nt405HzQgclUPwmb7E52QzIGz94GXpIX/O6le9nmWsvZ1vbi59D3+mt6Rfn6V892+PlhzPs5CMVSXCiEPnDt3IiL48/ejLFm2yiT2rPE+v4gpZYcBJoWMo8+H/fAyIuP5iJ/C+Op/J2lYuTTNqruTmqHk0Lkovv+kGat/u86NB0/5KrAmKpUa+//khbf/E8FPh/8l5nEKvpVc+OnTFjx5nMDvZ41+S7lizdmRzNbjPHLkCF26dKFz58707t2bu3fvmqvpfCPkgXNn/bqfadKsOT4VKpjEnjXe5yxMLTt89uwZjvx2iGGffm68b2o1f197iJeTPf38qnD04gNmbD3PT5++ydl5AdyJTSIxJZ378Zm67VfvP+FBQjIqtZoT12NZHnoF/8YVdbRiBFY8VjdL4Hz8+DGjRo3i22+/ZdeuXXTr1o2QkBBzNG0UQh44d9av+ZlevfuYzJ413meQRnb4j6NHiIi4TdVK5ang7cmCeXPZse0Xmjaqn2+bCoWMCv89x1x18Bq+I3dRdehWdobdQaGQc+ne41yvU6uljVtWHDfNEzgjIiIoXbo0Ff7robRs2ZI///yT+Hj99KB1YY2ytdYoDwzw9/G/uH8/0mSz6WCd9xmkkR3uN2Ag5y//y/ET4Rw/EU7/jz6m/Tsd2bH7V72uL13Sjq6Ny1PcrghymYzWNT15t4kPv198gJ2NnOplSwFQ1sWe+f0asTz0Co+fpQHwTr2ylLK3BaDeay4MbFuVfSdvmeR95YaupUhZhyVilmecFSpUIDY2lnPnzlGrVi127doFQFRUFM7Ozkbbt0bZWiltS+nz2p9/wj+wq0mH/mB991kq2WF7e3vs7e015w4ODtgVLYqrq6te16vV0M+vMt/2bYhMLuNebBLfrDnJvvBIStrbsHJwM3zcS5CYnM66P24ydcs5zbXvNi7P4gGNsbWRcz/+GQv2XGLD0auSLkey1kTGZpEHBvjrr79YtGgRqamptGjRgrVr1/Lzzz9TTcfDdCEPbD6sMcmHVEj5s5DKtFd/020ayEKemkDpswslkQfeuucAZcpolwe+fz+Srh3ftjh5YLPNqjdt2pSmTZsCEBsby/fffy9ULgWCVxhrzo5ktln1hw8fApmzkN9++y1BQUHZhiQCgeDVQqbnf5aI2Xqc8+fP5/Tp06Snp9OsWTNGjBhhrqYFAoEFIrIj6cHUqVPN1ZRAILACrHirutg5JBAICggrjpwicAoEggJBLkPnOk1LXZAhknwIBIICQYqdQ7du3aJHjx60a9eOHj16cPv2bRN6/BwROAUCQcEgQeScMGECPXv2JDQ0lJ49ezJ+/HiTupyFxQ/VlUolANEPHhSwJ4UflUQL4OWWOt7SgqT7QiQyLU9NML3NtMwEKVm/Q1MSEx2NrsiYWQce5PL7L1myZLbMV3FxcVy6dInVq1cD0KlTJyZPnkx8fLxJdii+iMUHzqz1nx/2yf82NoHgVUCyrZFk/g7Lly9vElsODg6UKlVK79+0nZ0dvXrlrDt06FCGDXsu3RIVFYW7uzsKRWaaPIVCgZubm8m2dr+IxQfOGjVqsHbtWlxdXTU3RCAQmAelUsnDhw+pUaOGyWw6Ojqyf/9+EhMT9aqvVqtzTZj9cp5Vc2LxgbNo0aL4+voWtBsCwSuLqXqaL+Lo6Iijo6Puigbg6elJdHQ0SqXy/+3de0wU59cH8C8glFakeEHc4qXVtEiqyCpdq1ahYFtAAixRkVpqazQiilIihgIFhB9Q0CAENStoFG9ViRQq6wWalkUugsIKBEVEBVSQlYuikWURzvsHL5NStbLsoLU+n4TEmXnmzDODe3hmZucMdHR00N3dDYVCAYFA8OKV1cRuDjEM858wevRomJubIzMzEwCQmZkJc3Nz3k/TgZdYHYlhGGaoXb9+HQEBAWhvb4ehoSFiYmIwefJk3rfDEifDMIya2Kk6wzCMmljiZBiGURNLnAzDMGpiiZNhGEZNLHEyDMOoiSVOZsD4eOXy8zx48AA9PT28x62pqRnwEyrqunDhApqbm3mP29XVNaTHmtGcTlhYWNir7oQm8vLykJ6ejqKiIpiamr7Sx7AGqqSkBDk5OaiqqoJAIODtndwAkJ+fjxMnTiA7OxtTp06FgYEBL3Hz8vIQGxsLkUiE4cOH8xKzT05ODo4cOQKRSAQ9PT1e427duhXm5ua8Pz1SUFCA7777Dnfv3oWtrS1vjwPLZDLs3r0bv/zyC2bNmoV3332Xl7iFhYXIzMxESUkJxo0b91p8Tv7NXusRZ25uLiIiImBoaIiWlhZ4eHggNzeXl5FLeXn5kNTyy8nJwZYtW3Dz5k0UFhYiKioKSqWSl9jnzp3Dtm3bMGHCBLS1tWH79u28xO3u7sb58+fxxx9/YMeOHWhpaeElLtCbkOPj4+Hg4MBbkgeAS5cuITo6Gps2bYJQKOQtLtDb561bt2LVqlXQ0tJCZ2cnAM0rKslkMmzfvh329vYYP348YmNj+egucnJyEB0djbfeegtNTU1wcnKCTCYb2gpQ/3X0GouMjKTDhw9z0wcOHCA3NzfKy8vTKK5MJiMzMzNyc3Oj2tpaTbvJKSsro6+++oouX75MRERyuZxWr15NLS0tGse+dOkSOTk50YULF4iISCqV0pYtWyg7O5saGho0jl9QUECJiYm0atUqWrduHRER3bt3jzo7Owcds6SkhEQiEff7amlpoYKCAsrJyaHW1laN+puWlkZRUVFERHTr1i1KTk6miIgIKisro56enkHHzc/Pp4ULF1JZWRkRETk5OVFsbKxGfSUi6uzspB9++IFyc3OJiOjChQu0efNmSkpKovLy8kH3ubOzk/z8/KioqIibt2zZMrKxsaHz589r3O831Ws94tTR0YFCoeCmPT094eLigoCAADQ2Ng4qplKpxMmTJ5GQkAALCwsEBgairq6Ol/7q6enh22+/hbm5OQDA0tISDx48wLVr1zSObWJigtDQUFhZWaG5uRkJCQm4f/8+8vLyIBaLNRo9ExE6OjrQ1taGXbt2QalUYvny5Vi1ahVX9m8wjIyMoK+vj4aGBtTV1cHb2xvHjh3DoUOHsHLlSo1Gttra2lwNyU2bNkGlUgEAgoKCUFpaOui4Ojo6iImJgYWFBQDAz88PtbW1aPr/upGauHfvHkpLS3HlyhWEhIRgxIgRUCgUCAwMRElJyaDj9h3fPvPmzcP06dPh6+uL1tZWjfv9RnrVmVsTZWVlJBKJSCqV9psfFBRE+/btG3TcpqYmbiTl7+9PX3/9Nd24cUOTrnIePnxIREQqlYqIiFauXEnl5eVERFRYWEjt7e0ab+PkyZOUlpbGTQcEBFBkZKRGMZVKJQUFBRERUV5eHllaWpK7u7tGMYmIqqqqyM7OjubMmUOpqalE1HuMfHx8+u2DumpqakgkEpG/vz+lpKRw8+Pj48nPz0+jUScRcevX1taSs7MznT17VqN4RL0jcLFYTKtXr6b//e9/3Py4uDjasGHDoPt8+vRpsre3p+3bt1NYWBh3xuDt7d1vJMoM3Gs94rSwsEBwcDD27NmDU6dOcfNHjBiBrq6uQccdO3YsdHV1AQCxsbEwNTVFcHAwHj9+jGPHjmH//v2Djt13Ha+vvqCuri5GjRqFs2fPIjY2Fg8fPhx07D5OTk4Qi8XcNSxTU1MYGxtrFFOlUqGjowMSiQQRERGIiooCAPz4448a3QE2MzODRCLB2rVrsXjxYgC9x8jAwADa2oP/7zllyhRERESgsLAQ1dXV3HyBQABjY+Nn1ndUR9/6kyZNwuLFi7F3716Nr/3OnDkTR48ehbW1db9SbiYmJhgzZsygr0l++eWXCAoKglKphEAgQFxcHIDeUbkmn5M32qvO3Jrq6uqizMxMEolEFBsbS3FxceTo6EjXrl3TOHZ3dzf37/DwcJo7dy7Z2Nhw1yj5sHnzZvLx8SGxWEzV1dW8xe1z6tQpcnNzo+vXr2sca/fu3TR//nxudNXZ2Um3b9/WOO7fnTlzhlxcXKi+vl6jOE+ePKH09HSaNm0aJScnk0QiIVdXV7p69SpPPe1VX19PHh4eJJfLeYlXWlpKixYtooMHD9Lx48dJLBbz3uf09HRycHCgO3fu8Br3TfHaJ84+lZWVtGvXLoqLi+M1AfUlz4yMDBKJRLwkZKLeU72enh5yd3enefPm8XoTiqj3UsCRI0fIwcGBtz4rFAq6cuUKF59vPT09lJqaSvb29rz+DisrKyk5OZkSExOppqaGt7h/FRERoXGi79Pd3U1SqZRWrFhBfn5+vCfNrKwscnd3536XjPpYWbkBaG9vR2hoKNasWYOpU6fyGjs7OxuTJk3CRx99xGtcAKioqMCIESPw/vvv8x57KBARiouLYWxsPCQ1FIcCPee1DnxQqVTQ0tLiLhvxpbm5GU+ePMG4ceN4jfsmYYlzgFQqFa9fzmYY5vXFEifDMIyaXuu76gzDMK8CS5wMwzBqYomTYRhGTSxxMkOmqKgICxYs4KYXLVqEoqKiId9uQEAAbwVO+vx9X17Wusy/E0ucQ8jW1hbTpk176nlgV1dXmJmZ4fbt2wB6P+hmZmYoLy/n2tTV1cHMzIyb9vT0RGpqKjctkUhga2sLoVCIBQsWwNfXF0BvchIKhRAKhTA3N8f06dO5aYlE8lQfExMT8fHHH0MoFMLKygrLli2DXC7n9Tj0kUqlmD179gvbmZmZ8VYf4O/S0tLg4eExJLGZNwdLnEPM1NQUUqmUm7569So6OjqeamdkZIT4+PgBxfz111+RkZGB/fv3Qy6X48SJE5gzZw6A3uQkl8shl8thZWWFkJAQbtrLy+uZ8RwcHCCXy1FYWIiZM2fCx8fnmY/39RXNYJg3HUucQ8zFxQXp6encdHp6OlxdXZ9q5+rqiqtXr6K4uPiFMSsqKvDZZ59h4sSJAABjY2O4u7tr3FddXV2IxWLcu3cPbW1tCAgIQGhoKFavXg1LS0sUFRWhqakJPj4++PTTT2Fra4sDBw5w6yuVSgQEBOCTTz6Bo6MjKioq+sW3tbVFQUEBgN4kLJFIsHDhQgiFQri5uaGxsRHLly8H0HvchEIhV4Pgzz//hIuLCzcqrqqq4uJevnwZYrEYQqEQvr6+XH1MdZ04cQIODg4QCoWws7PD0aNHn2ojkUgwe/Zs2Nra4rfffuPmq1QqxMTEwMbGBnPnzkVISAhvdVaZfx+WOIeYpaUlHj16hOvXr6O7uxtSqRTOzs5PtdPX18eaNWsGdG1uxowZyMjIwJ49e1BRUcHbSFClUiEtLQ0CgQCjRo0CAGRmZsLLywulpaUQCoVYu3YtzMzMkJubi5SUFKSkpODcuXMAgB07dqC+vh7Z2dnYu3dvvz8Yf7dv3z5IpVIkJSWhtLQUUVFR0NfXx+HDhwEAGRkZkMvlcHR0xOXLlxEYGIjw8HAUFRXB3d0d3t7eUKlUUKlUWLduHVxcXFBcXAx7e3tkZWUNav9Hjx6N3bt3o7S0FNHR0YiOjkZlZSW3vLm5GW1tbTh37hx+/vlnhISE4MaNGwCAbdu24ebNm0hPT0dWVhYUCgV27tw5qH4w/34scb4EfaPO/Px8TJkyBSYmJs9st2zZMjQ2NkImk70wXnBwMPLy8uDp6Ym5c+ciKSlp0P07c+YMrKysYG1tjcrKSuzYsYNbZmdnh1mzZkFbWxvV1dVobW3F+vXroaenhwkTJmDp0qXcqPD06dPw8vKCkZERBAIBPD09n7vN1NRUbNy4EZMnT4aWlhamTp2KkSNHPrPtsWPH4O7ujhkzZkBHRwdisRi6urq4dOkSysrK0NXVhRUrVkBXVxf29vaYPn36oI6DjY0NJk6cCC0tLYhEIsybNw8XL17s12bjxo3Q09ODSCSCtbU1Tp8+DSLC8ePHERgYCCMjIxgYGGDNmjX9LtEw/y3DXnUH3gQuLi745ptvcPv2bbi4uDy3nZ6eHry9vZGQkPDCkaezszOcnZ3R1dWF33//Hf7+/jA3N8f8+fPV7p+9vT22bdv2zGV/fVfPnTt3oFAoYGVlxc3r7u7mphUKRb/277333nO3effuXe5Sw4s0NDQgPT0dhw4d4uZ1dXVBoVBAS0sLJiYm/Z4X/6ft/hOZTIadO3eitrYWPT09UCqV/WoIGBoa4p133um3HYVCgdbWVnR0dMDNzY1bRkRD8vI55t+BJc6XwNTUFOPHj4dMJkNkZOQ/tnVzc0NycvKATzd1dXXh4OCA5ORkXLt2bVCJc6AEAgHGjx//3L4ZGxujsbERH374IQD8YxX+cePGob6+fkDFTQQCAby8vLB27dqnlhUXF6OpqalfsY2GhgZMmDBhILvEUalU2LBhA2JiYmBnZwddXV14e3v3u0nW3t6Ox48fc8mzb19HjhwJfX19SKXS555NMP8t7FT9JYmMjERKSkq/EcuzDBs2DD4+PtizZ89z26SlpSEnJwePHj1CT08PZDIZampquNc5DBULCwsMHz4cSUlJUCqV6O7uRnV1Nfc1KgcHByQlJeHBgwe4e/cuDh48+NxYS5YsQUJCAmpra0FEqKqqQltbGwBgzJgxuHXrVr+2R48eRVlZGYgIjx8/5vbf0tISw4YNw4EDB9DV1YWsrKynbkr9HRGhs7Oz30/f9dJRo0Zh2LBhkMlkyM/Pf2rdxMREqFQqXLx4ETk5ObC3t4e2tjaWLFmCqKgorphxU1MTd+2X+e9hI86XZKCnpUBvBfekpCTcv3//mcsNDAwgkUi4G06mpqYICwvrdwo9FHR0dCCRSLhRmUqlwgcffMB9h3T9+vUIDQ2FnZ0dxo4dCzc3t3533f/q+++/h0qlwsqVK9HW1obJkydzN1PWr1+PgIAAKJVKhIeHw9HREREREQgPD0ddXR309fUxc+ZMWFlZQU9PD4mJifjpp58QHx8Pa2trfPHFF/+4H3K5/Kk/MpWVlQgODoavry9UKhU+//xz2Nra9mszZswYGBoaYv78+Xj77bcRFhaGKVOmAAD8/f2xc+dOLF26FG1tbTAxMYGHh8eQngEwrw6rjsQwDKMmdqrOMAyjJpY4GYZh1MQSJ8MwjJpY4mQYhlETS5wMwzBqYomTYRhGTSxxMgzDqIklToZhGDWxxMkwDKOm/wNZj2p1YZlRfwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYKWSHRJBlBc"
      },
      "source": [
        "# **References link**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmE3vQ5-CBB6"
      },
      "source": [
        "\n",
        "\n",
        "A. Check Grokking deep learning book \n",
        "Sample code :  https://github.com/iamtrask/Grokking-Deep-Learning (Links to an external site.) chapter 7,8,9.  - use mini batch, dropout, learning rate etc.,. \n",
        "\n",
        "Pick appropriate batch size for minibatch (read fastai and other tips and https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6 (Links to an external site.) for example.) see sample https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/ (Links to an external site.) as well.\n",
        "\n",
        "B. Try various dropout rates and pick the one which works well. (need not be same for all layers ;-) ). - see https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6 (Links to an external site.) for ideas.\n",
        "\n",
        "The code should initialize the random weights of network properly - see https://docs.google.com/presentation/d/1cYzq7TEGXRAhKF9P0eOI_q01kQAOajl-eS9h3CTGRLg/edit#slide=id.g60fb2717a6_37_196 (Links to an external site.) for more information on how to initialize the random weights before training\n",
        "\n",
        "C. The code should do basic image augmentations to supplement the training data (not testing data) using keras libraries  (NEW than the deck) \n",
        "See the image augmentations tried in https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6 (Links to an external site.)\n",
        "\n",
        "G.The code should use appropriate learning rate (try out few to find out which one works)\n",
        "You can use adaptive learning rates like different learning rates per epoch or per mini batch - see discussion of learning rate schedules https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6 (Links to an external site.)\n",
        "\n",
        "https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/ (Links to an external site.) for more information on different learning rates generations for various epochs etc.\n",
        "\n",
        "I. The code should display top common errors like in below link.\n",
        "Extra points if you hit 99% test accuracy with these changes (very challenging given you are not using CNNs).\n",
        "\n",
        "Sample (these are with using keras you should try not to use keras for training model /testing other than data preprocessing - like image data augmentation, scaling, normalization ) :\n",
        "\n",
        "https://stats.stackexchange.com/questions/376312/mnist-digit-recognition-what-is-the-best-we-can-get-with-a-fully-connected-nn-o (Links to an external site.)\n",
        "\n",
        "https://www.kaggle.com/fchollet/simple-deep-mlp-with-keras/code (Links to an external site.) (Links to an external site.)\n",
        "\n",
        "https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6.  (Links to an external site.)\n",
        "\n",
        "https://www.kaggle.com/c/digit-recognizer/discussion/61480 (Links to an external site.)\n",
        "\n",
        "https://www.kaggle.com/adityaecdrid/mnist-with-keras-for-beginners-99457 (Links to an external site.)\n",
        "\n",
        "more inspiration : https://www.kaggle.com/c/digit-recognizer/notebooks (Links to an external site.). \n",
        "\n",
        "(note that most use cnn which we have not yet studied - you should use regular neural network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBxweYuCsiL"
      },
      "source": [
        "Hint: you can hack  on getting these tunings and  hyperparameters by running experiments on gpu using free  automl online services (like https://www.simonwenkel.com/2018/08/30/autokeras_mnist.html \n",
        "(Links to an external site.), \n",
        "\n",
        "or a ton of tools similar to this (like online free https://www.r-bloggers.com/kannada-mnist-prediction-classification-using-h2o-automl-in-r/ (Links to an external site.).\n",
        "\n",
        "http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html (Links to an external site.).\n",
        "\n",
        "https://www.h2o.ai/blog/a-deep-dive-into-h2os-automl/?gclid=Cj0KCQiA4sjyBRC5ARIsAEHsELEeWwIWhvZeJj75IRd_PWUBFSEZS7zllR0Abk0Pp9ao7euEmvXzA5IaAnZBEALw_wcB (Links to an external site.). )  \n",
        "\n",
        "- aka - test the right dnn configuration (without cnn) - first or capture from your research online - and then try it out in your python code)\n"
      ]
    }
  ]
}