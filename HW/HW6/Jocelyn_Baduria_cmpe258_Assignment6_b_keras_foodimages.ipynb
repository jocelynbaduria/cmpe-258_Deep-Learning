{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jocelyn_Baduria_cmpe258_Assignment6_b_keras_foodimages.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1D5b7kxHVDgO7nGNaEo7SvjV1pzXFRMzT",
      "authorship_tag": "ABX9TyMuYHwzrvMK6o0ce03A0DlG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jocelynbaduria/Assignment-6_part_abcde/blob/main/Jocelyn_Baduria_cmpe258_Assignment6_b_keras_foodimages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpRJqf63j4Yk"
      },
      "source": [
        "B. CNN based image classifier using Keras (food images)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok79zHxfYOGE"
      },
      "source": [
        "Download Images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEvk7cHpYSs3"
      },
      "source": [
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XhUHGYAbUQD",
        "outputId": "1fa503ad-b0d7-46cb-eb06-f894d2431720"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-01 02:08:09--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 74.125.23.128, 74.125.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519183241 (495M) [application/zip]\n",
            "Saving to: ‘10_food_classes_all_data.zip.3’\n",
            "\n",
            "10_food_classes_all 100%[===================>] 495.13M   147MB/s    in 3.4s    \n",
            "\n",
            "2021-05-01 02:08:12 (147 MB/s) - ‘10_food_classes_all_data.zip.3’ saved [519183241/519183241]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGjh1ZloY8qH"
      },
      "source": [
        "# Unzip the downloaded file\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Utility function to unzip a zipped file.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA-o4yN-lpZ9"
      },
      "source": [
        "unzip_data(\"10_food_classes_all_data.zip\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48OKsz-McHeT",
        "outputId": "ee09184f-2842-4866-f409-4aa6b58f3c12"
      },
      "source": [
        "!ls 10_food_classes_all_data"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgF_4-PecLIL"
      },
      "source": [
        "# Setup data inputs\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def create_data_loaders(train_dir, test_dir, image_size=IMG_SIZE):\n",
        "  \"\"\"\n",
        "  Creates a training and test image BatchDataset from train_dir and test_dir.\n",
        "  \"\"\"\n",
        "  train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  image_size=image_size)\n",
        "  # Note: the test data is the same as the previous experiment, we could\n",
        "  # skip creating this, but we'll leave this here to practice.\n",
        "  test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  image_size=image_size)\n",
        "  \n",
        "  return train_data, test_data"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzi14jCicSBF"
      },
      "source": [
        "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
        "data_augmentation = keras.Sequential([\n",
        "  preprocessing.RandomFlip(\"horizontal\"),\n",
        "  preprocessing.RandomRotation(0.2),\n",
        "  preprocessing.RandomZoom(0.2),\n",
        "  preprocessing.RandomHeight(0.2),\n",
        "  preprocessing.RandomWidth(0.2),\n",
        "  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n",
        "], name =\"data_augmentation\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue4YQ5UKrXbm"
      },
      "source": [
        "# Setup input shape and base model, freezing the base model layers\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "BASE_MODEL = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "def create_model(input_shape=INPUT_SHAPE, base_model=BASE_MODEL, num_classes=10):\n",
        "  # Fine-tune?\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # Create input layer\n",
        "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "  # Add in data augmentation Sequential model as a layer\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  # Give base_model inputs (after augmentation) and don't train it\n",
        "  x = base_model(x, training=False)\n",
        "\n",
        "  # Pool output features of base model\n",
        "  x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "\n",
        "  # Put a dense layer on as the output\n",
        "  outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "  # Make a model with inputs and outputs\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTpiGmGBcX09"
      },
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=False):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  if scale:\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icoxP-n5qE8p",
        "outputId": "253feec5-3c54-419b-9af1-2ea725d021d2"
      },
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_all_data'.\n",
            "There are 10 directories and 0 images in '10_food_classes_all_data/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/chicken_curry'.\n",
            "There are 10 directories and 0 images in '10_food_classes_all_data/train'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/grilled_salmon'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/pizza'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/sushi'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/ice_cream'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/steak'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/ramen'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/chicken_wings'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/fried_rice'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/hamburger'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/chicken_curry'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l5hNCMBqJ9F",
        "outputId": "802ba452-ae9c-4689-9ba8-f7d2d845bb1e"
      },
      "source": [
        "# Check the file in 10_food_classes_10_percent\n",
        "!ls -la 10_food_classes_all_data"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16\n",
            "drwxr-xr-x  4 root root 4096 May  1 01:47 .\n",
            "drwxr-xr-x  1 root root 4096 May  1 02:08 ..\n",
            "drwxr-xr-x 12 root root 4096 May  1 01:47 test\n",
            "drwxr-xr-x 12 root root 4096 May  1 01:47 train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZScJCDGqYsw"
      },
      "source": [
        "# Create tensorboard callback (functionized because need to create a new one for each model)\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjUCWjcFdbKU"
      },
      "source": [
        "Create a Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DDGfZzHceBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76a1b2d-1dfc-4f62-d307-0d7638078c3d"
      },
      "source": [
        "# Create BatchDataset\n",
        "train_data, test_data = create_data_loaders(train_dir=\"10_food_classes_all_data/train/\",\n",
        "                                            test_dir=\"10_food_classes_all_data/test/\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7500 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8hbGMr-q09y",
        "outputId": "0211e495-ff51-4295-ee0b-a1468de01071"
      },
      "source": [
        "# Create model\n",
        "model_1 = create_model(num_classes=len(train_data.class_names))\n",
        "\n",
        "# Fit the model\n",
        "history_1_percent = model_1.fit(train_data,\n",
        "                    epochs=5,\n",
        "                    steps_per_epoch=len(train_data),\n",
        "                    validation_data=test_data,\n",
        "                    validation_steps=int(0.25 * len(test_data)), # validate for less steps\n",
        "                    # Track model training logs\n",
        "                    callbacks=[create_tensorboard_callback(\"transfer_learning\", \"all_data_aug\")])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: transfer_learning/all_data_aug/20210501-020826\n",
            "Epoch 1/5\n",
            "235/235 [==============================] - 596s 2s/step - loss: 1.4444 - accuracy: 0.5564 - val_loss: 0.5575 - val_accuracy: 0.8240\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 578s 2s/step - loss: 0.7157 - accuracy: 0.7773 - val_loss: 0.4625 - val_accuracy: 0.8487\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 579s 2s/step - loss: 0.6268 - accuracy: 0.8072 - val_loss: 0.4004 - val_accuracy: 0.8701\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 572s 2s/step - loss: 0.5774 - accuracy: 0.8202 - val_loss: 0.3892 - val_accuracy: 0.8750\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 585s 2s/step - loss: 0.5511 - accuracy: 0.8242 - val_loss: 0.3905 - val_accuracy: 0.8701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpFb7mzY5jJh",
        "outputId": "2ec7d4e8-599b-457f-af55-a59810c33e79"
      },
      "source": [
        "# Get an image Tensor\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-01 03:08:36--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2874848 (2.7M) [image/jpeg]\n",
            "Saving to: ‘03-pizza-dad.jpeg’\n",
            "\n",
            "03-pizza-dad.jpeg   100%[===================>]   2.74M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-05-01 03:08:37 (19.8 MB/s) - ‘03-pizza-dad.jpeg’ saved [2874848/2874848]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEcYE1K65qWN",
        "outputId": "defee388-c9c6-48f1-d4f4-90821cbc8177"
      },
      "source": [
        "# Classes our model is trained on\n",
        "class_names = train_data.class_names\n",
        "class_names"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TU7CSOq5wc2"
      },
      "source": [
        "# Preprocess image\n",
        "pizza_img = load_and_prep_image(\"03-pizza-dad.jpeg\")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9F9DZQX7D-L",
        "outputId": "8dd950c7-bb6c-4f2b-d02d-c6efc45d2033"
      },
      "source": [
        "print(pizza_img)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 73.625  76.75   67.125]\n",
            "  [114.    122.    101.   ]\n",
            "  [146.875 151.875 129.875]\n",
            "  ...\n",
            "  [ 14.5    17.5    10.5  ]\n",
            "  [ 14.25   19.25   12.25 ]\n",
            "  [ 19.75   22.75   15.75 ]]\n",
            "\n",
            " [[239.125 243.625 246.125]\n",
            "  [225.375 232.125 234.875]\n",
            "  [240.    245.    244.5  ]\n",
            "  ...\n",
            "  [ 11.     14.      7.   ]\n",
            "  [ 20.     23.     16.   ]\n",
            "  [ 20.875  25.875  18.875]]\n",
            "\n",
            " [[ 32.5    34.5    31.5  ]\n",
            "  [ 44.625  44.5    42.375]\n",
            "  [ 33.     38.     34.   ]\n",
            "  ...\n",
            "  [  8.75   13.25    6.25 ]\n",
            "  [ 14.875  17.875  10.875]\n",
            "  [ 13.625  20.625  12.625]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 61.875  40.875  19.875]\n",
            "  [ 60.     42.     22.   ]\n",
            "  [ 61.     43.     21.   ]\n",
            "  ...\n",
            "  [134.5    96.125  60.75 ]\n",
            "  [104.875  69.375  43.125]\n",
            "  [106.25   75.25   46.25 ]]\n",
            "\n",
            " [[ 62.75   44.75   24.75 ]\n",
            "  [ 61.125  43.125  23.125]\n",
            "  [ 58.125  40.125  20.125]\n",
            "  ...\n",
            "  [159.125 111.125  64.625]\n",
            "  [160.375 112.375  66.375]\n",
            "  [134.     94.125  56.75 ]]\n",
            "\n",
            " [[ 59.625  42.625  22.625]\n",
            "  [ 61.75   43.75   22.5  ]\n",
            "  [ 59.25   41.25   21.25 ]\n",
            "  ...\n",
            "  [161.5   113.5    64.5  ]\n",
            "  [159.    108.     63.   ]\n",
            "  [155.875 104.875  59.875]]], shape=(224, 224, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf_h8G4Q5zQS",
        "outputId": "d6c4f8c4-5e49-47b5-8cb6-9ea6b04beff0"
      },
      "source": [
        "# Make predictions\n",
        "pizza_expanded = tf.expand_dims(pizza_img, axis=0) # expand image dimensions (224, 224, 3) -> (1, 224, 224, 3)\n",
        "pred = model_1.predict(pizza_expanded)\n",
        "pred"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.8958344e-03, 2.6990494e-05, 3.3113139e-04, 1.3801754e-04,\n",
              "        2.5877202e-06, 1.1752647e-06, 9.9270952e-01, 2.2431467e-04,\n",
              "        7.7706420e-05, 5.9265993e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XSTfeSHz590_",
        "outputId": "56025ae5-2fd3-4ae9-cec3-7670b22ac1f3"
      },
      "source": [
        "# Check the predicted class\n",
        "class_names[tf.argmax(pred[0])]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pizza'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PKQD4oFc_Yk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def pred_and_plot(model, image, class_names):\n",
        "  pred_probs = model.predict(tf.expand_dims(image, axis=0))\n",
        "  pred_class = class_names[tf.argmax(pred_probs[0])]\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  # plt.imshow(tf.argmax(pred[0]).astype(\"uint8\"))\n",
        "  plt.title(f\"{pred_class}, prob: {tf.reduce_max(pred_probs):.2f}\")\n",
        "  plt.axis(False);"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Y07sUdL7_CYd",
        "outputId": "2edab98e-ef27-45df-ae84-41a788b46683"
      },
      "source": [
        "pred_and_plot(model=model_1,\n",
        "              image=pizza_img,\n",
        "              class_names=train_data.class_names)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}